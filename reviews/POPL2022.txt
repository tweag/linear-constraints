> POPL 2022 Paper #479 Reviews and Comments
> ===========================================================================
> Paper #479 Linear Constraints
> 
> 
> Review #479A
> ===========================================================================
> 
> Overall merit
> -------------
> B. Weak Accept
> 
> Reviewer expertise
> ------------------
> X. Expert
> 
> Paper summary
> -------------
> This paper develops a type system and type inference to ease
> programming with linear types.
> 
> Linear types are often used to keep track of the state change of
> resources such as files and sockets, as exemplified in the work on
> typestates and session types.  However, programming with linear types
> tends to be awkward: it is typical that primitives for resource
> accesses are supposed to take a linear resource and returns the same
> resource after state change and so a program has to introduce a
> variable to be bound to the result, every time the primites are used.
> This problem can be mitigated by a flow sensitive type system, which
> takes care of state change, but this solution is not ideal, either.
> 
> This paper proposes linearly used type class constraints to address
> the problem.  Roughly speaking, the idea is to lift typestate
> information to the type class constraint level and let a single
> resource type, which itself is not linear, to belong to different type
> classes that represent the states of a file, depending on program
> points (thus the type system is flow-sensitive).  The type of a
> resource access primitive is given in such a way that it takes a value
> of a resource type *and a linearly used piece of evidence that the
> resource type belongs to a certain type class* and may return another
> piece of evidence that the resource type belongs to a possibly
> different type class.  As a result, a variable of type, say File, can
> be used more than once and typestate change is implicitly managed by
> the type system, making programs more concise.
> 
> The main technical contributions are a qualified type system with
> linear type class constraints and type inference.  Soundness of type
> inference is stated (and proved in the supplementary material).  The
> semantics of the language is given by elaboration to a linear type
> system so that type class constraints are lifted down to the term
> level.  It is stated that elaboration is type preserving and so the
> proposed type system is sound.
> 
> It is reported that a prototype has been implemented on top of GHC 9.1
> and implementation issues are discussed.
> 
> Strengths
> ---------
> * A clever idea to reduce typical clutter of programs using linear types.
> 
> * Solid technical development.
> 
> * Clearly presented.
> 
> * A prototype is implemented.
> 
> Weaknesses
> ----------
> * There is no evaluation, despite that there is an implementation.
>

JP: Not exactly true: our evaluation is the ability to implement prototypical examples. Which we can do.

> * The resulting program still needs boilerplate annotations (pack and
>   unpack), although it is claimed that they can be also inferred.
> 
> Comments for author
> -------------------
> I like very much the idea of pushing linearity to the type constraint
> level.  Very nice.  Given a big picture, it's not very hard to
> understand the technical development.  It may look not very surprising
> or challenging, but I appreciate straightforwardness.
> 
> I would have liked to see how linear constraints work in practice.  It
> would be nicer if it was confirmed that inference of pack/unpack could
> be integrated without problems, though.  Without such an integration,
> programs will still suffer from boilerplate code.
> 
> 
> # Minor comments:
> 
> Section 4.1.  It makes sense to distinguish read and write capabilities but
> I don't see the real use of Own (at least from the examples here).
> 
> Section 4.2.  I would have liked to see client programs that uses
> these array primitives.
> 
> L406: The idea of multiplicity can date back further to
> 
>   David N. Turner, Philip Wadler, Christian Mossin: Once Upon a Type. FPCA 1995: 1-11.
> 
> where multiplicity was called use and
> 
>   Naoki Kobayashi, Benjamin C. Pierce, David N. Turner:
>   Linearity and the Pi-Calculus. POPL 1996: 358-371
> 
> .  In these papers, operators for multiplicities are not very explicit
> but
> 
>   Atsushi Igarashi, Naoki Kobayashi: Type-Based Analysis of
>   Communication for Concurrent Programming Languages. SAS 1997:
>   187-201
> 
> considers summation and product of multiplicities.
> 
> Fig. 3:  What does T range over?
> 
> Fig. 4:  A typing rule for unrestricted variables seems to be missing.
> 
> Fig. 4:  Typing rules uses conditions of the form "$\bar a$ fresh" but
> it's not always clear where these variables must be fresh.
> 
> Fig. 6, G-LetSig:  It seems that if $\bar a$ appears in $Q$ they will be free
> in `Q =o C1`.  Isn't it a problem?
> 
> L864, "this is the only source of incompleteness": I'm not sure about
> this claim.  G-Let doesn't allow the type of x to be under constraints
> as in E-Let.  Isn't it another source of incompleteness?
> 
> Fig. 10(b): $z'$ at the end of the line 4 should be $z_1$.
> 
> L1007: I don't understand what "the superclasses of a linear
> constraint are never expanded" means...
> 
> L1199: I'm not sure Igarashi and Kobayashi gave a decision procedure
> for a wide class of analyses.  They showed that a wide class of
> analyses could be reduced to set containment problems, though.
> 
> Questions for the response period
> ---------------------------------
> * Can you answer to my question about incompleteness?
> 
> * Are any of extensions implemented?  I'd be especially interested in
> inference of pack and unpack.
> 
> * Is there any reason that a proof of Theorem 7.1 is not given in the
>   supplementary material?
> 
> 
> 
> Review #479B
> ===========================================================================
> 
> Overall merit
> -------------
> B. Weak Accept
> 
> Reviewer expertise
> ------------------
> Y. Knowledgeable
> 
> Paper summary
> -------------
> The paper details yet another extension of Haskell's class/type
> system: linear constraints, which are supposed to make programming
> with linear types (supported in GHC 9.x) less painful.
> 
> Strengths
> ---------
> I wasn't able to try out the addition but I fully believe that linear
> constraints take a lot of bureaucratic work away from the programmer.
> In other words, this is a very welcome addition.
> 
> Weaknesses
> ----------
> The core calculus is only presented in passing by, with almost no
> explanations and no accompanying proofs of soundness or any other
> properties.
> 
> Comments for author
> -------------------
> As already indicated above, I have mixed feelings about the paper. It
> is a very enjyoable read up to Page 8. The "need" for linear
> constraints is well motivated and the examples are compelling.  Then
> it goes down the route of a typical GHC paper. It tries, in a sense,
> too much: it presents a system of qualified types (for linear
> constraints), an algorithmic counterpart thereof, it indicates how the
> surface syntax desugares into core, how the proposed extension
> interacts with other parts of GHC's version of Haskell, outlines
> possible extension etc. Don't get me wrong, all of these points are
> worth discussing, but this is probably not possible within the given
> page frame, or only at the cost of omitting much-wanted explanations.
>  
> In more detail, the examples in §4 only discuss APIs but do not
> provide any applications that make use of these APIs. In other words,
> I get a feel how expressive the proposed addition is for library
> writers but I don't see how painless (or painful) it is to use these
> libraries. The "firstLine" program is pretty much the only example
> that demonstrates the usefulness, but it is over-simplistic.
> 
> The first technical section, §5, provides no overview of the
> development but starts immediately with a lot of technicalities.  The
> core system is advertised as "this system is our ground truth: a
> system with a simple enough definition that programmers can reason
> about typing.", advertised with no noticeable trace of irony. I got
> lost with the very first rule: E-Var. (For a start, some parentheses
> would help: Q_1 [τ/a] ; (Γ_1 + ω · Γ_2); there is more space around +
> but less space around ; which suggests the wrong bracketing.) Why do
> you insist that x has a multiplicity of 1, ie Γ_1 = x :_1 ∀a.Q1 =◦ υ?
> Surely, there should also be a rule for ω? (There is also no rule for
> "K".) You write "we survey .." and, indeed, the following explanations
> are a bit thin.
> 
> There is no proof of soundness for this system. You later state that
> "Thus, the soundness of our *implementation* is verified by the Core
> typechecker, which already supports linearity."

JP: this sentence should be clarified; reviewer misunderstood the
point (†) completely.

> which seems to be
> misleading. The Core typechecker surely does not *verify* the
> soundness of the implementation, it helps *debuggin* the
> implementation, acting as a safe-guard. Bad programs do not make it to
> the code generator, but that says little about the correctness of the
> implementation. (Dijkstra comes to mind:
>   Today a usual technique is to make a program and then to test
>   it. But: program testing can be a very effective way to show the
>   presence of bugs, but is hopelessly inadequate for showing their
>   absence.
> 
> There is a good discussion of related work, with one obvious (?)
> omission: I do feel that Clean's uniqueness typing is worth mentioning
> and discussing.
> 
> 
> 
> Review #479C
> ===========================================================================
> 
> Overall merit
> -------------
> C. Weak Reject
> 
> Reviewer expertise
> ------------------
> X. Expert
> 
> Paper summary
> -------------
> This paper presents *linear constraints*, an extension of Haskell that can be
> presented as a marriage of Haskell's pre-existing *type class constraints* and
> *linear types*. In Haskell, a class constraint can be viewed as an implicit
> parameter to a function, while a linear function parameter is a parameter that
> can be used at most once. Thus, quite naturally, a linear constraint is
> essentially an implicit parameter that can be used at most once.
> 
> Furthermore, whereas Haskell currently can reason about linear *parameters*,
> but not about linear *results*, this turns out to be too restrictive for the
> purposes of the present paper; thus, the system is extended (in a
> straightforward way) to allow linear constraints to be both received as
> function parameters and returned as function results. Existential
> quantification is also required.
> 
> The motivation for introducing linear constraints is relatively clear. Haskell
> currently can reason about linear values, whereas many linear type systems and
> program logics allow separating a duplicable value and a linear permission to
> use this value. (This goes back to Alias Types in the type systems literature
> and to Separation Logic in the program logic literature; these references
> could be cited.) The paper gives the elementary example of `openFile`,
> `readLine` and `closeFile`, and (in Section 4) presents a more advanced
> examples, where the type system allows governing the ownership of mutable
> references and arrays. The authors distinguish three levels of permission,
> Own, Write and Read; a stronger permission can be temporarily downgraded to a
> lower level. (However, the Read permission is still linear and cannot be
> shared or dropped, as in Rust, for example, where borrowed permissions can be
> dropped, and where a full permission magically re-appears when the borrowing
> scope is exited.)
> 
> It is important to note that (as far as I understand) the types assigned to
> the primitive operations on references and arrays are axioms. That is, the
> type system does not understand the meaning of these types, and does not check
> that they are sound in some sense. Thus, the type system is used to impose a
> certain discipline on the client side (on a program that uses mutable
> references and arrays), but it is difficult to ascertain in a formal sense
> what are the guarantees offered by this discipline. ("The language itself is
> agnostic about what linear constraints mean", line 1154.)

JP: tied to the above point (†). The meaning is actually given by the
underlying language without constraints. (It itself may be agnostic,
but beside the point at this stage of the paper.)

> Another potential shortcoming of the system is its limited expressiveness. The
> example of arrays presents a classic difficulty: because an array owns its
> elements, when one wishes to read an element, one must "borrow" the element
> from the array. (Another popular option in the literature is to use a swap, an
> operation that reads the element and writes another element in its place.)
> Here, this is done via "focusing", that is, temporarily losing the permission
> to access the array, and gaining a permission to use the element. (The paper
> "Adoption and Focus" may be the origin of this idea. The language Mezzo uses a
> similar approach.) Unfortunately, focusing is heavy (the `lend` operation
> takes the form of a higher-order function) and inflexible (one can focus on at
> most one element at a time, so one cannot simultaneously borrow two elements
> from an array). Rust's borrowing discipline is more flexible (in some ways).
> In summary, the example of references and arrays does not convince me of the
> need for linear constraints in Haskell. It is not clear to me that programmers
> will want to use this API. Are there more convincing motivating examples?

JP: Good points, but a large chunk of work to address them.
 
> The remainder of the paper is concerned with the metatheory of linear
> constraints: typing rules, constraint generation and constraint solving.
> The typing rules seem relatively straightforward (which is arguably good).
> The constraint solving machinery seems relatively simple, perhaps because
> the system has limited power. The authors rely on the fact that type
> inference can be performed first, so that the type derivation is available
> and can be exploited by the constraint solver. In particular, the manner
> in which existential types must be introduced (the witnesses) has been
> inferred already, so constraint solving actually appears to be a relatively
> simple *checking* process.
> 
> Somewhat surprisingly, the constraint solver is incomplete (see the end of
> Section 6). The authors conjecture that there is only "one source of
> incompleteness". The constraint solver seems sound, although this is not
> stated as far as I can see.
> 
> I give a low rating to the paper, mainly because I am not convinced (or I fail
> to see) what are the compelling potential applications of linear constraints.
> I am also not entirely convinced of the value of a type system that needs many
> axioms and checks only the client side, although I recognize that Rust's type
> system falls largely into this category (people use `unsafe` blocks to
> implement various operations whose safe use can then be enforced by the type
> system).

JP: the same point again (†)

> Strengths
> ---------
> + Relatively simple and natural design.
> 
> + A prototype implementation in GHC exists.
> 
> Weaknesses
> ----------
> + No really convincing examples of the applications of the type system.
>
> + Doubts on the expressiveness of the system. (The "focusing" API seems
>   heavy and inflexible.)
> 
> + Some doubts about verbosity. (I see a heavy style where `x : a p` must be
>   understood as meaning that the value `x` has type `a` and that `p` is
>   a type-level name for this value.)
> 
> Comments for author
> -------------------
> Related work: "Kindly bent to free us" (https://arxiv.org/abs/1908.09681)
> should be cited and compared.
> 
> line 26, "it doesn't naturally scale beyond this use case". This claim is in
> need of a justification. Could you provide an example, or an argument,
> explaining in what ways Rust's borrow checker is limited? What use cases
> can't it handle?
> 
> line 27, "general purpose linear types". There seems to be an implicit claim
> that Haskell's linear type are "as powerful as one might wish", and that their
> only drawback lies in their verbosity. This is not at all obvious to me; on
> the contrary, many kinds of linear type systems have been proposed in the
> literature, enforcing various properties (unique pointer, unique use, ...),
> so I do not expect any single system to be "general purpose" (more powerful
> than every other system).

JP: we should cite concrete evidence that this style of linear types
is heavily used in the literature with good benefits and there are
already applications of it.
 
> line 63, why "linear constraints", as opposed to, say, "linearity
> constraints"? As far as I understand, the constraint itself is not "linear"
> (whatever that would mean), but enforces linearity of certain values or types.


> line 80, "the resource representing the open file is a linear constraint".
> As someone who is familiar with Separation Logic, I would tend to think
> of the resource as a linear "token", or "permission", or "ghost token".
> But the word "constraint" does not seem appropriate here.

JP: Not sure if the reviewer is acting in good faith here. But perhaps
the paper should be called "Linear Constraints = Capabilities" (or similar) to
clarify this point as early as possible.
 
> line 84, ok, I understand. "Linear assumption" makes sense, and for some
> reason, sounds better to me than "linear constraint".
> 
> line 172, "While giving a name [...] the full power of dependent types." There
> are other examples, e.g. Mezzo has value-dependent types and permissions, but
> does not have full dependent types. In Mezzo, `Open h` would be a permission,
> referring to the variable `h` that is bound in the program by `let h =
> openFile()`.
> 
> line 203, "a gadts"
> 
> line 261, "Bind must be linear". There are three arrows in the type of bind,
> so, when you write "bind must be linear", which arrow do you mean?
> The first arrow clearly can be linear because clearly `bind x f`
> uses `x` exactly once.
> Can the third arrow be linear? I am not quite sure, because if
> the computation `x` diverges, then `bind x f` does not use `f`
> at all. But I imagine that this is OK. (Perhaps one could add
> "or the program diverges" at the end of the definition at lines 115-116?)
> Can or must the second arrow (`a ⊸ IO_L b`) be linear?
> At first this seems restrictive (what if we need to use the value of type `a`
> several times?) but perhaps it is OK because this value can be wrapped in an
> `Ur`?
> Also, I seem to understand that this arrow must be linear because
> otherwise readTwo would be ill-typed.
> ButI find it difficult to mentally type-check readTwo,
> especially considering that the typing rules have not
> been explained yet.
> To conclude this remark, I believe Section 3.2 needs work
> (more explanations).
> 
> I remark that, in plain Linear Haskell, there are apparently no linear types
> in the usual sense: `a ⊸ b` is the type of a function that uses its argument
> once, but the function itself is unrestricted. In this paper, however, the
> pair `t o Q` introduced at line 181 is a linear type: it is the type of a
> value that must be used exactly once. This seems to introduce a fundamental
> novelty into the system, and should perhaps be stressed. The fact that I have
> been given no explanations about this may be part of the reason why I do not
> know how to mentally typecheck readTwo.

JP: the above comment make me question whether the reviewer has any clue.

> line 312, you might wish to note the similarity with the type of `runST`.
> The idea is the same, at the granularity of a single location, and with
> linearity.
> 
> line 315, another approach might be to use
> newRef : (∀n. O n =◦ AtomRef a n → (b o O n)) ⊸ b
> which would allow returning a value of an arbitrary type b,
> but would have the drawback of tying deallocation to the end of the scope.
> Does this make sense?
> 
> line 315, isn't it very restrictive to require newRef to have
> an unrestricted return type?
> 
> line 360, "(and deallocate any previous reference at that index)".
> This is a bit cryptic, and could be better explained.
> The value that was previously held in the array is overwritten,
> and because it is linear, it must be properly disposed of.
> Here, this value is a reference, so it must be deallocated;
> but in general, since the type PArray is parameterized,
> this value could have arbitrary type;
> this seems to imply that writePArray must somehow have access
> to a polymorphic `dispose` operation. Could you clarify?
> 
> line 364, lendPArrayElt is a "focusing" operation, where one temporarily loses
> access to container and gains access to one element of the container. This
> construction has well-known drawbacks; e.g., it is heavy (scoped), and it
> allows accessing only one element at a time. In the case of Mezzo, this
> problem is discussed by Balabonski, Pottier, Protzenko in Section 2.4 of the
> Mezzo paper ("The design and formalization of Mezzo, a permission-based
> programming language").
> 
> line 367-368, it would be easy to make a mistake in the type of one these
> operations. Can these operations be implemented and type-checked, so as to
> guarantee that no mistake is possible?
> 
> line 406, "The idea of multiplicity goes back at least to Ghica and Smith
> [2014]". Really? Isn't it much older? What about, say, Wansbrough and Peyton
> Jones, POPL 1999?

JP: learn the difference between "at least" and "at most".

> Figure 2, "entailent"
> 
> line 537, what is the metavariable `q`? Is it a constraint `Q`?
> I do not see where `q` has been introduced.
> 
> In E-Unpack, why is the binding for `x` in the last premise annotated
> with `1`? This seems to require `x` to be used exactly once in `e2.
> However, I do not necessary why that is necessary.
> 
> line 654, "The intuition here is that [...]". I don't get it.
> 
> line 675, "Notably, the algorithm has access to the context splitting".
> Also, in G-Pack, you need access to the witnesses $\bar{ν}$
> 
> line 874, "evidence for constraints is passed explicitly". Could you
> clarify whether this evidence must exist at runtime or can be erased?
> One might hope that it can be erased, and that pack/unpack actually
> do nothing at runtime.
> 
> line 868, another way of asking the previous question is,
> why is the semantics of your language given by desugaring?
> Why isn't it given simply by a type- and constraint- erasure process?
> (Maybe lines 982-983 are part of the answer.)
> 
> line 1007, "the superclasses of a linear constraint are never expanded."
> A purely arbitrary choice?
> 
> line 1150, "Rust’s convenient syntax comes at the price that it is almost
> impossible to write tail-recursive functions." Can you explain this claim?
> Is it due to the syntax of Rust, or is it a consequence of its type system?
> 
> line 1168, "In exchange, neither Mezzo nor ats support O(1) freezing like in
> Section 4". The Mezzo paper by Balabonski et al. shows write-once references
> as an example (Figure 1). I suppose you mean "O(1) freezing of arbitrarily
> large data structures".
