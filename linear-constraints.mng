% -*- latex -*-

%if style == newcode
module LinearConstraints where

\begin{code}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE ConstraintKinds #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeOperators #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE MultiParamTypeClasses #-}

import Data.Kind (Constraint)
--import GHC.IO.Unsafe
import GHC.Base
\end{code}
%endif

\documentclass[acmsmall,review,natbib=false]{acmart}

\usepackage[backend=biber,citestyle=authoryear,style=alphabetic]{biblatex}
\bibliography{bibliography}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
  }
\usepackage[plain]{fancyref}
\usepackage{mathpartir}
\usepackage{newunicodechar}
\input{newunicodedefs}

%%%%%%%%%%%%%%%%% ott %%%%%%%%%%%%%%%%%

\usepackage[supertabular,implicitLineBreakHack]{ottalt}
\inputott{ott.tex}

%%%%%%%%%%%%%%%%% /ott %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% Workaround %%%%%%%%%%%%%%%%%

% This should be handled by the acmclass article, there are a couple
% of issues about
% this. https://github.com/borisveytsman/acmart/issues/271,
% https://github.com/borisveytsman/acmart/issues/327 . Both have been
% merged long ago, and the version of acmart in the shell.nix is from
% 2020.

%% \usepackage{fontspec}
%% \setmainfont{Linux Libertine O}
%% \setsansfont{Linux Biolinum O}
%% \setmonofont{inconsolata}

%%%%%%%%%%%%%%%%% /Workaround %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% lhs2tex %%%%%%%%%%%%%%%%%

\let\Bbbk\undefined    % see https://github.com/kosmikus/lhs2tex/issues/82
%include polycode.fmt
%if style == poly
%format ->. = "⊸"
%format =>. = "\Lolly"
%format .<= = "\RLolly"
%format IOL = "IO_L"
%format . = "."
%format exists = "\exists"
%format forall = "\forall"
%endif

%%%%%%%%%%%%%%%%% /lhs2tex %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      \setlength{\marginparwidth}{1.2cm} % A size that matches the new PACMPL format
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{{\color{blue}{#1}}}
      \newcommand{\note}[1]{{\color{blue}{\begin{itemize} \item {#1} \end{itemize}}}}
      \newenvironment{alt}{\color{red}}{}

      \newcommandx{\jp}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      
      \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
  \else
  %    \newcommand{\Red}[1]{#1}
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{#1}
      \newcommand{\note}[1]{}
      \newenvironment{alt}{}{}
  %    \renewcommand\todo[2]{}
      \newcommand{\unsure}[2]{}
      \newcommand{\info}[2]{}
      \newcommand{\change}[2]{}
      \newcommand{\inconsistent}[2]{}
      \newcommand{\critical}[2]{}
      \newcommand{\improvement}[1]{}
      \newcommand{\resolved}[2]{}
  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Domain-specific macros %%%%%%%%%%%%%%%%%

  \newcommand{\cscheme}[1]{\mathcal{#1}}
  \newcommand{\aand}{\mathop{\&}}
  \DeclareMathOperator*{\bigaand}{\vcenter{\hbox{\Large\&}}}
  \newcommand{\lollycirc}{\raisebox{-0.2ex}{\scalebox{1.4}{$\circ$}}}
  \newcommand{\Lolly}{\mathop{=\!\!\!{\lollycirc}}}
  \newcommand{\RLolly}{\mathop{\lollycirc\!\!\!=}}
  \newcommand{\subst}[2]{[#1]#2}
  \newcommand{\sby}[2]{#1 ↦ #2}
  \newcommand{\vdashi}{⊢_{\mathsf{i}}}
  \newcommand{\vdashs}{⊢_{\mathsf{s}}}

  % language keywords
  \newcommand{\keyword}[1]{\mathbf{#1}}
  \newcommand{\klet}{\keyword{let}}
  \newcommand{\kcase}{\keyword{case}}
  \newcommand{\kwith}{\keyword{with}}
  \newcommand{\kpack}{\keyword{pack}}
  \newcommand{\kunpack}{\keyword{unpack}}
  \newcommand{\kin}{\keyword{in}}
  \newcommand{\kof}{\keyword{of}}

%%%%%%%%%%%%%%%%% /Domain-specific macros %%%%%%%%%%%%%%%%%
\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  Paso, Texas USA} 
\acmYear{1997}
\copyrightyear{2016}

\acmPrice{15.00}

\begin{document}

\title{Linear Constraints}

\author{Jean-Philippe Bernardy, Richard Eisenberg, Csongor Kiss, Arnaud Spiwack}
\date{}

\maketitle

\section*{Introduction}
\info{There  is an Appendix section with unorganised thoughts and
  examples.}

\unsure{Not the actual beginning of the introduction}
Consider the following example from the Linear Haskell
article~\cite{LinearHaskell}, where |IOL| is the linear IO monad.
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { f <- openFile fp
      ; (f, Ur bs) <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

We see that linear types introduce some noise on the |readLine| line:
we need to destruct an extra pair, and an extra |Ur| (called
|Unrestricted| in~\cite{LinearHaskell}), compared to the
traditional (albeit less safe)\unsure{It only gets worse in larger
  program. This makes the extra safety afforded by linear types too
  rarely worth it.}
\begin{code}
firstLine :: FilePath -> IO Bytestring
firstLine fp =
  do  { f <- openFile fp
      ; bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

This extra noise is the consequence of the fact that, as far as a
linear type system is concerned, |f| is expended after |readLine
f|. But, of course, we typically want to do more with a file that
reading just one line of it, so the linear |readLine| is given the type.

\begin{code}
  readLine :: File ⊸ IOL (File, Unrestricted ByteString)
\end{code}

It appears to return a new file, but really, it returns a new name for
the same file. It really is these names which can only be used once,
the file handle itself continues to exist until |closeFile| is called.

This is a bit of a bother, though. Why do I have to manage a bunch of
names to help a compiler count? Surely this can be handled by the
typechecker automatically. And, indeed, compilers with \emph{ad hoc}
specialised logic let me write essentially the traditional program but
with the guarantee that if I forget to |closeFile|, I'll get a type
error. This is most notably the case of the
\textsc{ats}~\cite{AtsLinearViews}, and Mezzo
languages\unsure{Citation needed}.\unsure{Both \textsc{ats} and Mezzo
  are specialised in handling pointers-and-mutations, rather than
  file. So the sentence above is a little bit of a lie. Either
  rephrase to say that we can write programs of \emph{this type}, or
  use an array example instead of a file example. Though I think that
  the file example is a better introduction.}

\unsure{Maybe we want to hammer in the fact that, in Linear Haskell,
  there is no use case natively understood by the compiler. Every
  abstraction is built user-side. \textsc{Ats}'s views are closest to
  what we are doing, though seems to only be geared towards pointers.}
In this article we introduce a generic extension to Linear Haskell,
which lets the typechecker handle the counting. With this extension
|firstLine| would be written as:
\unsure{probably display |pack| in bold in Haskell code}
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { pack f <- openFile fp
      ; pack bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

There is a bit of boilerplate left, but it doesn't involve managing
names to please the compiler. This considerably lowers the cost of
using a linear-type based abstraction.\unsure{I'm trying to get at the
  cost/benefit analysis thing and how it matters a lot, but I haven't
  found a convincing way to do so without ranting for a page or so,
  I'll get back to this when the rest of the paper is written and I
  revisit the introduction.}

\paragraph{Contributions}
\unsure{TODO}

\newpage

\section{What it looks like}
\label{sec:what-it-looks-like}

\newpage

\section{Examples}
\label{sec:examples}


\newpage

\section{The declarative system}

\subsection{Constraint entailment relation}
See Fig 3, p14 of OutsideIn\cite{OutsideIn}.

For simplicity, and contrary to OutsideIn, we don't introduce a notion
of $\mathcal{Q}$ (toplevel axioms), because they don't interact in an
interesting way with linearity.

\unsure{Do we need a rule for $!$ here?}
\begin{displaymath}
  \begin{array}{l}
    [[Q ||- Q]] \\
    [[Q1 ||- Q2]] \text{ and } [[Q * Q2 ||- Q3]] \text{ then } [[Q1 * Q ||- Q3]] \\
    [[Q ||- Q1 * Q2]] \text{ then the exists } [[Q']] \text{ and } [[Q'']]
    \text{ such that } [[Q' ||- Q1]] \text{ and } [[Q'' ||- Q2]] \\
    [[Q1 ||- Q1]] \text{ and } [[Q2 ||- Q2]] \text{ then } [[Q1 * Q2 ||- Q1 * Q2]] \\
  \end{array}
\end{displaymath}
\unsure{Missing: $[[Q]]$ should be equal (up to reordering) to
  $[[Q' * Q'']]$ in the tensor splitting condition. Or, at least, some
  form of entailment relation. What precisely will be apparent in the
  proof of the inversion/uniformity lemma}

\newpage
\unsure{I [Arnaud] am currently thinking that we want to make a
  relation like this which extends the entailment to C-constraints. It
  would abstract over the actual solver and clarify proofs. It
  probably doesn't fit here, though.}
\drules[C]{$[[Q |- C]]$}
  {Generalised constraint entailment}
  {Dom,Tensor,With,Impl,Promotion}
\info{[Arnaud]: It's really more of a side remark, but there seems
  to be a connection with focusing here: if a combinator is
  ``asynchronous'' then it need not appear in $[[Q]]$ constraints
  whereas if the combinator is ``synchronous'', then it does.}


\newpage

\subsection{Declarative type system}
\label{sec:decl-type-syst}

\change{Based on
  \href{https://github.com/tweag/linear-constraints/issues/13}{\#13}.}
%
\jp{It's very important to explain in detail that linear constraints
  (as linear values) can never escape to omega contexts.
}

%
See Fig 10, p25 of OutsideIn\cite{OutsideIn}.

Main differences:
\begin{itemize}
\item Linearity as in the Linear Haskell paper
\item $\kcase$ doesn't have GADTs
\item Existential packs are our only GADT. They have a single
  constructor, pattern-matched over by $\kunpack$.

  (Consequently, we encode linear constraints inside data types as
  existential pack type.)\unsure{We may need a comment on the fact
    that $\kunpack$ doesn't have a $\pi$ index. There would be nothing
    wrong with it, I imagine, it's just a little bit useless.}

\end{itemize}
\improvement{We also want let with a signature. For the sake of completeness}

\drules[E]{$[[Q;G |- e : t]]$}{Expression
  typing}{Var,Abs,App,Pack,Unpack,Let,Case,Sub}

\info{No substitution on $[[Q1]]$ in the $\kunpack$ rule, because there is
  only existential quantification.}


\newpage

\section{$\klet$ should be generalised}

\unsure{In the current version of the system $\klet$ doesn't
  generalise. We may want to repurpose this argumentation as a
  discussion on possible refinement of the type system for
  convenience.}

The let rule infers a qualified type for the bound variable, by generalising
over all the linear constraints appearing in the bound expression. This is in
stark contrast with OutsideIn's strategy of inferring fully monomorphic types
for let expressions. So why not follow the established tradition and also infer
monomorphic types when linear constraints are involved? Since the let binder is
unrestricted, the variable $x$ may be used multiple times (or none at all). This
means that the let \emph{must not consume any linear constraints}. \change{which
means that if we also add linear lets to the language, then those can consume
linear constraints. But I (Csongor) don't think linear lets will be necessary?}

To illustrate the practical necessity of the let generalisation strategy,
consider the following file handling API:

\begin{code}
newFile :: IO (exists f. File f .<= Open f)
writeFile :: Open f =>. File f -> String -> IO (() .<= Open f)
closeFile :: Open f =>. File f -> IO ()
\end{code}

The |newFile| function creates a file and returns a file handle |File f|,
together with a linear constraint witnessing that the file |f| is open (note
that |f| is existentially quantified). |writeFile| writes a string to an open
file and keeps it open. Finally, |closeFile| closes the file and consumes the
|Open f| constraint.

Now consider the following program:

\begin{code}
readBad :: IO ()
readBad = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  return ()
\end{code}

This program creates a new file, writes the string |"hello"| to it, then
returns. Even though the |closeFile file| action is assigned to a variable, the
action itself is never invoked, and the file remains open. The fixed version
follows:

\begin{code}
readGood :: IO ()
readGood = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  x
\end{code}

Here, |x| is actually executed, thus the file is closed before the function
returns. The type of |x| in both cases is |Open f0 =>. IO ()| (with |f0| the
existential variable created by |newFile|). Happily, |readBad| gets rejected
because the |Open f0| constraint doesn't get consumed before the function returns.

Unlike traditional let-generalisation, this behaviour can not be overridden with
a signature, so writing |x :: IO ()| is rejected. \change{We don't have a rule
for let with a signature yet, but it will have to be this way.}

\subsection{Comparison with OutsideIn}

So far we have argued that linear constraints should be quantified over in let
bindings. But how does this fit into the OutsideIn constraint solver, the type
inference framework employed by GHC?  In~\cite{OutsideIn}, the authors carefully
consider various different generalisation strategies, each with different
tradeoffs, before reaching the conclusion that no generalisation is the most
ergonomic option.

Here is a summary of the different criteria:

\begin{description}
  \item[Equalities]
        OutsideIn never generalises over equality constraints. Doing
        so would result in very large constraints, resulting in ergonomic and
        performance penalties. In our system, equality constraints are always
        unrestricted, so the issues around consumption explained above do not
        apply to them. Thus, there is no need to generalise over equality
        constraints in our system.
  \item[Class constraints]
        OutsideIn never generalises over class constraints. A downside of
        generalising is that type errors are delayed to call sites when a
        constraint can not be solved. In the case of linear constraints, this is
        the desired behaviour, since whether the constraint can be solved depends
        on whether it is available at the call site, which might differ from
        whether it is available at the definition site.
  \item[Type variables]
        OutsideIn makes the observation that if a type variable is generalised,
        then so must be all the constraints that mention that variable (otherwise
        principal types are lost). Because constraints are not generalised, the
        algorithm opts to also not generalise type variables. A possibility not
        considered in~\cite{OutsideIn} is generalising only the constraint, but
        not the type variables mentioned in it. This is the path we take: type
        variables are not quantified over, but (linear) constraints are. This is
        a sensible option in our setting because it still allows deferring
        constraint solving to use sites, without deviating too much from GHC's
        existing strategy.
\end{description}

To summarise, the generalisation strategy in let bindings is to always
generalise over linear constraints, but keep type variables monomorphic and never
quantify over nonlinear constraints (which includes all equality constraints).
This is a conservative extension of OutsideIn.

\subsection{Maybe we need to be more careful?}

As I (Csongor) wrote the above example, I realised that the example API might
not be sufficient. For example,

\begin{code}
readBad2 = do
  file <- newFile
  writeFile file "hello"
  const (return ()) (closeFile file)
\end{code}

here the file handle is not closed, but according to the App rule, the |Open f0|
constrant is consumed by the application to |const|. The issue here is that we
want to actually ensure that |closeFile| gets \emph{executed}, so maybe a better
interface would be

\begin{code}
newFile :: IO (exists f. File f .<= Open f)
writeFile :: File f -> String -> IO (Open f =>. () .<= Open f)
closeFile :: File f -> IO (Open f =>. ())
\end{code}

is there any other way to fix it? Maybe a linear constraint is only consumed in
an application to a linear function?\info{Arnaud: yes! consuming a
  linear constraints in a non-linear operation should be a type error,
  otherwise linear constraints would be unsound.}

\newpage

\section{Constraint generation}

See Fig.13, p39 of OutsideIn~\cite{OutsideIn} \unsure{Todo: syntax to
  select the $\pi$ in case, linear $\kunpack$ rule}

In a full blown Haskell with linear constraints, there wouldn't be
linear equality constraints.\jp{Seems to suggest that we have linear
  equality constraints here? [Arnaud]: my poor phrasing, I meant to
  imply that we didn't have any equality constraints at all.}
That is, $a \sim b$\unsure{this notation
  hasn't been introduced, so if it makes the cut explain where it
  comes from} wouldn't appear to the left of a linear fat arrow. It's
not that linear equalities don't make sense, see for
instance~\cite{shulman2018linear} for a system which takes linear
equality seriously. However, the usual unification algorithms are
unsound for linear equalities, because they will gladly use the same
equality many times (or none-at-all). Haskell could, by some arbitrary
mean, reject equality constraints to the left of a linear fat arrow,
or it could simply refuse to do any solving with such equalities.

While it is possible that a future version of Haskell includes linear
equality constraints, automatic resolution of linear equality
constraints is beyond the scope of this article. Nor is it needed,
or even useful, for our use cases.
%
Thus, in general, no linear constraint can be used in, or influence in
any way, the unification of type meta variables to types.  As a
consequence, linear
%
constraints are fully orthogonal to type inference. Therefore, the
syntax-directed constraint generation system presented in this section
can legitimately assume that type inference is solved elsewhere;
contrary to~\cite{OutsideIn}, where type inference is mixed with
constraint generation. This separation of concern simplifies the
presentation significantly.\unsure{This paragraph is more wordy than
  it is clear, so let's not take it as an actual proposal for the
  explanation, I [Arnaud] merely wanted to record my thoughts}

\unsure{Todo: the rule for a constraint-generalising signatureless
  let}
\improvement{We also want let with a signature. There are two rules in
  OutsideIn: when the signature is monomorphic, and when it's
  polymorphic. Maybe we don't care about this distinction all that
  much.}
\unsure{The case rule, for an empty case, implies the existence of the
  typically annoying $⊤$. We will have to confront this.}
\unsure{We probably want the freshness condition on the $\kunpack$
  rule, though these variables are universal variables, not
  existentials.}
\info{Not caring about inferences simplifies $\kpack$ quite a bit, we
  are using the pseudo-inferred type to generate constraint. In a real
  system, we would need $\kpack$ to know its type (\emph{e.g.} using
  bidirectional type checking).}
\unsure{The case rule should have constructors with fields with
  varying multiplicities}
\drules[G]{$[[G |-> e : t ~> C]]$}{Constraint generation}{Var, Abs,
  App, Case, Unpack, Pack}

\jp{In the case rule, the sum is a bit confusing. It may just work with
  linear haskell, but Morally it is a union (or with), perhaps this should be written so for symmetry with what happens with constraints?}
\jp{In the case rule, the letter e is used twice; this is confusing.}
\jp{In G-Unpack, the use of ⊃ is confusing (it's not a superset, but rather a linear implication?). }

\newpage

\subsection{Soundness of constraint generation}
\label{sec:constraint-generation-soundness}

If we can type a term and generate constraints ($[[G |-> e : t ~> C]]$), and
these constraints are solvable using $[[Q]]$ with no leftover,
($[[Q |-s C ~> 1;1]]$), then we can type it in the declarative system
($[[Q;G |- e : t]]$).\unsure{In fact, do we have to bring the
  simplifier here? Can we instead use the constraint entailment
  relation and show separately that the simplifier is sound for
  constraint entailment? [arnaud]: entailment doesn't understand
  $[[C]]$ constraints. However, I agree with the sentiment, and I've
  been considering introducing an extended entailment for $[[C]]$
  constraints rather than deal with the more algorithmic system.}

\begin{lemma}
  \label{lem:inversion}
  \begin{itemize}
  \item If $[[Q |-s C1*C2 ~> Q_o;Q_r]]$ then there exists $[[Q_o']]$,
    $[[Q_r']]$, $[[Q_r'']]$ such that
    \begin{itemize}
    \item $[[Q |-s C1 ~> Q_o';Q_r']]$
    \item $[[Q_o' |-s C2 ~> Q_o;Q_r'']]$
    \item $[[Q_r]] = [[Q_r' * Q_r'']]$\unsure{I'm not sure this last
        one is quite the correct criterion. In that we may want an
        equivalence rather than an equality.}
    \end{itemize}
  \item If $[[Q |-s pi.C ~> Q_o;Q_r]]$ then there exists $[[Q']]$,
    $[[Q_o']]$, $[[Q_r']]$, such that
    \begin{itemize}
    \item $[[Q' |-s C ~> Q_o'; Q_r']]$
    \item $[[Q]] = [[pi.Q']]$
    \item $[[Q_o]] = [[pi.Q_o']]$\unsure{This is almost certainly
        wrong. Which pleads for defining the inversion lemma on a less
        algorithmic relation}
    \item $[[Q_r]] = [[pi.Q_r']]$\unsure{Again, these equality
        probably want to be equivalences}
    \end{itemize}
  \end{itemize}
\end{lemma}
\unsure{I want to reformulate these lemmas in terms of the logical
  entailment relation. I think they correspond to the uniform proof
  story from~\cite{hh-ll}, namely, any provable sequent with a
  non-atomic right-hand side can be proved with a right introduction
  rule. There is a bit of complication here due to the domain-specific
  entailment but the decomposability requirement should give us the
  same result.}

\newpage

\begin{lemma}
  For all $[[Q_g]]$ if
  \begin{itemize}
  \item $[[G |-> e : t ~> C]]$
  \item $[[Q_g |-s C ~> Q_o;Q_r]]$
  \end{itemize}
  then there exists $[[Q]]$ such that
  \begin{itemize}
  \item $[[Q_g*Q_r ||- Q*Q_o]]$\unsure{$[[Q_r]]$ are the residuals,
      like in InsideOut, that is, the wanted which remain to be
      proved. $[[Q_o]]$ are due to linearity, and are the given which
      remain to be used.}
  \item $[[Q; G |- e : t]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  \unsure{The proof is a sketch}
  \unsure{The proof needs to be corrected for the fixed Lemma~\ref{lem:inversion}}
  By induction on $[[G |-> e : t ~> C]]$
  \begin{description}
  \item[App] \info{Most of the linearity problems are here}
    We have
    \begin{itemize}
    \item $[[G1+pi.G2 |-> e1 e2 : t ~> C1 * pi.C2]]$
    \item $[[Q_g |-s C1 * pi.C2 ~> Q_o;Q_r]]$
    \item $[[G1 |-> e1 : t2 ->_pi t ~> C1]]$
    \item $[[G2 |-> e2 : t2 ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exists $[[Q_o']]$, $[[Q_r']]$,
    $[[Q_o'']]$, $[[Q_o''']]$, $[[Q_r'']]$ such that
    \begin{itemize}
    \item $[[Q_g |-s C1 ~> Q_o';Q_r']]$
    \item $[[Q_o'' |-s C2 ~> Q_o''';Q_r'' ]]$
    \item $[[Q_o']] = [[pi.Q_o'']]$
    \item $[[Q_o]] = [[pi.Q_o''']]$
    \item $[[Q_r]] = [[Q_r' * pi.Q_r'']]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item There exists $[[Q1]]$ such that
      \begin{itemize}
      \item $[[Q_g*Q_r' ||- Q_1*Q_o']]$
      \item $[[Q1; G1 |- e1 : t2 ->_pi t]]$
      \end{itemize}
    \item There exists\ldots\unsure{unfinished, but straightforward}
    \end{itemize}
  \item[Unpack] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> unpack x = e1 in e2 : t ~> pi.C1 * Q1 => C2]]$
    \item $[[Q_g |-s pi.C1 * Q1 => C2 ~> Q_o;Q_r]]$
    \item $[[G1 |-> e1 : exists as. t1 o= Q1 ~> C1]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item There exists $[[Q]]$ such that\unsure{Something about
        residuals and outputs} and $[[Q; G1 |- e1 : exists as. t1 o=
      Q1]]$
    \item There exists $[[Q']]$ such that \unsure{Again residuals and
        outputs} and $[[Q' ; G2, x:_pi t1 |- e2 : t]]$
    \end{itemize}
    Therefore \unsure{The condition about residuals and outputs and
      extensions} and $[[pi.Q * Q' ; pi.G1 + G2 |- unpack x = e1 in e2
    : t]]$
  \item[Case] \unsure{Arnaud: will I be able to avoid a $\aand$ constraint
     or not? I'm guessing not.}
  \end{description}
\end{proof}

\newpage

\section{Constraint solver}
\label{sec:constraint-solver}
$[[Q_g |-s C ~> Q_o;Q_r]]$

Correctness property: $[[Q_g * Q_r |- C * Q_o]]$.\unsure{We would
  typically have $[[Q_o]]⊆[[Q_g]]$, but does it matter? Actually, I'm
  [Arnaud] tempted to posit that this wouldn't always hold for
  GHC. Indeed, GHC rewrites givens, therefore, $[[Q_o]]$ may have
  extra formula or rewritten formulas which are not actually in
  $[[Q_g]]$.}

Various recipes are given
by~\textcite{resource-management-for-ll-proof-search}.
\info{The first presentation of returning output context that I could
  find is~\cite{hh-ll}, but I
  find~\cite{resource-management-for-ll-proof-search} more
  informative.}
These recipes are phrased in a way which implies goal oriented
proof search, but they can be adapted \emph{mutatis mutandis} to GHC's
backtrackingless rewrite-based search.

The key points are
\begin{itemize}
\item Each rule return the remaining, unused (linear) hypotheses: the
  \emph{leftovers}.
\item To deal with $⊤$, remember that you've encountered a $⊤$ in a
  different branch. And let you spend any leftover back into a
  previous $⊤$
\item In~\cite{resource-management-for-ll-proof-search}, there is a
  third input context ($Ξ$), which represents a context which need to
  be used, and cannot be returned as leftovers. However, this is used
  to fail earlier in backtracking branches which are doomed to
  fail. It doesn't apply to our backtrackingless
  setting\unsure{[Arnaud]: I think.}
\end{itemize}

We can do pretty much like in OutsideIn: split the constraint between
flat constraints and non-flat constraints if we wish (but, this time,
non-flat constraint include $\aand$! so there will be significantly
more of them). Apply synchronous rules on non-flat constraint to retrieve flat
constraint, call the simplifier on them.

To be honest, we can even do one atomic constraint at a time, given
that we have no equality, hence our wanted can't interact (I [Arnaud]
think) but the details don't matter terribly.

\newpage

\section{Desugaring}
\label{sec:desugaring}

\info{The plan is to give the operational semantics in the form
  of a desugaring to the core calculus of the Linear Haskell paper.}


\info{
  On unicity of tokens:

  A constraint like ``Open'' (no argument), does not make much sense
  to use as a linear constraint. Because if we can make it once, then
  we can make it omega times, and it's useless (it's similar to linear
  constants in linear haskell. They were not supported.)

  So, we're using something like ``Open f'' instead. Together with a
  an existential variable f. Then the API can ensure that there is a
  single token for this constraint at any given point. The API can
  however create several copies --- but then it's up to the API to
  make sure that the order of picking the constraints is
  computationally irrelevant. (Label constraints as computationally
  relevant? Then GHC could issue errors if there is computational
  relevance and it ends up making a choice.)

  [arnaud] maybe reject all programs which force the constraint solver
  to make an ordering choice
  
  [jp] still worried about the order of treating arguments: if we have
  writeFile f x >> writeFile f y then the arguments of could be
  handled in any order (for constraints!), and it's a shame to reject
  this.

  [arnaud] I don't think so, because in this case, writeFile f y is
  forced to use the most nested evidence, which is that given by
  writeFile f x
  
}

Goal: describe transformations
\begin{enumerate}
\item Constraint generator + solver $\leadsto$ declarative
  system\unsure{My [Arnaud's] guess is that the main difficulty, here,
  will be to deal with $⊤$ and its effect at a distance}
\item declarative system $\leadsto$ $λ^q$\info{Really, this is just
    evidence passing style. If the declarative system is well written,
    it will be quite direct.}
\end{enumerate}

\newpage

\section{Extensions}
\begin{itemize}
\item Like there are implicational and universally-quantified
  constraints in the left-hand side of fat arrows, we may want to have
  $\aand$ constraints on the left hand side of (linear) fat
  arrows. This falls in the Linear Hereditary Harrop fragment
  described, for instance, in~\cite{hh-ll}
  and~\cite{resource-management-for-ll-proof-search}. Hereditary
  Harrop is a natural extension of Horn clauses in proof search
  algorithms.
\end{itemize}

\appendix

\section{Preamble from Csongor}

\begin{spec}
data a .<= c where
  Pack :: c =>. a -> a .<= c
data IOL c a = IOL {runIOL :: RealWorld -> (RealWorld, a .<= c)}
\end{spec}

If we bake the constraint into |IOL|, then we need to change \emph{both} |c| and |a|:
\begin{spec}
(>>=) :: IOL c a -> (c =>. a -> IOL d b) -> IOL d b
io_a >>= f = IOL $ \rw -> case runIOL io_a rw of
                            (rw', Pack a) -> runIOL (f a) rw'
\end{spec}

% $ emacs

\section{Arnaud's motivating examples}

\subsection{Linear IO without the hassle (file handles)}

In Linear Haskell~\cite{LinearHaskell}

\begin{spec}
readTwoLines path = do
  h0 <- openFile path
  (h1, line1) <- readLine h0
  (h2, line2) <- readLine h1
  close h2
\end{spec}
API:
\begin{spec}
openFile  :: FilePath -> IOL Handle
close     :: Handle ⊸ IOL ()
readLine  :: Handle ⊸ IOL (Handle, String)
\end{spec}
With linear constraints, API:
\begin{spec}
openFile  :: FilePath -> IOL (Handle h .<= Open h)
close     :: Open h =>. Handle h -> IOL ()
readLine  :: Open h =>. Handle h -> IOL (String .<= Open h)
\end{spec}
The example become (remark: not the do-notation for the |IO| monad):
\begin{spec}
readTwoLines path = do
  h <- openFile path
  line1 <- readLine h
  line2 <- readLine h
  close h
\end{spec}

It looks exactly the same as without linear types. But you still get
an error for double-free and use-after-free usages.

\subsection{Ownership and so on…}

From the linear types paper:

\begin{spec}
  newMArray    :: (MArray a ⊸ Unrestricted b) ⊸ Unrestricted b
  writeMArray  :: MArray a ⊸ Int -> a -> MArray a
  freeze       :: MArray a ⊸ Unrestricted (Array a)
  readArray    :: Array a -> Int -> a
\end{spec}

In |writeArray|: we insert an unrestricted element |a ->|. Otherwise
we could do a linear type taboo:

\begin{spec}
unrestrict :: a ⊸ Unrestricted a
unrestrict x = case unrestrictArray x of
  Unrestricted arr -> readArray 0

unrestrictArray :: a ⊸ Unrestricted (Array a)
unrestrictArray x = newArray $ \marr ->
  freeze $
  writeMArray 0 x marr
\end{spec} % emacs <- syntax highlighting bug

This is not ok if I want to make a multidimensional array (say an
|MArray (MArray a)|), which I would later freeze.

How could freeze look like for that use-case?

Something like

\begin{spec}
  freeze :: MArray a ⊸ (a ⊸ Unrestricted b) -> Unrestricted (Array b)
\end{spec}

But this is no longer $O(1)$ unless the compiler has special support
(like |Coercible|~\cite{citation_needed}).

The crux of the issue is that mutable arrays and immutable arrays have
distinct types, which me must convert.

Contrast with Rust, where there is a single type \verb+Vector+, and
freezing is simply
\verb+fn (vect : Vector<a>) : Rc<Vector<a>> -> { Rc<vect> }+ (check
syntax).

With linear constraints:

\begin{spec}
-- Each reference has 3 linear capabilities associated with it. References can be freely copied, but the capabilities are controlled linearly.

-- The relation between references and capabilities is mediated with an existential type variable (of kind Token for legibility here, but we can let Token = Type with no loss of expressivity.)

kind Token
class Read (n :: Token)    -- read capability
class Write (n :: Token)   -- write capability
class Own (n :: Token)     -- move, free,

type O n = (Read n, Write n, Own n) -- but we cannot move unless no one has kept a reference, so really all 3 capabilities are needed. We never use Own alone, always O.

type RW n = (Read n, Write n) -- likewise, one cannot be writing unless we also have read access (so that a reader does not see changes happening while it is reading)

type ReferenceKind = Token -> Type -- kind of types which are associated to capabilities via tokens (so ``references'')

data PArray (a :: Token -> Type) (n :: Token)
  -- QUESTIONS: is this an array of References? Is it a boxed array or unboxed array? Are all references inside it associated with the same token?

type Array a = Frozen (PArray a)


data Frozen a where
  Freezed :: Read n => a n -> Frozen a
data Reading a where
  Read :: Read n =>. a n -> Reading a
data Borrowed a where
  Borrow :: RW n =>. a n -> Borrowed a
data Owned (a :: * -> *) where
  Move :: O n =>. a n -> Owned a


newPArray    :: (forall n. O n =>. PArray a n -> Unrestricted b) ⊸ Unrestricted b
-- Create a new array with the 3 capabilities available (|O n|).

writePArray  :: (RW n, O p) =>. PArray a n -> Int -> a p -> Owned a .<= RW n
  -- Relinquishes the ownership of the |a p| argument. Returns
  -- ownership of the old value.
  -- iiuc: The reference p is moved inside the array (if we'd make a copy we don't need the O p capability). So we make a new token for it (existentially quantified by Owned).
  -- ? With this interface it seems that the owner will be able to freeze the array, but the reference will survive. So it seems that there is a bug here.

writePArrayAlt  :: (RW n, O p) =>. PArray a n -> Int -> a p -> () .<= (RW n)
-- here the ownership of |a p| is absorbed by n.
-- Operational semantics: move the p *reference* inside n.

readPArray   :: Read n =>. PArray a n -> Int -> a n .<= Read n
-- OK

borrowPArray :: RW n =>. Parray a n -> Int -> (Borrowed a ⊸ Unrestricted b) ⊸ Unrestricted b .<= RW n
-- I don't think that this is necessary, the linear constraints should be threaded correctly with the generic mechanism to any function which demands the RW capability.

freeze       :: O n =>. PArray a n -> Array a
-- OK

readArray :: Array a -> Int -> Frozen a
readArray (Freezed arr) i = Freezed (readPArray arr i)
\end{spec}


\printbibliography

\end{document}

% LocalWords:  sequent typechecker
