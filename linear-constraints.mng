% -*- latex -*-

%if style == newcode
module LinearConstraints where

\begin{code}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE ConstraintKinds #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeOperators #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE MultiParamTypeClasses #-}

import Data.Kind (Constraint)
--import GHC.IO.Unsafe
import GHC.Base
\end{code}
%endif

\documentclass{jfp}
% \settopmatter{printacmref=false,printfolios=true}

% \usepackage[backend=biber,citestyle=authoryear,style=alphabetic]{biblatex}
% \usepackage[backend=biber,datamodel=acmdatamodel, style=acmauthoryear,uniquename=false]{biblatex}
% \addbibresource{bibliography.bib}

\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
  }
% \usepackage[plain]{fancyref}
\usepackage[capitalize]{cleveref}
\usepackage{mathpartir}
\usepackage{newunicodechar}
\input{newunicodedefs}

%%%%%%%%%%%%%%%%% ott %%%%%%%%%%%%%%%%%

\usepackage[supertabular,implicitLineBreakHack]{ottalt}
\inputott{ott.tex}

%%%%%%%%%%%%%%%%% /ott %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% lhs2tex %%%%%%%%%%%%%%%%%

\let\Bbbk\undefined    % see https://github.com/kosmikus/lhs2tex/issues/82
%include polycode.fmt
%if style == poly
%format a_i = "\Varid a \ensuremath{_i}"
%format a_j = "\Varid a \ensuremath{_j}"
%format ->. = "⊸"
%format => = "\FatArrow "
%format =>. = "\Lolly "
%format poly_arrow = "\mathop{\to_{\multiplicityfont{m}}}"
%format .<= = "\RLolly"
%format <== = "\RFatArrow"
%format omega = "\omega"
%format IOL = "IO_L"
%format . = "."
%format exists = "\exists"
%format forall = "\forall"
%format pack x = "\packbox" x
%format pack' = "\kpack!"
%format Unique = "\constraintfont{" Linearly "}"
%format unique = linearly
%format constraint (c) = "\constraintfont{" c "}"
%format multiplicity (p) = "\multiplicityfont{" p "}"
%
%format a1
%format a_n
%format an = a_n
%format ^^ = "\,"
%format e1
%format e2
%
%format ! = "!"
  %% ^^ this suppresses some space. I think lhs2TeX would otherwise use \mathop
%format spack = "!\kpack"
%format (at n) = "{@}" n
%format phantom x = "\phantom{" x "}"
%endif

%let full = False

%%%%%%%%%%%%%%%%% /lhs2tex %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  % TOGGLE ME to turn off all the commentary:
  \InputIfFileExists{no-editing-marks}{
    \def\noeditingmarks{}
  }

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      \setlength{\marginparwidth}{2cm} % A size that matches the new JFP format
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{{\color{blue}{#1}}}
      \newcommand{\note}[1]{{\color{blue}{\begin{itemize} \item {#1} \end{itemize}}}}
      \newenvironment{alt}{\color{red}}{}

      \newcommandx{\jp}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommandx{\csongor}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=purple,#1]{#2}}
      \newcommandx{\rae}[2][1=]{\todo[linecolor=magenta,backgroundcolor=magenta!25,bordercolor=magenta,#1]{RAE: #2}}
      \newcommandx{\nw}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{NW: #2}}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
  \else
  %    \newcommand{\Red}[1]{#1}
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{#1}
      \newcommand{\note}[1]{}
      \newenvironment{alt}{}{}
  %    \renewcommand\todo[2]{}
      \newcommand{\unsure}[2][1=]{}
      \newcommand{\info}[2][1=]{}
      \newcommand{\change}[2]{}
      \newcommand{\inconsistent}[2]{}
      \newcommand{\critical}[2]{}
      \newcommand{\improvement}[1]{}
      \newcommand{\resolved}[2]{}

      \newcommand{\csongor}[2][1=]{}
      \newcommand{\jp}[2][1=]{}
      \newcommandx{\rae}[2][1=]{}
      \newcommandx{\nw}[2][1=]{}
  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Domain-specific macros %%%%%%%%%%%%%%%%%

  % Fonts and colours
  \newcommand{\constraintcolour}{\color{RoyalBlue}}
  \newcommand{\constraintfont}[1]{{\constraintcolour#1}}
  \newcommand{\multiplicitycolour}{\color{RoyalBlue}}
  \newcommand{\multiplicityfont}[1]{{\multiplicitycolour#1}}

  % Utilities
  \newcommand{\revop}[1]{\mathop{\reflectbox{\ensuremath{#1}}}}

  % Notations
  \newcommand{\cscheme}[1]{\mathcal{#1}}
  \newcommand{\rlolly}{\mathop{\revop{\multimap}}}
  \newcommand{\subst}[2]{[#1]#2}
  \newcommand{\sby}[2]{#1 ↦ #2}
  % \newcommand{\vdashi}{⊢_{\mathsf{i}}}
  \newcommand{\vdashi}{%
      \mathrel{%
          \vdash\hspace*{-4pt}%
          \raisebox{0.9pt}{\scalebox{.66}{\(\blacktriangleright\)}}%
      }%
  }
  \newcommand{\vdashs}{⊢_{\mathsf{s}}}
  \newcommand{\vdashd}{⊢_{\mathsf{diff}}}
  \newcommand{\vdashsimp}{⊢_{\mathsf{s}}^{\mathsf{a}}}
  \newcommand{\scale}{\constraintfont{\cdot}}
  %% Constraint notations
  \newcommand{\constraintop}[1]{\mathop{\constraintfont{#1}}}
  \newcommand{\aand}{\constraintop{\&}}
  \DeclareMathOperator*{\bigaand}{\vcenter{\hbox{\Large\&}}}
  \newcommand{\lollycirc}{\raisebox{-0.255ex}{\scalebox{1.4}{$\circ$}}}
  \newcommand{\Lolly}{\constraintop{=\kern-0.9ex \lollycirc}}
  \newcommand{\FatArrow}{\constraintop{\Rightarrow}}
  \newcommand{\RLolly}{\mathop{\constraintfont \circledless}}
  \newcommand{\RFatArrow}{\constraintop{\rtimes}}
  \newcommand{\qtensor}{\constraintop{\otimes}}
  %% Desugarer notations
  \newcommand{\dsterm}[2]{\llbracket #2 \rrbracket_{#1}}
  \newcommand{\dstype}[1]{\llbracket #1 \rrbracket}
  \newcommand{\dsevidence}[1]{\llbracket #1 \rrbracket^{\mathbf{ev}}}

  % language keywords
  \newcommand{\keyword}[1]{\mathbf{#1}}
  \newcommand{\klet}{\keyword{let}}
  \newcommand{\kcase}{\keyword{case}}
  \newcommand{\kwith}{\keyword{with}}
  % \newcommand{\packbox}{\square}
  \newcommand{\packbox}{\raisebox{-0.08ex}{\scalebox{0.88}{$\square$}}}
  \newcommand{\kin}{\keyword{in}}
  \newcommand{\kof}{\keyword{of}}
  %% Pseudo-keywords for use in text
  \newcommand{\kunpack}{\klet\packbox}

  % defining grammars
  \newcommand{\bnfeq}{\mathrel{\Coloneqq}}
  \newcommand{\bnfor}{\mathrel{\mid}}

  % theorems
  \newtheorem{theorem}{Theorem}[section]
  \newtheorem{lemma}[theorem]{Lemma}
  \newtheorem{corollary}[theorem]{Corollary}
  \newtheorem{property}[theorem]{Property}

  \newtheorem{definition}[theorem]{Definition}

\begin{document}

\journaltitle{JFP} % What's the correct value here?
\cpr{The Author(s),} % What's the correct value here?
\jnlDoiYr{2025}
\doival{10.1017/xxxxx} % dummy value

\title{Linearly Qualified Types: Generic Inference for Capabilities and Uniqueness}
\righttitle{Linearly Qualified Types: Generic Inference for Capabilities and Uniqueness}

\begin{authgrp}
\author{Arnaud Spiwack}
\affiliation{Tweag, Paris, France
  \email{arnaud.spiwack@@tweag.io}
}
\author{Csongor Kiss}
\affiliation{Independent,
  \email{kiss.csongor.kiss@@gmail.com}
}
\author{Jean-Philippe Bernardy}
\affiliation{University of Gothenburg, Gothenburg, Sweden
  \email{jean-philippe.bernardy@@gu.se}
}
\author{Nicolas Wu}
\affiliation{Imperial College London, London, United Kingdom
  \email{n.wu@@imperial.ac.uk}
}
\author{Richard A.~Eisenberg}
\affiliation{Tweag, Paris, France\footnote{Since working on this paper, Richard
    Eisenberg's affiliation has changed to Jane Street, USA}
  \email{rae@@richarde.dev}
}
\end{authgrp}
% I don't know why this isn't computed automatically
\lefttitle{A. Spiwack, C. Kiss, J.-P. Bernardy, N. Wu, R. A.~Eisenberg}

% \begin{keywords}
%   GHC, Haskell, linear logic, linear types, constraints, qualified types,
%   inference
% \end{keywords}

\begin{abstract}
  A linear parameter must be consumed exactly once in the body of its
  function. When declaring resources such as file handles and manually
  managed memory as linear arguments, a linear type system can verify
  that these resources are used safely.
  However, writing code with explicit linear arguments requires bureaucracy.
  %
  This paper presents \emph{linear constraints}, a front-end feature for
  linear typing that
  decreases the bureaucracy of working with linear types.
  %
  Linear constraints are implicit linear arguments that are
  filled in automatically by the compiler.
  %
  We present linear constraints as a qualified type system,
  together with an inference algorithm which extends
  \textsc{ghc}'s existing constraint solver algorithm. Soundness of
  linear constraints is ensured by the fact that they desugar into
  Linear Haskell.
\end{abstract}

\maketitle

% The full names fit on a line. As per the author instructions, we
% don't need to shorten the authors' names.
% \renewcommand{\shortauthors}{Bernardy, Eisenberg, Kiss, Spiwack, Wu}
\newcommand{\maybesmall}{\small}

\section{Introduction}
\label{sec:introduction}

Linear type systems have seen a renaissance in recent years in
various programming communities. Rust's ownership system guarantees
memory safety for systems programmers, Haskell's \textsc{ghc}~9.0 includes
support for linear types, and even
dependently typed programmers can now use linear types with Idris 2.
All of these systems are vastly different in ergonomics and
scope. Rust uses dedicated syntax and code generation
to support management of resources, while Linear Haskell is a
type system change without requiring any other impact on the compiler, such as in the
code generator or runtime system.\rae{But actually we'd \emph{like} to have
an impact on the runtime system to allow update-in-place.} Linear Haskell
is designed to be general purpose, but
using its linear arguments to emulate Rust's ownership model is a tedious exercise. It
requires
% the compiler doesn't know how to help, requiring
the programmer to carefully thread resource tokens.
\nw{Maybe a comment about why we want this in the first place? Some positive adjective about
Rust's model would be enough.}

To get a sense of the power and the tedium of programming with linear types, consider the
following function:
\begin{code}
read2AndDiscard :: MArray a ->. (Ur a, Ur a)
read2AndDiscard arr0 =
  let  (arr1, x)  = read arr0 0
       (arr2, y)  = read arr1 1
       ()         = free arr2
  in (x, y)
\end{code}
This function reads the first two elements of an array and returns them after
deallocating the array.
Linearity enables the array library to ensure that there is only one reference
to the array, and therefore it can be mutated in-place without violating
referential transparency. Let us stress that this uniqueness property
is an invariant of the array library, not an intrinsic property of
linear functions.

After the array has been freed, it is no longer
possible to read or write to it.
%
Notice that the |read| function consumes the array and returns a
fresh array, to be used in future operations. Operationally, the array remains
the same, but each operation assigns a new name to it, thus facilitating tracking
references statically. Finally, |free| consumes the array without returning a
new one, statically guaranteeing that it can no longer be used.
The values |x| and |y| read from the array are returned; their
types include elements wrapped by the |Ur|
(pronounced ``unrestricted'',  and corresponding to the
``!'' operator of \citet{girard-linear-logic}) type, allowing them to be used
arbitrarily many times. This works because |read2AndDiscard| takes a restricted-use array
containing unrestricted elements.
%
In a non-linear language, one would have to forgo referential transparency to
handle mutable operations either by using a monadic interface or allowing
arbitrary effects.
Compare the above function with what one would write in a non-linear, impure
language:
\begin{code}
read2AndDiscard :: MArray a -> (a, a)
read2AndDiscard arr =
  let   x    = read arr 0
        y    = read arr 1
        ()   = unsafeFree arr
  in (x, y)
\end{code}
This non-linear version does not guarantee that there is a unique reference to
the array, so freeing the array is a potentially unsafe operation.
However, it is simpler because there is less bureaucracy to manage: we are
clearly interacting with the \emph{same} array throughout, and this version makes
that apparent.
We see here a clear tension between extra safety and clarity of code---one
we wish, as language designers, to avoid. %%  When
%% modelling a handle as a linear resource, the type system must know at all
%% times where it is being consumed, so the file handle is passed around
%% manually, resulting in extra noise.
%
% Reading the non-linear version, it is clear that it keeps a single reference to
% the array.
How can we get the compiler to see that the array is used safely
without explicit threading?

%% Rust introduces the \emph{borrow checker} for this very purpose. % seems out of place when referring to 1999 ideas.
Following well-known ideas~\citep{DBLP:conf/popl/CraryWM99,DBLP:conf/esop/SmithWM00,DBLP:conf/tic/WalkerM00}, our approach is to let arrays be unrestricted, but
associate linear capabilities (such as |constraint(Read)|, |constraint(Write)|) to them.
In fact, we show in this paper that such linear capabilities
are the natural analogue of Haskell's type class
constraints to the setting of linear types.
We call these new constraints \emph{linear constraints}.
Like class constraints,
linear constraints are propagated implicitly by the compiler.
Like linear arguments, they can safely be used to track resources such as arrays
or file handles. Thus, linear constraints are the combination of these two
concepts, which have been studied independently elsewhere
\citep{OutsideIn,LinearHaskell,hh-ll,resource-management-for-ll-proof-search}.

With our extension, we can write a new pure version of |read2AndDiscard| which does
not require explicit threading of the array:
\begin{code}
read2AndDiscard :: constraint ((Read n, Write n)) =>. UArray a n -> (Ur a, Ur a)
read2AndDiscard arr = Linearly.do
  x   <-  read arr 0
  y   <-  read arr 1
  free arr
  Linearly.return (x, y)
\end{code}
The only changes from the impure version are that this version explicitly requires having
read and write access to the array, and the
use of the qualified |Linearly.do| notation to sequence the appropriate actions.
% and pattern-matching against $\packbox$ (read ``pack'') is necessary in order to access the linear constraint
% packed in the result of |read| and |free|. (\Cref{sec:implicit-existentials}
% suggests how we can get rid of $\packbox$, too.)
Crucially, the resource representing the ownership of the
array is a linear constraint and is separate from the array itself, which no
longer needs to be threaded manually.

\nw{It should be more clearly stated that this is an extended version of the ICFP paper, and
what the particular contributions of this version are.}
Our contributions are as follows:
\begin{itemize}
\item A system of qualified types that allows a constraint assumption
  to be given a multiplicity (linear or unrestricted). Linear assumptions are used precisely
  once in the body of a definition
  (\Cref{sec:qualified-type-system}). This system supports examples
  that have motivated the design of several resource-aware systems,
  such as ownership \textit{à la} Rust (\Cref{sec:memory-ownership}), or
  capabilities in the style of Mezzo~\cite{mezzo-permissions} or
  \textsc{ats}~\cite{AtsLinearViews}; accordingly, our system points
  towards a possible unification of these lines of research.

\item Applications of this qualified type system to allow writing
  \begin{itemize}
  \item functions whose result can only be used linearly (\Cref{sec:Unique-constraint})
  \item resource-aware algorithms without explicit threading (\Cref{sec:memory-ownership}); and
  \end{itemize}

\item An inference algorithm that respects the multiplicity of
  assumptions. We prove that this algorithm is sound with respect to
  our type system~(\Cref{sec:type-inference}). It consists of
  \begin{itemize}
  \item a constraint generation
    algorithm~(\cref{sec:constraint-generation}). The language of
    generated constraints tracks multiplicities.
  \item a solver~(\cref{sec:constraint-solver}) for the generated
    constraints, which restricts proof-search algorithms for linear
    logic in order to be \emph{guess
      free}~\cite[Section~6.4]{OutsideIn}. A guess-free algorithm
    ensures that constraint inference is predictable and insensitive
    to small changes in the source program; it is necessarily
    incomplete.
  \end{itemize}
\end{itemize}
%
Our language is given semantics by desugaring into a core language based
on that of \citet{LinearHaskell}.
Our design is intended to work well with other features of Haskell and
\textsc{ghc} extensions. Indeed, we have a prototype implementation (\cref{sec:implementation}).

\section{Background: Linear Haskell}
\label{sec:linear-types}

This section follows \citet[Section 2.1]{LinearHaskell},
to describe our baseline approach, as released in \textsc{ghc}~9.0.
%
Linear Haskell adds a new type of functions,
dubbed \emph{linear functions}, and written |a ⊸ b|.\footnote{The linear function
  type and its notation come from linear
  logic~\citep{girard-linear-logic}, to which the phrase \emph{linear
    types} refers. All the various designs of linear typing in the
  literature amount to adding such a linear function type, but details
  can vary wildly. See~\citet[Section 6]{LinearHaskell} for an analysis
  of alternative approaches.} A linear function consumes its
  argument exactly once. Linear Haskell defines it as follows: % "thusly" is very rare; let's not summon our inner Shakespeare just yet.

\begin{quote}
% \emph{Meaning of the linear arrow}: %JP: redundant
|f :: a ⊸ b| guarantees that if |(f u)| is consumed exactly once, \\
then the argument |u| is consumed exactly once.
\end{quote}
To make sense of this statement we need to know what ``consumed exactly once'' means.
Our definition is based on the type of the value concerned:
\begin{definition}[Consume exactly once]~ \label{def:consume}
\begin{itemize}
\item To consume a value of atomic base type (like |Int|) exactly once, just evaluate it.
\item To consume a function exactly once, apply it to one argument, and then consume its result exactly once.
\item To consume a pair exactly once, pattern-match on it, and then consume each component exactly once.
\item In general, to consume a value of an algebraic datatype exactly once, pattern-match on it,
  and then consume all its linear components exactly once.
\end{itemize}
\end{definition}

In the case of arrays, we treat |MArray a| as  a 


%
\subsection{Multiplicities}
\label{sec:multiplicities}
The usual arrow type |a -> b| can be recovered using |Ur|, as |Ur a ⊸ b|, but Linear
Haskell provides a first-class treatment of |a -> b|, thus ensuring
backwards compatibility with Haskell. In practice, the type-checker
records the \emph{multiplicity} of every introduced variable: \(1\) for linear
arguments and \(ω\) for unrestricted ones. This way, one can give a unified treatment
of both arrow types~\citep{linearity-and-pi-calculus}.
$$
\begin{array}{lcll}
  [[{pi}]], [[{rho}]] & \bnfeq & [[{1}]] \bnfor [[{omega}]] & \text{Multiplicities}
\end{array}
$$

We stress that a multiplicity of \(1\) restricts \emph{how the variable can be used}. It does not
restrict \emph{which values can be substituted for it}.
In particular, a linear function cannot assume that it is given the
unique pointer to its argument.  For example, if |f :: a ⊸ b|, then
the following is fine because the type of |duplicate| makes no guarantees about how it uses |x|:
\begin{code}
duplicate :: (a ⊸ b) -> a -> (b, b)
duplicate f x = (f x, f x)
\end{code}
In particular, |duplicate| can pass two copies of |x| to two copies of |f|.

Pattern matching on a value of type |Ur a| yields a payload of multiplicity
$[[{omega}]]$, even when the scrutinee has multiplicity $[[{1}]]$. In general, given a
multiplicity set, the desired
(sub)structural rules can be obtained by endowing multiplicities with the appropriate
semiring structure~\citep{abel_unified_2020}. In
this paper, we use the same multiplicity structure as Linear Haskell:\footnote{Even though linear Haskell additionally supports multiplicity
polymorphism, we do not support multiplicity polymorphism on
constraint arguments.  Linear Haskell takes advantage of multiplicity
polymorphism to avoid duplication of higher-order functions. The
prototypical example is |map :: (a poly_arrow b) -> [a] poly_arrow
[b]|, where |poly_arrow| is the notation for a function arrow of
multiplicity |multiplicity(m)|.  First-order functions, on the other
hand, do not need multiplicity polymorphism, because linear functions
can be $\eta$-expanded into unrestricted functions as explained in
\cref{sec:linear-types}. Higher-order functions whose arguments are
themselves constrained functions are rare, so we do not yet see the
need to extend multiplicity polymorphism to apply to constraints.
Futhermore, it is not clear how to extend the constraint solver of
\cref{sec:constraint-solver} to support multiplicity-polymorphic
constraints.}${}^,$\footnote{Here and in the rest of the paper we adopt the convention that
equations defining a function by pattern matching are marked with a
$\left\{\right.$ to their left.}
%
$$
\begin{array}{c@@{\qquad\qquad}c}
\left\{
  \begin{array}{lcl}
    [[{pi + rho}]] & = & [[{omega}]]
  \end{array}
\right.
&
\left\{
  \begin{array}{lcl}
    [[{1 . pi}]] & = & [[{pi}]] \\
    [[{omega . pi}]] & = & [[{omega}]]
  \end{array}
\right.
\end{array}
$$

\subsection{Shortcomings of Linear Haskell that We Address}
The |read| function in \cref{sec:introduction} consumes the array it
operates on. Therefore, the same array can no longer be used in
further operations: doing so would result in a type error.  To resolve
this, a new name for the same array is produced by each operation.

From the perspective of the programmer, this is unwanted boilerplate.
Minimizing such boilerplate is the main aim of this paper.  Our
approach is to let the array be non-linear, and let its
capabilities (\emph{i.e.} having read or write access) be \emph{linear
constraints}. Once these capabilities are consumed, the array can no
longer be read from or written to without triggering a compile time
error.

\nw{I think this paragraph is out of place. We should also say where in the paper these shortcomings are addressed}
A further drawback of today's Linear Haskell is that
the programmer cannot restrict how a linear function is used.
For example, suppose we want to use linear types to create
a pure interface to arrays that supports in-place mutation;
the interface is safe only if we guarantee that arrays cannot
be aliased. Because the result of a hypothetical |newArray|
function can be stored in an unrestricted variable (of multiplicity
$[[{omega}]]$), the linearity system cannot prevent its aliasing.
Instead, \citet[Fig.~2]{LinearHaskell} use a continuation-passing
style to enforce non-aliasing.

% In \cref{sec:introduction} and in the rest of the paper, we use pattern matches
% in $\klet$ bindings. By default in Haskell, patterns in $\klet$s are lazy, which means that
% |let  (a, b) = p in ()|
% will not actually evaluate the pair. To force evaluation, a strictness annotation can be added:
% |let  ^^ !(a, b) = p in ()|.
% Pattern matching in linear $\klet$ bindings must always be strict in Linear Haskell, so writing
% the lazy version would be rejected by the compiler. To simplify the
% presentation, we assume that all patterns in $\klet$ bindings are strict.
% Strict $\klet$ pattern bindings can be desugared into $\kcase$ expressions:
% |case p of (a, b) -> ()|.

\section{Working With Linear Constraints}
\label{sec:what-it-looks-like}
\jp{Why is this here? This current presentation is stuttering. IMO. It should go back somewhere in sec. 4.}
\begin{figure}%
  \maybesmall
  \centering
  \begin{subfigure}{.3\linewidth}%
    \noindent%
\begin{code}
phantom ( type constraint(RW n) = constraint((Read n, Write n)) )
new  :: Int -> (MArray a ->. Ur r) ->. Ur r
write :: MArray a ->. Int -> a -> MArray a
read :: MArray a ->. Int -> (MArray a, Ur a)
free :: MArray a ->. ()
\end{code}
\caption{Linear Types}
\label{fig:linear-interface}
  \end{subfigure}
  \hfill
  \begin{subfigure}{.55\linewidth}
\begin{code}
type constraint(RW n) = constraint((Read n, Write n))
new  :: constraint (Unique) =>. Int -> exists n. Ur (UArray a n) .<= constraint (RW n)
write :: constraint (RW n) =>. UArray a n -> Int -> a -> () .<= constraint (RW n)
read :: constraint (Read n) =>. UArray a n -> Int -> Ur a .<= constraint (Read n)
free :: constraint (RW n) =>. UArray a n -> ()
\end{code}
\caption{Linear Constraints}
\label{fig:constraints-interface}
  \end{subfigure}
\caption{Interfaces for mutable arrays}
\end{figure}

Consider the Haskell function |show|:
\begin{code}
show :: constraint (Show a) => a -> String
\end{code}
In addition to the function arrow |->|, common to all functional
programming languages, the type of this function features a constraint arrow |=>|.
Everything to the
left of a constraint arrow is called a \emph{constraint}, and will be
highlighted in \constraintfont{blue} throughout the paper. Here
|constraint (Show a)| is a
class constraint.

Constraints are handled implicitly by
the typechecker. That is, if we want to |show| the integer |n :: Int| we would write |show
n|, and the typechecker is responsible for proving that |constraint (Show Int)| holds, without
intervention from the programmer.

For our |read2AndDiscard| example, the |constraint((Read n, Write n))| (abbreviated as |constraint(RW n)|)
constraint represents read and write
access to the array tagged with the type variable |n|. (The full \textsc{api} under consideration appears
in \cref{fig:constraints-interface}.)
That is, the constraint |constraint(RW n)|
is provable if and only if the array tagged with |n| is readable and writable.
This constraint is linear: it must be consumed (that is, used as an assumption
in a function call) exactly once.
In order to manage linearity implicitly, this paper introduces a
linear constraint arrow (|=>.|), much like Linear Haskell introduces a linear
function arrow (|->.|). Constraints to the left of a linear constraint
arrow are \emph{linear constraints}.
Using the linear constraint |constraint(RW n)|, we can give
the following type to |free|:

\begin{code}
free :: constraint (RW n) =>. UArray a n -> ()
\end{code}

There are a few things to notice:
\begin{itemize}
\item We have introduced a new type variable |n|, which is a type-level tag
  used to identify the array. In contrast, the version in
  \Cref{fig:linear-interface} without linear constraints  has type
  |free :: MArray a ->. ()|.
  % Ideally, the linear constraint would refer directly to the
  % array value, and have the dependent type |free :: (n :: Array a) -> constraint (RW n) =>. ()|.
  % While giving a compile-time name to a function argument is common in
  % dependently typed languages such as \textsc{ats}~\cite{ats-lang} or Idris, our
  % approach, on the other hand, shows how we can still link a run-time value and a
  % compile-time tag without needing any dependent types.
\item The run-time variable representing the array can now be used multiple
  times. Instead of restricting the use of this variable,
  the linear constraint |constraint(RW n)| controls access to the
  array.
\item If we have a single, linear, |constraint (RW n)|
  available, then after |free| there will not be any |constraint (RW n)|
  left to use, thus preventing the array from being used after freeing.
  This is precisely what we were trying to achieve.
\end{itemize}

Let us now see some examples programs that use |free|. We reject |dithering|
because it does not unconditionally consume |constraint(RW n)|:
\begin{code}
dithering :: constraint (RW n) =>. UArray a n -> Bool -> ()
dithering arr x = if x then free arr else ()
\end{code}
The branch where |x == True| uses the resource |constraint(RW n)|,
whereas the other branch does not.

Linear constraints can interact with linear functions.
Consider the type of the linear version of |const|:
\begin{code}
const :: a ->. b -> a
\end{code}
This function uses its first argument linearly, and ignores the second. Thus,
the the second arrow is unrestricted.
%
One way to improperly use the linear |const| is by neglecting a linear variable:
\begin{code}
neglecting :: constraint (RW n) =>. UArray a n -> ()
neglecting arr = const () (free arr)
\end{code}
The problem with |neglecting| is that, although |free| is mentioned in this program,
it is never consumed: |const| does not use its second argument.
The constraint |constraint(RW n)| is not consumed exactly once, and
thus this program is rejected.
%
The rule is that a linear constraint can only be consumed (linearly)
in a linear context. For example,
\begin{code}
notNeglecting :: constraint (RW n) =>. UArray a n -> ()
notNeglecting arr = const (free arr) ()
\end{code}
is accepted, because the |constraint (RW n)| constraint is passed on to |free|
which itself appears as an argument to a linear function (whose result is
itself consumed linearly).

\label{sec:overusing}
Finally, the following program is rejected because it uses |RW n| twice:
\begin{code}
indulging :: constraint (RW n) =>. UArray a n -> ((), ())
indulging arr = (free arr, free arr)
\end{code}
Although freeing a resource multiple times is usually only considered bad form,
our type system rules this out completely.

The above deals with freeing an array and ensuring that it cannot be used afterwards.
However, we still need to explain how a constraint |constraint (RW n)| can come
into scope.
The type of |new| with linear constraints is as follows:
\begin{code}
new  :: constraint (Unique) =>. Int -> exists n. Ur (UArray a n) .<= constraint (RW n)
\end{code}

This type, too, illustrates several new aspects:
\begin{itemize}
\item The |constraint(Unique)| constraint is a linear constraint, though
it takes no type parameter. It restricts the result of |new|
to be used linearly, meaning that any variable that stores the result of |new| must
have multiplicity $[[{1}]]$. |constraint(Unique)| is explained more fully in \Cref{sec:Unique-constraint}.

\item Because |UArray| is now parameterised by a type-level tag |n|, |new| must
return a |UArray| with a fresh such |n|. This is achieved through returning an
existentially-quantified type\footnote{There is a variety of ways that existential types can
  be worked into a language. The existentials that we use here may be understood
  as a generalisation of those presented by \citet[Chapter
  24]{tapl}.
  However, \citet{existentials} work out an
  approach that makes linear constraints even easier to use, as we
  discuss in \Cref{sec:implicit-existentials}. In order to separate
  concerns, we do not build our formalism on \citet{existentials},
  instead modeling our existentials on the more widely known formulation described by \citet{tapl}.
  We additionally freely
omit the |exists a1 ... an.| or |.<= constraint (Q)| parts when they are
empty.
  The idea of using existentials to return linear capabilities can be attributed to \citet{DBLP:conf/esop/FluetMA06}.
} packing the type variable |n|. Such types are introduced with the $\packbox$ constructor.
% , which some readers might recognize as $\keyword{pack}$. % redundant with "packing". If there is a specific concept that this refers to, a typeface isn't enough to identify it (explicit reference is needed)

\item Not only do we need a fresh type variable |n|, but we also need to introduce
the linear constraint |constraint(RW n)| for use in subsequent calls to |read| and |free|.
Our existentials also allow packing a constraint, thanks to the |.<=| operator.
\end{itemize}

With all these features working together, we see that |new| returns a non-duplicable
|UArray| tagged with |n|, accessible only when the |constraint(RW n)| constraint is available.

We must also ensure that |read| can both promise to operate only on a readable array
and that the array remains readable afterwards:
\begin{code}
read :: constraint (Read n) =>. UArray a n -> Int -> Ur a .<= constraint (Read n)
\end{code}
That is, |read| must both consume
a linear constraint |constraint(Read n)| and also produce a fresh linear constraint
|constraint(Read n)|.
%% The fact that existential quantification generates new type-level names
%% is folklore. It's used crucially in the interface of the
%% |ST| monad~\cite{st-monad} and in type-class
%% reflection~\cite{type-class-reflection} (in both of these cases, existential
%% quantification is encoded as rank-2 universal quantification).
%% We
%% shall use it in exactly this way: |openFile| uses an existential
%% quantifier to generate the type-level name of the file
%% handle. Existentially quantified types are paired with a constraint |Q|
%% which we understand as being returned by functions.
% This type has a new symbol, |.<=|, which allows us to pack a produced constraint
% with a returned value. We will see in \cref{sec:arrays} that these produced constraints
% will also sometimes need to come with fresh type variables. Combining these
% ideas, we
% introduce
% a type construction |exists a1 ... an. t .<= constraint(Q)|,
% where |constraint(Q)| is a linear constraint (with the |a1 ... an| in scope) that is
% paired with the type |t|.\footnote{} Such types are introduced with the $\packbox$ constructor.
% Today's Haskell does not have an existential quantifier. However,
% existentially quantified types can
% be encoded as datatypes. For instance, |exists h. Ur (Handle h) .<= constraint (Open h)| can
% be implemented as
% \begin{code}
% data PackHandle where
%   Pack :: forall h. constraint (Open h) =>. Handle h -> PackHandle
% \end{code}
% In our implementation (\Cref{sec:implementation}), packed linear constraints
% piggy-back on \textsc{ghc}'s standard \textsc{gadt} syntax. Correspondingly, existential types are
% introduced by a data constructor, which we write as $\packbox$.
% In order to simplify extracting out the payload of an existential, however, we
% introduce a new syntax |let x := f args|: this notation means that the result
% of |f args| is unpacked, putting its payload in |x|. The |:=| notation also
% denotes a \emph{strict} binding, necessary for binding the type variables and
% assuming the constraints carried with |f args|; it can be understood as
% syntactic sugar for a |case| expression.



%
% However, the
% following version is accepted:
% \begin{code}
% notOverusing :: constraint ((C, C)) =>. (Int, Int)
% notOverusing = (useC, useC)
% \end{code}
% We see here that it is possible to have multiple copies of a given
% constraint.

% Because the consumption of constraints is implicit, when there are
% several possible ways to consume a constraint, the particular order
% chosen will depend on the details of the constraint resolution
% algorithm. We do not want the semantics of programs to depend on this
% order, which would not be at home in a declarative specification of
% the type system. Specifically, we require that the choice of
% given constraint (when there are multiple) cannot influence the
% behavior of the running program. In the domain of class constraints,
% this property is called \emph{coherence}: that only one instance of
% a specific type is in scope. Haskell already has mechanisms to ensure
% coherence~\cite{coherence}, though expert users have discovered ways
% to introduce incoherence\footnote{Kmett's \textsf{reflection} library,
% \url{https://hackage.haskell.org/package/reflection}, both uses incoherence
% to its advantage and also demonstrates techniques to keep its interface
% safe.}. As usual, any introduction of incoherence in the design of
% an \textsc{api} must be carefully considered for possible negative effects;
% the addition of linear constraints does not change this.

% \subsection{Linear I/O}
% \label{sec:linear-io}

% The file-handling example discussed in sections~\ref{sec:linear-types}
% and~\ref{sec:what-it-looks-like} uses a linear version of the |IO| monad, |IOL|.
% Compared to the traditional |IO| monad, the
% type of the monadic operations |>>=| (aka \emph{bind}) and |return| are changed to
% use linear arrows.
% %
% \begin{code}
% (>>=) :: IOL a ->. (a ->. IOL b) ->. IOL b
% return :: a ->. IOL a
% \end{code}
% %
% Bind must be linear because, as explained in the previous section, a linear
% constraint can be consumed in only a linear context. Consider
% the
% following program:
% \begin{code}
% readTwo ::  constraint (Open h) =>. Handle h -> IOL (Ur (String, String) .<= constraint (Open h))
% readTwo h =  readLine h >>= \case pack' xs ->
%              readLine h >>= \case pack' ys ->
%              return (pack' (xs, ys))
% \end{code}
% If bind were not linear, the first occurrence of |readLine h| would
% not be able to consume the |constraint (Open h)| constraint
% linearly.

\subsection{Restricting to a Linear Context with |constraint(Unique)|}
\label{sec:Unique-constraint}
A linear function makes a promise about how it is going to use its argument, but
linearity imposes no restrictions on how a function -- or its result -- is going to be used.
The caller may use the linear function's result unrestrictedly.  This poses a
challenge for providing a type-safe interface for libraries that rely on having a unique pointer to
some resource, such as safe mutable arrays, because the obvious definition of a
constructor function can immediately be misused, violating the assumption of uniqueness.
%
\begin{code}
new :: Int -> MArray a

forge = let arr = new 5 in (arr, arr)
smuggle = Ur (new 5)
\end{code}
%
However, with linear constraints, we can overcome this problem by putting the
special |constraint(Unique)| constraint on |new|:
\begin{code}
new :: constraint(Unique) =>. Int -> MArray a
\end{code}
Suppose we have assumed the |constraint(Unique)| constraint linearly; that is,
we must use the |constraint(Unique)| assumption precisely once. Now, our definition
for |forge| is rejected: either we infer |arr| to have multiplicity~$[[{omega}]]$,
in which case its definition uses |constraint(Unique)| $[[{omega}]]$ times; or
we infer |arr| to have multiplicity~$[[{1}]]$, in which case its use (twice) violates
the linearity restriction. Likewise, the use of |Ur| in |smuggle| requires using
the |constraint(Unique)| assumption $[[{omega}]]$ times.

This is promising so far, but several problems remain:

\begin{description}
\item[Duplicating |constraint(Unique)|] What if we want to create multiple
arrays, each of which having a unique pointer? If |constraint(Unique)| is assumed
linearly, then |let arr1 = new 5; arr2 = new 6| will fail, as it uses our
|constraint(Unique)| assumption twice. We thus stipulate that |constraint(Unique)|
must itself be duplicable: from one assumption of |constraint(Unique)|, we
must be able to satisfy any arbitrary fixed number of demands on that constraint.
By ``arbitrary fixed number'', we mean to say that we can duplicate |constraint(Unique)|
a finite number of times, but we may not use an assumption of |constraint(Unique)| with
multiplicity 1 to satisfy |constraint(Unique)| at multiplicity $[[{omega}]]$.

\item[Discarding |constraint(Unique)|] Similarly to allowing
  duplication, we must allow discarding, in case a function allocates
  no arrays at all. Accordingly, we allow a linear assumption of
  |constraint(Unique)| to be accepted even if the constraint is never
  used.

\item[Initial assumption of |constraint(Unique)|] For this approach to work,
we must have an assumption of |constraint(Unique)| of multiplicity 1. We can
achieve this via the following primitive:
\begin{code}
unique :: (Unique =>. Ur r) ->. Ur r
\end{code}
The argument to |unique| will be a continuation that assumes |constraint(Unique)|
with multiplicity 1. Because |unique| returns an unrestricted value, no restricted
values from the continuation can escape the scope of the |constraint(Unique)|
assumption. Thus, the continuation has exactly the condition we need: a
linear assumption of |constraint(Unique)|.
\end{description}

The pattern of using a continuation in |unique| mirrors the use
of that technique by \citet[Fig.~2]{LinearHaskell}. But
|unique| is, now, the only place where we need a continuation: once
we have our linear |constraint(Unique)| assumption, we can use it to produce
new values that must be unique.

With just these simple ingredients -- a duplicable, discardable constraint
that can be assumed linearly -- we can write \textsc{api}s that require
uniqueness without heavy use of continuations.

\section{Applications}
\label{sec:memory-ownership}

\improvement{This section needs an intro}

\subsection{Borrowing slices}
\label{sec:borrowing-slices}

Managing mutuable arrays is an important use case for linearly qualified types,
since many algorithms are split into subalgorithms that work on a particular
given subarray, or \emph{slice}, before returning control to the main algorithm.

% As an introduction to a style that will be used a lot throughout this section,
% let us start with answering the question of: how can we extend the purely
% functional mutable array interface of \cref{fig:constraints-interface} so that
% we can take subarrays (hereafter referred to as a \emph{slices}) of arrays.

\subsubsection{Simple slices}
\label{sec:simple-slices}

%format sub1 = "\Varid sub \ensuremath{_1}"

\nw{I think |sub| should probably be named |slice|: there are so many other "sub" things.}
A first intuition may be to add a function looking like this:
\begin{code}
sub1 :: constraint(RW n) =>. UArray a n -> Int -> Int -> exists p. Ur (UArray a p) .<= constraint(RW p)
\end{code}
This |sub1| takes a starting index and a length, and return the corresponding
slice of the array. The slice is returned with a fresh type-level name,
consuming the capabilities on the original array, so that we can't write
concurrently on the slice and on the original array, preserving referential
transparency.

There is one problem, though: this is a one way transformation. It is rare that
one wants to abandon the original array altogether when taking a slice: the goal
is usually to focus on the array for a portion of an algorithm, and return to
the global view later.

To be able to return to the global view, we only need to be able to recover
the original |constraint(RW n)| capabilities. A simple modification of |sub1|
achieves this result:
\begin{code}
sub ::  constraint(RW n) =>. UArray a n -> Int -> Int ->
        exists p. (Ur (UArray a p), (constraint(RW p) =>. () .<= constraint(RW n))) .<= constraint(RW p)
\end{code}
That is, |sub| returns an additional value of type |constraint(RW p) =>. () .<=
(constraint(RW n))|. We call this additional value a \emph{release function}. We
can then call this release function when we're done with the slice, and return
to the original array.

For instance we can write the following in-place insertion sort function, where
|insert a bs| inserts |a| into the already-sorted array |bs| in place. To
preserve the size of the array, the smallest element of $a\cup bs$ is removed
from the result and returned. In the interesting case, |a| isn't the smallest
element of $a\cup bs$, so |b=read bs 0| is, we return |b| and insert |a| to the
tail of |bs|, that is |sub bs 1 (len - 1)| (where |len| is the length of |bs|).

\info{I'm using insertion sort as an example here to set up the merge sort
  example below.}
\critical{I'm using length here, we need to define it somewhere}
\critical{I'm using unless here, we need to define it somewhere}
\begin{code}
insertSort :: constraint(RW n) =>. UArray a n -> () .<= constraint(RW n)
insertSort as =
  unless (length as <= 1) $ Linearly.do
    Ur a <- read 0 as
    (Ur tail, release) <-sub as 1 (len - 1)
    insertSort tail
    Ur a' <- insert a tail
    release
    write as 0 a'
    Linearly.return ()

insert :: constraint(RW n) =>. a -> UArray a n -> Ur a .<= constraint(RW n)
insert a bs =
  unless (length bs == 0) $ Linearly.do
    Ur b <- read b in
    if a <= b then
      Linearly.return (Ur a)
    else Linearly.do
      (Ur tail, release) <- sub bs 1 (len - 1)
      Ur b' <- insert a tail
      release
      write bs 0 b'
      Linearly.return (Ur b)
\end{code}

% \improvement{Define swap somewhere? The code is in comments below}
% \begin{code}
% -- Reversing the elements of an array, the array's length is a parameter
% rev :: constraint(RW n) =>. UArray a n -> Int -> () .<= constraint(RW n)
% rev as len =
%   if len <= 1 then pack ()
%   else
%     let        ilen                 =  len - 2
%          pack  (Ur inner, release)  =  sub as 1 ilen       -- take a slice
%          pack  ()                   =  rev inner ilen      -- reverse the slice recursively
%          pack  ()                   =  release             -- return to the old array
%          pack  ()                   =  swap as 0 (len -1)  -- swap the first and last element
%     in pack ()
% \end{code}

% \begin{code}
% swap :: constraint(RW n) =>. UArray a n -> Int -> Int -> () .<= constraint(RW n)
% swap as i j =
%   let  pack  (Ur ai)  =  read as i
%        pack  (Ur aj)  =  read as j
%        pack  ()       =  write as i aj
%        pack  ()       =  write as j ai
%   in ()
% \end{code}

The release function returned by |sub| is linear, which means it must be called.
When an array has a linear release function attached, it can't be freed (with
the |free| function of \cref{fig:constraints-interface}), for instance, since
this would leave the release function unable to be called and the type system
would reject the program.

When a value has such a linear release function we say that the value \emph{has
  a lifetime}. When a value doesn't have a lifetime, we say it is \emph{owned}.
This distinction will be quite important for \cref{sec:o1-freeze}, in
particular. In addition, we refer to any function which returns one or more
values with lifetimes as a \emph{borrow}.

For completeness, let us observe that the Haskell language (at least
\textsc{ghc}'s flavour) supports higher-order constraints. With higher-order
constraints, we could replace the release \emph{function} by a release
\emph{constraint} of type |constraint(RW p) =>. constraint(RW n)|. The
difference is that we wouldn't have to call |release| explicitly anymore, simply
using the original array would implictly release the slice's permissions. We
didn't want to rely on higher-order constraints in this article, as we feel that
the additional complications to \cref{sec:constraint-solver} would obscure the
exposition. Either way, we haven't made our mind whether the explicit style or
implicit style is preferable in a fully fledged programming language.
\nw{We should rephrase this! Not making up our mind sounds too informal}

\subsubsection{Slicing in two}
\label{sec:slicing-two}

A more advanced form of borrowing slices of arrays is to borrow two independent
slices from the same array simultaneously. As long as two slices don't overlap,
mutating one doesn't affect the other, and it's therefore safe to mutate them
concurrently.

The |sub| primitive from earlier can't be used to borrow two independent slices:
when a slice is borrowed, then we lose access to the original array until the
slice is released, so we can't make a second slice exist simultaneously. So we
need a new function. The simplest version is to cut an array in two at a given
position:
\begin{code}
slice ::  constraint(RW n) =>. UArray a n -> Int ->
          exists p q. (Ur (UArray a p, UArray a q), (constraint(RW p, RW q) =>. () .<= constraint(RW n))) .<= constraint((RW p, RW q))
\end{code}
such that |slice as n| returns two slices, one with the first |n| elements, and
one with the remaining |length as - n| elements. The two slices can be used
simultaneously. Crucially, both slices much be released for the original
array to be accessible again, this is represented as a single release function
which consumes the permissions for both slices.

To see why we may need two slices concurrently rather than, say, call |sub|
twice in a sequence, consider the merge sorting function below. The |merge|
function takes two sorted arrays |ls| and |rs|, and mutates them so that the
concatenation of |ls| and |rs| becomes sorted as a whole\footnote{The
  implementation of |merge| is chosen for simplicity over efficiency for the
  sake of this exposition. Inserting elements into |rs| with the |insert|
  function of \cref{sec:simple-slices} is convenient but not particularly
  efficient. In fact, neither |merge| nor |insert| are truly in place: while
  they do use $O(1)$ heap space, the actually use $O(n)$ stack space, since they
  aren't tail recursive.}. It's crucial that the arrays |ls| and |rs| be
disjoint, if they weren't, referential transparency would be lost and |merge|
wouldn't be a pure function (for instance reordering |write ls 0 r| and |insert
l rs|, which is a legal transformation, would change the result). The |sub|
function from \cref{sec:simple-slices} can't prove that two slices are disjoint,
so |sub| can never provide two slices of the same array at the same time. Which
is why we need the |slice| function in |mergeSort| to even be able to call
|merge|.

\info{Merge sort isn't too simple on arrays, really, but it was the simplest
  example I could come up with of a function that truly needed two slices of the
  same array.}
\critical{I'm using length here, we need to define it somewhere}
\begin{code}
mergeSort ::  constraint(RW n) =>. UArray a n -> () .<= constraint(RW n)
mergeSort as =
  unless (length as <= 1) $ Linearly.do
    (Ur(ls, rs), release) <- slice as (len / 2)
    mergeSort ls
    mergeSort rs
    merge ls rs
    Linear.return ()

merge ::  constraint((RW p, RW q)) =>. UArray a p -> UArray a q -> () .<= constraint((RW p, RW q))
merge ls rs =
  unless (length ls == 0 || length rs == 0) $ Linearly.do
    Ur l <- read ls
    Ur r <- read rs
    if l <= r then Linearly.do
      (Ur (_, ls'), release) <- slice ls 1
      merge ls' rs
      release
      Linear.return ()
    else Linearly.do
      write ls 0 r
      (Ur ls', release) <- slice 1 ls
      Ur r' <- insert l rs
      write rs 0 r'
      merge ls' rs
      release
      Linear.return ()
\end{code}

It's worth noting that, despite being a very simple function, |slice| is very
general. Indeed, |slice| can be used to define the |sub| function of
\cref{sec:simple-slices}. Notice how the unneeded slices are released, below, by
partially discharging the linear constraint of the release functions.

\begin{code}
sub ::  constraint(RW n) =>. UArray a n -> Int -> Int ->
        exists p. (Ur (UArray a p), (constraint(RW p) =>. () .<= constraint(RW n))) .<= constraint(RW p)
sub as start len = Linearly.do
  (Ur (_, rght), release_r) <-  slice as start
  (Ur (sb, _), release_s) <-  slice rght len
  Linearly.return (Ur sb, Linearly.do {release_s; release_r})

\end{code}

\subsection{Blockwise matrices: in-place Valiant algorithm}
\label{sec:valiant}

\improvement{Come back to the introduction of this section to make sure that it
  flows with the previous section}
This subsection illustrates in-place modification of matrices on a
parsing algorithm. This algorithm was invented by
\citet{valiant_general_1975} as a theoretical tool to show that
context-free parsing could be sub-cubic, but has also
found practical applications
\citep{bernardy_efficient_2013,bernardy_efficient_2015}.  Valiant's
algorithm is a divide-and conquer algorithm which works on matrices,
and we use it illustrate how such corresponding ownership patterns can be
encoded with our system.

We direct the curious reader to the cited works, but at its core,
Valiant's algorithm consists in reducing context-free parsing to the
computation of a (non-associative) transitive closure of a cycle-free
directed graph. Each node corresponds to a position in the string, and
edges are labeled by the set non-terminals generating the corresponding substring. The grammar
controls whether two paths can be combined into a longer path, depending on their labels.
In the closed graph, the eventual labels of the edge
between the start node and the end node give the parsing result.  The
graph and its closure are represented by adjacency matrices which are
both upper-triangular.  We will show how to update this matrix in-place,
building up closures, in a divide and conquer pattern.
By nature of the closure, the closure is built incrementally: one add labels to the entries of the matrix, but never remove them.

In fact, Valiant's algorithm consists in two divide-and-conquer recursive functions:
\begin{code}
v :: constraint (RW n) =>. Matrix a n .<= constraint (RW n)
w :: (Read p, RW n, Read q) =>. Matrix a p -> Matrix a n -> Matrix a q .<= (Read p, RW n, Read q)
\end{code}
Here |v| takes a writeable matrix |n|. When done |n| will be transitively
closed. The |w| function is a
helper, which takes two fully closed sub-matrices |p| and |q|, and a
partial subgraph between the nodes of |p| and the nodes of |q|, represented as a rectangular matrix |n|. When done, |n| contains
all the possible labeled paths from |p| to |q|.

If its input is small enough, then there is nothing to do for |v|, but otherwise it splits |n| it in two new triangular matrices |a| and
|b| and the top-right matrix |x|. (The bottom left is always empty.)
The read-write ownership is transferred to each of the components.
After recursively computing the closure of |a| and |b|, the matrix is
completed using the helper function (|w a x b|).
\begin{code}
v n =
  if size n <= 2
    return ()
  else do
    let i = size n `div` 2
    (a,x,b) <- splitUpperMatrix n i
    v a
    v b
    w a x b
    joinUpperMatrix a x b
\end{code}
The splitting and joining of upper triangular matrices is prodived by the functions:

> splitUpperMatrix :: constraint (RW n) =>. Matrix a n -> Int -> exists m l r. Ur (Matrix a l, Matrix a m, Matrix a r) .<= constraint ((RW l, RW r, TriSlices n m l r))
> joinUpperMatrix :: constraint ((TriSlices n m l r, RW r , RW m, RW l)) =>. Matrix a l -> Matrix a m -> Matrix a r -> Ur (Matrix a n) .<= constraint (RW n)

The helper |w p n q| is somewhat more involved. It won't touch the
completed matrices |p| and |q|, as declared in its signature. If both
of the upper-triangular matrices |p| and |q| are one-by-one, then
we're done. Otherwise, we split the larger of the two (say |p|) into
three parts, and |n| is split along the corresponding dimension, at
the same position, into |y| and |z|. The matrix |z| is closed by a recursive
call. Then the multiplication of |x| and |z| is performed (the
multiplication of elements, non-terminals, determines the grammar) and
added (using set union) to |y|. Finally |z| is recursively closed. The case of splitting |q| is symmetric.
\begin{code}
w p n q =
  if size p <= 1 && size q <= 1
  then return ()
  else if size p > size q
    then Linearly.do
      let i = size p `div` 2
      (a,x,b) <- splitUpperMatrix p i
      (y,z) <- sliceMatrixV n i
      w b z q
      multiplyMatricesInto y x z
      w a y q
      joinUpperMatrix a x b; joinMatrices y z
    else Linearly.do
      let i = size q `div` 2
      (a,z,b) <- splitUpperMatrix q i
      (x,y) <- sliceMatrixH n i
      w p x a
      multiplyMatricesInto y x z
      w p y b
      joinUpperMatrix a x b; joinMatrices y z
\end{code}

\providecommand{\upperRightTriangle}[4]{
    % 1: start pos
    % 2: side length of the square
    % 3: text to display in the triangle
  \begin{scope}[shift={(#1 , -#1)}]
    \pgfmathsetmacro{\triSize}{#2}
    \draw[#4] (0,0) -- (\triSize,0) -- (\triSize,-\triSize) -- cycle;
    \node at (2*\triSize/3, -\triSize/3) {#3};
  \end{scope}
}
\providecommand{\matrixRectangle}[5]{
  \begin{scope}[shift={#1}]
    \draw [#5] (0,0) rectangle (#2,-#3) ;
    \node at (#2 / 2,-#3 / 2) {#4};
  \end{scope}
}

\begin{figure}
  \centering
  \begin{tikzpicture}
    \def\extraSpace{0.25}
    \def\asize{1}
    \def\bsize{1.1}
    \def\qsize{0.6}
    \pgfmathsetmacro{\psize}{\asize + \bsize}
    \pgfmathsetmacro{\bpos}{\asize}
    \pgfmathsetmacro{\qpos}{\psize + \extraSpace}
    \pgfmathsetmacro{\totsize}{\psize + \qsize}
    \upperRightTriangle{0}{\asize}{a}{white}
    \upperRightTriangle{\bpos}{\bsize}{b}{white}
    \upperRightTriangle{0}{\psize}{}{}
    \upperRightTriangle{\qpos}{\qsize}{q}{}
    \matrixRectangle{(\qpos,0)}{\qsize}{\psize}{}{}
    \matrixRectangle{(\bpos,0)}{\bsize}{\asize}{x}{dotted}
    \matrixRectangle{(\qpos,0)}{\qsize}{\asize}{y}{dotted}
    \matrixRectangle{(\qpos,-\bpos)}{\qsize}{\bsize}{z}{dotted}
  \end{tikzpicture}
  \caption{Division of the inputs of the |w| function when |p| is larger than |q|. That is, |p=(a,x,b)| and |n=(y,z)|.}
  \label{fig:valiant-w}
\end{figure}
The splitting and joining of general rectangular matrices follows the usual pattern (and in fact, can be used to implement such operations on triangular matrices).

> sliceMatrixH :: constraint (RW n) =>. Matrix a n -> Int -> exists l r. Ur (Matrix a l, Matrix a r) .<= constraint ((RW l, RW r, MatSlices n l r))
> sliceMatrixV :: constraint (RW n) =>. Matrix a n -> Int -> exists l r. Ur (Matrix a l, Matrix a r) .<= constraint ((RW l, RW r, MatSlices n l r))
> joinMatrices :: constraint ((MatSlices n l r, RW r, RW l)) =>. Matrix a l -> Matrix a r -> Ur (Matrix a n) .<= constraint (RW n)

We won't detail the underlying matrix multiplication; but its signature is the following.
> multiplyMatricesInto :: constraint ((RW x, Read y, Read z)) =>. Matrix NTSet x -> Matrix NTSet y -> Matrix NTSet z .<= constraint (RW x, Read y, Read z)

The structure of the algorithm follows exactly that outlined by
\citet{valiant_general_1975}. The overhead is the
explicitly calling of join functions to re-construct ownership
of the analysed matrices. In return, one gets additional static
checks: we do not demand full read-write permissions on complete
matrices. Besides, even though the algorithm is imperative, it can be
called from pure functions, where the resulting matrix would be
\emph{frozen}.\jp{When the generic matrix stuff is done, show to combine with freezing}

\subsection{Matrices from first principles: a theory of nested arrays}
\label{sec:nested-arrays}

In \cref{sec:borrowing-slices}, we split arrays in two at a position, in
\ref{sec:valiant} we split matrices either at a vertical position or a
horizontal position. Higher-dimensional tensors could, in general, be split
along any dimension. The good news is that we don't have to define a new
interface from unsafe primitives for each dimension.
Capabilities-as-linear-constraints are flexible enough that we can build a
single interface which covers all dimensions.

\paragraph*{Arrays with nesting}

Specifically, we're going to represent matrices as arrays of arrays (say an
array of columns). Higher-dimensional tensors will follow easily. To whet the
reader's appetite, slicing a matrix in two sets of columns is, rather
straightforward: just consider two halves of the root array; but slicing a
matrix in two sets of lines is much less obvious as it requires slicing each
column in two.

Let's first notice that we can't use the |UArray| type of
\cref{sec:borrowing-slices}. Indeed, nesting |UArray| would give us a type like
|UArray (UArray a p) n|. But this isn't what we want: presumably |p| should be
different for each array. Nor can we use something like |UArray (exists p.
UArray a p .<= RW p) n|, since |RW p| is a linear constraint, and an |UArray|
can only store linear values.

So we need to introduce a new type |NArray| (the |N| stands for ``nested'').
What we want to express, with |NArray| is that all the arrays have the same
owner, so that when we write an array |bs| in a cell of an array |as|, we
relinquish the ownership of |bs| to that of |as|. We do that by abstracting over
the type-level name of |bs|.

% Yet, we propose to build a library of arrays which lets us build such deep
% slices. One of our main tool is that existential types such as we use in this
% paper, or \textsc{gadt}s as in Haskell or Ocaml let us package capabilities as
% values, hence let us program capabilities. This is hardly a new insight,
% functional languages with capabilities usually have ways to pack capabilities
% inside values~\cite{AtsLinearViews,mezzo-permissions}\unsure{Rust's lifetime are
%   an exception here. The fact that they can't be existentially quantified over
%   is a pretty restrictive (but maybe also liberating?) aspect of Rust's design.
%   Should we comment on this?}. What is new is that this natural generalisation
% of the concept of type classes is enough to represent many capability systems.

\begin{code}
type NArray :: (Reg -> Type) -> Reg -> Type
\end{code}
Notice that it's very convenient for the region parameter to be the last
parameter, in order for the types to align when nesting arrays.

In consequence, we can't have |NArray Int|, we will need a type to mediate
between nested arrays, bound to a region, and ordinary values. We introduce the
type |Val| to that effect.

\begin{code}
type Val :: Type -> Reg -> Type
newtype Val a n = MkVal a
instance constraint(R (Val a n))
instance constraint(W (Val a n))
\end{code}

%format Matrix0 = "\Varid Matrix \ensuremath{_0}"

Since |Val| isn't an abstract type, its free to ignore its capabilities (which
is fine since no mutation can occur in a |Val a r|). We provide unrestricted
read and write access to |Val| since neither do anything, but they'll be needed
to interface with the array functions\critical{We can only do this if we change
  the solver!}. With this, a matrix  can have
type:
\begin{code}
type Matrix0 a n = NArray (NArray (Val a)) n
\end{code}
This isn't quite the type that we will use to represent the matrices of
\cref{sec:valiant}, because in this section it will be convenient to have a
separate type for full arrays (|NArray|) and slices (|Slice| below).

\begin{code}
newNArray :: constraint(Linearly) =>. Int -> (constraint(Linearly) =>. Int -> exists p. a p .<= constraint(RW p) ) -> exists n. NArray a n .<= constraint(RW n)
borrowNA :: constraint(RW n) =>. NArray a n -> Int -> exists p. (Ur (a p), (constraint(RW p) =>. () .<= constraint(RW n))) .<= constraint(RW p)
borrowNAR :: constraint(R n) =>. NArray a n -> Int -> exists p. (Ur (a p), (constraint(R p) =>. () .<= (constraint(R n)))) .<= constraint(R p)
writeNA :: constraint((RW n, RW p)) =>. NArray a n -> Int -> a p -> () .<= constraint(RW n)
\end{code}

To write a value |u| into an array |a|, you need read and write access to |u| since
you are going to give |a| permission to read and write to |u|. For the same
reason we need to produce read and write capabilities to the elements we
initialise the array with in |newNArray|.

Accessing inner arrays, both for reading and writing, is more interesting: it
introduces a new kind of borrow, in the form of the functions |borrowNA| and
|borrowNAR|. We don't borrow slices here, we borrow inner values. If you ignore
all the capabilities, these borrows have the type signature we'd expect of a
read function. They're borrows because they need to provide capabilities for the
inner value, and a release function. The fresh capabilities and the release
function prevent aliasing mutable cells.

\paragraph*{Slice type}
\label{sec:slice-type}

This is enough \textsc{api} on full arrays to let us implement slices. Because
we are going to be manipulating capabilities in an unsafe way, we shall need a
handful of unsafe primitives to provide or consume capabilities.

\begin{code}
unsafeRead :: () .<= constraint(Read n)
unsafeWrite :: () .<= constraint(Write n)
unsafeRW :: () .<= constraint(RW n)
unsafeRW = Linearly.do { unsafeRead; unsafeWrite ; Linear.return ()}

unsafeConsumeRead :: constraint(Read n) =>. ()
unsafeConsumeWrite :: constraint(Write n) =>. ()
unsafeConsumeRW :: constraint(RW n) =>. ()
unsafeConsumeRW = Linearly.do { unsafeConsumeRead; unsafeConsumeWrite ; Linear.return ()}
\end{code}
These aren't user facing, as they would make the library unsound. They are only
used as part of the implementation of our array and slice library.

We shall use an object-oriented definition of slices because functions are a
very powerful and convenient abstraction. An implementation aiming for
efficiency would have to use a more specialised implementation (like above,
|UnsafeMkSlice| isn't part of the public interface).
\begin{code}
type Slice :: (Reg -> Type) -> Reg -> Type
data Slice a n = UnsafeMkSlice {
  borrowS  ::  constraint(RW n) =>. Int -> exists p. (Ur (a p), (constraint(RW p) =>. () .<= constraint(RW n))) .<= constraint(RW p),
  writeS   ::  forall p. constraint((RW n, RW p)) =>. Int -> a p -> () .<= constraint(RW n) }
\end{code}
An array can be converted into a slice which spans the whole array
\begin{code}
fullSlice :: constraint(RW n) =>. NArray a n -> exists p. (Ur (Slice a p), constraint(RW p) =>. () .<= constraint(RW n)) .<= constraint(RW p)
fullSlice as = Linearly.return
  (  (UnsafeMkSlice { borrowS = borrowNA as, writeS = writeNA as }),
     Linearly.return ())
\end{code}

More interestingly, we can slice a |Slice| in two\unsure{The type applications
  are a bit of a lie here. But this is already quite a complicated function, so
  I don't know whether we should go even more in the weeds. In fact, I don't
  even think the test of this function really helps at anything. It was meant as
  evidence that, yes, this can be done, but I don't like it anymore.}
\begin{code}
sliceS ::  constraint(RW n) =>. Slice a n -> Int ->
           exists p q. (Ur (Slice a p, Slice a q), (constraint(RW p, RW q) =>. () .<= constraint(RW n))) .<= constraint(RW p, RW q)
sliceS as i = Linearly.return
   (  ( UnsafeMkSlice {
          borrowS = (\j ->
            if j > i then
              error "Index out of bound"
            else Linearly.do
              unsafeRw @n
              borrowS as j),
          writeS = (\j v ->
            if j > i then
              error "Index out of bound"
            else
              unsafeRw @n
              writeS as j v )},
        UnsafeMkSlice {
          borrowS = (\j -> Linearly.do
             unsafeRW @n
             borrowS as (i+j)),
          writeS = (\j v -> Linearly.do
            unsafeRW @n
            writeS as (i+j) v) }),
      (Linearly.do { unsafeConsumeRW @p; unsafeConsumeRW @q; Linearly.return () }) )
\end{code}
Note that the implementation uses unsafe creation and consumption of
capabilities, since it creates a new access pattern. As the library author, we
must, in exchange, ensure that this access pattern doesn't create aliases.

\paragraph*{Implementing UArray}
\label{sec:implementing-uarray}

With these primitives in hands we can give an implementation to the |UArray|
type of \cref{sec:borrowing-slices} and up. Since in
\cref{sec:borrowing-slices}, we use the same a type for owned arrays and slice,
we implement it as a sum type.

\begin{code}
data UArray a n
  = OwnedArray (NArray (Val a) n)
  | SliceArray (Slice (Val a) n)
\end{code}

We can, for instance, write the |write| function

\begin{code}
write :: constraint (RW n) =>. UArray a n -> Int -> a -> () .<= constraint (RW n)
write (OwnedArray as) i a = writeNA as i (Val a)
write (SliceArray as) i a = writeS as i (Val a)
\end{code}

The |read| function is a little more involved, since it involves a borrow. But
the borrow is degenerate since we're borrowing a value of type |Val a|.

\begin{code}
read :: UArray a ->. Int -> (UArray a, Ur a)
read (OwnedArray as) i = Linearly.do
  (Ur (Val a), release) <- borrowNA as i
  release
  Linear.return (Ur a)
read (SliceArray as) i = Linearly.do
  (Ur (Val a), release) <- borrowS as i
  release
  Linear.return (Ur a)
\end{code}

As a final example, here is the implementation of the |slice| function.

\begin{code}
slice ::  constraint(RW n) =>. UArray a n -> Int ->
          exists p q. (Ur (UArray a p, UArray a q), (constraint(RW p, RW q) =>. () .<= constraint(RW n))) .<= constraint((RW p, RW q))
slice (OwnedArray as) i = Linearly.do
  (Ur as', release_top) <- fullSlice as
  (Ur (SliceArray l, SliceArray r), release_slices) <- sliceS as' i
  Linearly.return (Ur (l, r), do { release_slices; release_top })
slice (SliceArray as) i = Linearly.do
  (Ur (l, r), release_slices) <- sliceS as i
  Linearly.return (Ur (SliceArray l, SliceArray r), release_slices)
\end{code}

\paragraph*{Deep borrowing and slicing}
\label{sec:deep-slicing}

The motivation for defining the |Slice| type, however, is that we can lift any
borrow operation on the inner type |a| to a borrow on slices. The idea is
simple: we delay actually calling the inner borrow function until we borrow an
inner value from the slice.
\begin{code}
borrowDeep ::  constraint(RW n) =>. Slice a n ->
               (forall p. constraint(RW p) =>. a p -> exists q. (Ur (b p), (constraint(RW b) =>. () .<= constraint(RW p)))) ->
               exists r. (Ur (Slice b r), constraint(RW r) =>. () .<= constraint(RW n))
borrowDeep as brw = Linearly.return (
  UnsafeMkSlice {
      borrowS = \i -> Linearly.do
        (Ur a, release_a)  <-  borrowS as i
        (Ur b, release_b)  <-  brw a
        Linearly.return (Ur b, Linearly.do { release_b; release_a }),
      writeS =
         error "Attempt to write to a borrowed space" },
  (Linearly.return ()) )

borrowDeepR ::  constraint(Read n) =>. Slice a n ->
                (forall p. constraint(Read p) =>. a p -> exists q. (Ur (b p), (constraint(Read b) =>. () .<= constraint(Read p)))) ->
                exists r. (Ur (Slice b r), constraint(Read r) =>. () .<= constraint(Read n))
borrowDeepR = … -- Mutatis mutandis
\end{code}
Note how the write method is an error after a deep borrow. It doesn't make sense
to try to write a |b| in a cell that really holds an |a|. In our case |b| will
always be |Slice c| for some |c|, so |writeS| would have to replace a slice of
an array wholesale, this isn't an operation which can be performed without
copying the inner array, while |writeS| is supposed to be of $O(1)$ write
operation. Fortunately, slices are always borrowed, and attempting to write a
slice to an array cell would result in a static error: the release function
hasn't been called.

Similarly we can lift a slicing function on the inner |a| with the following
functions
\begin{code}
sliceDeep
  ::  constraint(RW n) =>. Slice a n ->
      (forall p. constraint(RW p) =>. a p -> exists r s. constraint((RW r, RW s)) =>. (Ur (a r, a s), constraint((RW r, RW s)) =>. () .<= constraint(RW p))) ->
      exists q. constraint((RW o, RW q)) =>. (Ur (Slice a o, Slice a q), constraint((RW o, RW q)) =>. () .<= constraint(RW n)) .<= constraint((RW o, RW q))
sliceDeepR
  ::  constraint(Read n) =>. Slice a n ->
      (forall p. constraint(Read p) =>. a p -> exists r s. constraint((Read r, Read s)) =>. (Ur (a r, a s), constraint((Read r, Read s)) =>. () .<= constraint(Read p))) ->
      exists q. constraint((Read o, Read q)) =>. (Ur (Slice a o, Slice a q), constraint((Read o, Read q)) =>. () .<= constraint(Read n)) .<= constraint((Read o, Read q))
\end{code}
We're omitting their implementation because it's becomes a little involved
without being meaningfully different form the other borrowing functions we've
seen so far. The idea is the same as deep borrowing: the slicing function is
suspended until a borrows is called. But when we borrow, we only need one of the
two produce slices, so we return the other one immediately. Note that the type
of the inner slicing function is slightly abstracted compared to the type of
`sliceS`: it doesn't take an integer argument, which we assume to be captured by
the closure.

\paragraph*{Implementing Matrix}
\label{sec:implementing-matrix}

This is enough material to implement the |Matrix| type from \cref{sec:valiant}.
Like arrays, matrices are implemented as a disjunction
\begin{code}
data Matrix a n
  = OwnedMatrix (NArray (NArray (Val a)) n)
  | SliceMatrix (Slice (Slice (Val a)) n)
\end{code}

We can see the deep borrowing and slicing functions at work, for instance, in
the |sliceMatrixV| function, which splits a matrix vertically into a top matrix
and a bottom matrix.
\begin{code}
sliceMatrixV ::  constraint(RW n) =>. Matrix a n -> Int ->
                 exists p q. (Ur (Matrix p, Matrix q), constraint((RW p, RW q)) =>. () .<= constraint(RW n)) .<= constraint((RW p, RW q))
sliceMatrixV (OwnedMatrix m) row_num = Linearly.do
  (Ur m', release_top) <- fullSlice m
  (Ur m'', release_top_deep) <- borrowDeep m' fullSlice
  (Ur (t, b), release_slices) <- sliceDeep m'' (\col -> slice col row_num)
  Linearly.return (
    Ur (SliceMatrix t, SliceMatrix b),
    Linearly.do { release_slices; release_top_deep; release_top })
sliceMatrixV (SliceMatrix m) row_num = Linearly.do
  (Ur (t, b), release_slices) <- sliceDeep m (\col -> slice col row_num)
  Linearly.return (Ur (SliceMatrix t, SliceMatrix b), release_slices )
\end{code}
Notice how we use |borrowDeep| in the |OwnedMatrix| case to convert an |Array
(Array _)| into a |Slice (Slice _)|. The rest of the matrix functions follow
easily.

As promised our nested array \textsc{api} is general enough to support slicing
along both dimension of matrices. Of course, there's nothing special about
matrices, higher dimension tensors would work as well. The key to all this is
that all this flexibility follows from the theory of linear constraints, which
is a natural extension of Haskell's constraints. Constraints can be captured in
closure, and in existential types (or \textsc{gadt}s in real-life Haskell),
which affords us a lot of programming techniques. We don't have to develop any
\emph{ad hoc} theory of capabilities.

\subsection{Freezing nested structures}
\label{sec:o1-freeze}

\begin{itemize}
  \item Based on the blog post
\end{itemize}

\subsection{Beyond arrays: splay Trees}

Another application of in-place updates are \emph{splay trees}. A
splay tree acts like a binary search tree, but at every access, the
tree structure is modified so that the recently accessed elements are
moved towards the root of the tree. This way, recently acessed
elements are faster to reach in subsequent lookups.


A tree associated with a region |n| will be defined as follows:

> data Node n = Node (Ref Node n) Int (Ref Node n) | Leaf
%
The noteworthy feature is that each child is accessible via an
updateable reference.
As usual, we need splitting and joining functions for this data:
> splitTree :: constraint (RW n) => Ref Node n -> ∃ p q. (Ref Node p, Int, Ref Node q) .<= constraint((RW p, RW q, TreeSlice p q n))
> joinTree :: constraint((RW p, RW q, TreeSlice p q n)) =>. Ref Node p -> Int -> Ref Node q -> Ref Node n .<= constraint((RW n))
\todo{splitTree may fail (Leaf). Dealing with this case will considerably complexify the example. I'm not sure if it's worth it. But there is an interesting point belowwhich can be seen already with this simpler case: namely this is a bit convoluted compared to what one would write normally either with Haskell or C.}

Accessing generic references would be done via the following two functions:\jp{we discussed |AtomRef| above, how |Ref| is different is unclear to me.}
> readRef :: constraint (Read n) =>. Ref a n -> Ur a .<= constraint (Read n)
> writeRef :: constraint (RW n) =>. Ref a n -> a -> () .<= constraint (RW n)
%
But for this application we also need a way to exchange the contents of references:
> swapRefs :: constraint((RW p, RW q)) =>. Ref f p -> Ref f q -> () .<= constraint((RW p, RW q))

When accessing a node in the splay tree, it is brought towards the
root by repeated use of 'rotate' operations which effectively exchange
a node with either its left or right child. There follows a schematic
representation of the rotation with the left child:
\begin{center}
  \begin{tikzpicture}[baseline=(current bounding box.center),
    level distance=.8cm,
    level 1/.style={sibling distance=.8cm},
    level 2/.style={sibling distance=.8cm}]
    \node {y}
    child {node {x}
      child {node {A}}
      child {node {B}}
    }
    child {node {C}};
  \end{tikzpicture}
  \(\quad \Rightarrow \quad\)
  \begin{tikzpicture}[baseline=(current bounding box.center),
    level distance=.8cm,
    level 1/.style={sibling distance=.8cm},
    level 2/.style={sibling distance=.8cm}]
    \node {x}
    child {node {A}}
    child {node {y}
      child {node {B}}
      child {node {C}}
    };
  \end{tikzpicture}
\end{center}

Using our ownership system, the implementation of the above rotation would be:
\begin{code}
rotate :: constraint (RW n) =>. Ref Node n -> () .<= constraint (RW n)
rotate root = do
  -- create a new temporary tree for the exchange
  newRoot <- newRef Leaf

  -- swap newRoot (root.left)
  (l, x, r) <- splitTree root
  swapRefs newRoot l
  joinTree l x r

  -- swap (newRoot.right) (root.left)
  (l, x, r) <- splitTree newRoot
  (l', x', r') <- borrow root
  swapRefs r l'
  joinTree l x r >> joinTree l' x' r'

  -- swap (newRoot.right) root
  (l, x, r) <- borrow newRoot
  swapRefs root l
  joinTree l x r

  swapRefs root newRoot
  freeRef newRoot
\end{code}

The above code mixes aspects of functional and imperative styles. Like
in a functional language, we're explicitly pattern matching on nodes
structures when accessing them, using splitTree. But we can't simply
deep-match on the tree, and reconstruct it with the nodes at another
place, because the calls to |joinTree| must reflect the exact original
structure. So, we resort to local swaps, as one would do in an
imperative language.\jp{IMO we're reaching the limit of the system here.}

\subsection{Non-lexical lifetimes}
\label{sec:nl-lifetimes}

\unsure{In this section and the next, it sounds like if I'm trying to say that
  we're better than Rust or something. This isn't the intent, the intent is to
  look at Rust for inspiration for interesting examples. How do I sound less
  callous?}
In early versions of the Rust programming language, borrows were, for all
intents and purposes, bound to lexical scopes. This turned out to be too coarse
grained, rejecting natural sound programs. This became known as the problem of
non-lexical lifetimes (see \emph{e.g.}~\cite{non-lexical-lifetime-blog}). Rust
has since implemented non-lexical lifetime, however in capability-based systems,
including capabilities encoded as linear constraints, non-lexical lifetimes are
for free.

A typical example of non-lexical lifetimes consists in the following: we have a
map attaching references to keys, if a key is present we want to update the
corresponding reference, otherwise we want to create a new reference at that
key.

We can model this problem with the following \textsc{api}, where references are
taken to be arrays known to have exactly one cell.

\begin{code}
type Ref a s = UArray a s

type Map :: Type -> Reg -> Type
get ::  constraint(RW s) =>. Map v s -> Int ->
        Either (() .<= constraint(RW s)) (exists r. (Ref v r, constraint(RW r) =>. () .<= constraint(RW s)) .<= constraint(RW r))
add :: constraint(RW s) =>. Map v s -> Int -> v -> () .<= constraint(RW s)
\end{code}

The |get| function is the most interesting: if the key (here an |Int| is
absent), |get| returns the read and write permissions to the map, otherwise, it
borrows the corresponding cell. With this, we can easily write a |set| function
with the above specification.

\unsure{This is a case where we can't easily make the pack constructor disappear
  with a do notation. It's possible, but more verbose.}
\begin{code}
set :: constraint(RW s) =>. Map v s -> Int -> v -> () .<= constraint(RW s)
set vs i v = case get vs i of
  Right (pack (rv, release)) -> Linearly.do {write rv 0 v; release}
  Left (pack ()) -> add vs i v
\end{code}

The difficulty, when lifetimes are lexical, is that the borrow from |vs|, which
comes from the |case| scrutinee, remains in the |Right| branch (hence |vs| is
inaccessible here), but is written to directly in the |Left| branch. There is no
lexical scope which encompasses the scrutinee and the |Right| branch but not the
|Left| branch. With linear constraints and capabilities, it's explicit in the
type of |get| that the |Left| branch doesn't borrow, so we get this non-lexical
pattern at no cost.

\subsection{Self-referential borrows}
\label{sec:self-borrow}

Another, this one current, pattern which Rust doesn't support is what has been
known as ``self-referential borrows'' by the community. The problem is as
follow: borrowed value |b| can't outlive the (owned) value |o| it borrows from, but as
long as |o| and |b| are paired together in a record, we know that |o| doesn't
die, so |b| remains valid. A typical example is an array |o| paired with a
slice of |o|. Such a pair shouldn't have restrictions on its lifetime, but Rust
can't express the relationship between the fields.

In our presentation, this can't-outlive requirement is enforced by the release
function: as the release function is linear we must use the release function to
return, say, read and write capabilities to |o|, which must then be disposed of
some way. Until that happens, |o| lives. Making a self-referential borrow is as
easy as storing not only the original value and the borrow, but also the release
function.

\begin{code}
data Buffer s a n =
  MkBuffer :: NArray a s -> Slice a n -> (constraint(RW n) =>. () .<= constraint(RW s)) ->. Buffer s a n
\end{code}
It may be convenient to existentially quantify over the region argument |s| of
the |NArray|, making a |Buffer| look very similar to a slice.

Note that buffers define in this manner are always going to be linear values,
rather than unrestricted value with linear constraints like our arrays and
matrices so far. Here both the value and the constraints are linear. This is
because a |Buffer| contains a release function, which is always linear. It may
make |Buffer| less convenient to use than it should, we revisit this aspect
in~\cref{sec:unrestricted-release}.

\subsection{Capabilities in monadic computations}
\label{sec:monad-capability}


\subsection{Former intro}
\change{All the section, below this point, is to be removed, integrating
  whatever we feel like}
Let us now turn back to the more substantial example introduced in
\cref{sec:introduction}: manual memory management.  In functional programming
languages like Haskell, memory deallocation is normally the responsibility of a
garbage collector. However, garbage collection is
not always desirable, either due to its (unpredictable) runtime costs, or because
pointers exist between separately-managed memory spaces
(for example when calling foreign functions~\cite{linear-inline-java}).
In either case, one must then
resort to explicit memory allocation and deallocation. This task is
error prone: one can easily forget a deallocation (causing a memory
leak) or deallocate several times (corrupting data). In this section we show how
to build a % Rust-style % tone down Rust fetishism. It's already mentioned just below.
memory management \textsc{api} as a \emph{library} using linear
constraints. The library is a generalisation of the array library
introduced in \cref{sec:introduction}.

\subsection{Capability Constraints}
\label{sec:atomic-references}

Our approach, inspired by Rust, is
to represent \emph{ownership} of a memory location, and more specifically,
whether the reference is mutable or read-only.
We use the linear constraints |constraint(Read n)| and |constraint(Write n)|,
guarding read access and write access to a reference respectively.
Because of linearity, these constraints
must be consumed, so the \textsc{api} can guarantee that memory
is deallocated correctly.
%
In |constraint(Read n)|, |n| is a type variable (of a special kind |Location|)
which represents a memory location. Locations mediate
the relationship between references and ownership constraints.
%

\begin{minipage}{0.5\linewidth}
> class constraint (Read (n :: Location))
\end{minipage}
\begin{minipage}{0.5\linewidth}
> class constraint (Write (n :: Location))
\end{minipage}
% \begin{minipage}{0.3\linewidth}
% > class constraint (Own (n :: Location))
% \end{minipage}
\\
To ensure referential transparency,
writes can be done only when we are sure that no other part of the program has
read access to the reference.
% Rust disallows mutable aliasing for the same reason: ensuring that writes cannot be observed through other references is what allows treating mutable structures as ``pure''.
% jp: commented this tangent because it obscures the logical connection. It could perhaps go in a parenthesis
Therefore, writing also requires the read capability. Thus we
systematically use |constraint(RW n)|, pairing both the read and write
capabilities.

With these components in place, we can provide an \textsc{api} for mutable
references.

> data AtomRef (a :: Type) (n :: Location)

The type |AtomRef| is the type of references to values of a type |a| at
location |n|. Allocation of a reference can be done using the
following function. % As with |new|, the return value must be unrestricted.

> newRef :: constraint (Unique) =>. exists n. AtomRef a n .<= constraint (RW n)

The function |newRef| creates a new atomic reference, initialised with
|undefined|; we could also pass in an initial value, but doing so in the more
general case below would add complication and obscure our main goal of demonstrating
linear constraints.

To read a reference, a |constraint(Read)| constraint is demanded, and
then returned back. Writing is similar.

> readRef :: constraint (Read n) =>. AtomRef a n -> Ur a .<= constraint (Read n)
> writeRef :: constraint (RW n) =>. AtomRef a n -> a -> () .<= constraint (RW n)

Note that the above primitives do not need to explicitly declare
effects in terms of a monad or another higher-order effect-tracking
device: because the |constraint(RW n)| constraint is linear, passing it suffices
to ensure proper sequencing of effects concerning location |n|.

Also note that |readRef| returns an unrestricted \emph{copy} of the element, and
|writeRef| \emph{copies} an unrestricted element into the location. This means
that while |AtomRef|s are mutable, their contents are always immutable structures.

% This is ensured by the combination of the language and library
% behaviour. For example, here is how to write two values (|a| and |b|) to the same reference |x|:

% > case writeRef x a of
% >   pack _ -> case writeRef x b of
% >     pack _ -> ...

% The language semantics forces the programmer to do case analysis to
% access the returned |Write| constraints, and |writeRef| must be strict
% in the |Write| constraint that it consumes.

Since there is a unique |constraint(RW n)| constraint per reference, we
can also use it to represent ownership of the reference: access to |constraint(RW
n)| represents responsibility (and obligation) to deallocate |n|:

> freeRef :: constraint (RW n) =>. AtomRef a n -> ()

% Instead of deallocating the reference, one could transfer ownership
% of the memory location to the garbage collector. This operation is
% sometimes called ``freezing'':

% > freezeRef :: constraint (RW n) =>. AtomRef a n -> Ur a

\subsection{Arrays}
\label{sec:arrays}

The above toolkit handles references to base types just fine.  But
what about storing references in objects managed by the ownership
system? In \cref{sec:introduction}, we presented an interface for mutable
arrays whose contents are themselves immutable. Our approach
scales beyond that use case, supporting arrays of
references, including arrays of (mutable) arrays.

% JP: the discussion below sounds quite petty. Not many (zero
% non-conflicting?)  people will be aware of the issue with linear
% arrays. So it would need a lot more space to be properly
% justified. Besides, the issue of storing references in structures
% should be motivation enough in general.

% A motivating example of plain Linear Haskell is a pure interface to
% mutable arrays~\cite[Section 2.2]{LinearHaskell}. There we have two
% types: first |MArray a|, used linearly, for mutable arrays; and
% second |Array a|, used unrestricted, for immutable arrays. Mutable
% arrays can be frozen using |freeze :: MArray a ->. Ur (Array
% a)|. Note that this version of |freeze| can not support mutable
% arrays of mutable arrays.  The core of the issue is that mutable
% arrays and immutable arrays have different types.
% The ownership \textsc{api}, on the other hand, is readily extended to
% nested mutable arrays.
% Crucially, and in contrast to the plain linear types \textsc{api} the
% type |PArray| is both the type of mutable arrays and immutable arrays,
% |freezePArray| only changes the permissions. And since permissions are
% linear constraints, this is all managed automatically by the compiler.

> data PArray (a :: Location -> Type) (n :: Location)
> newPArray :: constraint (Unique) =>. Int -> exists n. PArray a n .<= constraint (RW n)

For this purpose we introduce the type |PArray a n|, where the kind of
|a| is |Location -> Type|: this way we can easily enforce that each
reference in the array refers to the same location |n|. Both types
|AtomRef a| and |PArray a| have kind |Location -> Type|, and therefore
one can allocate, and manipulate arrays of arrays with this
\textsc{api}. For example, an array of integers has type
|PArray (AtomRef Int) n|, and indeed, the |UArray| type from
\cref{sec:introduction} is a synonym for an array of atomic references.\jp{Can we have the definition?}
An array of arrays of integers has type |PArray (PArray (AtomRef Int)) n|. Thus,
the framework handles nested mutable structures without any additional
difficulty. %% As discussed in \cref{sec:what-it-looks-like}, the scope of |newPArray| returns
%% an unrestricted value to ensure that the linear constraint is consumed within
%% the scope (since linear values cannot be embedded into an unrestricted value).
%% As this is the only introduction form of |constraint (RW n)|, it can safely be
%% assumed to be unique within the scope. An alternative design would be to
%% require that the scope returns the linear constraint: |forall n. constraint (RW
%% n) =>. PArray a n -> b .<= constraint (RW n)|. This version is less flexible,
%% because it doesn't allow the scope to deallocate or freeze the array.

The actual runtime value of a |PArray| is a pointer to a contiguous block of
memory together with the size of the memory block. This means that the length of the
array can be accessed without having ownership of the array: |length :: PArray a n -> Int|.
While the |PArray| reference itself is managed by the garbage collector, the
pointer it contains points to manually managed memory.

% JP: I propose to cut down the following, since it appears unused in the rest of the paper.
% (The "quicksort" example is a lot more convincing as an example)

% For the special case where the array stores atomic references (|UArray|) which we know how
% to deallocate, the |write| function can be implemented using |replace|:


% > write :: constraint (RW n) =>. UArray a n -> Int -> a -> () .<= constraint (RW n)
% > write arr i x =
% >   let   pack' ref = newRefBeside arr
% >         pack () = writeRef ref x
% >         pack () = replace arr i ref
% >   in freeRef ref

% Because having access to a |constraint(RW n)| is proof that we are inside a scope
% with a unique resource, we can also allocate a reference to the same scope as |n|:

% > newRefBeside :: constraint (RW n) =>. a n -> exists m. Ur (AtomRef m) .<= constraint ((RW n, RW m))

% \csongor{I think this is now the first time we talk about existentials? Need to be careful not to forget introducting them}

\subsubsection{Borrowing}

The |lendMut arr i k| primitive lends access to the reference at index |i| in
|arr|, to a continuation function |k| (in Rust terminology, the function
\emph{borrows} an element of the array). Note that the continuation must return the
read-write capability, so that the ownership transfer is indeed temporary. The
type system guarantees that the borrowed reference cannot be shared or deallocated.\jp{Ok, but what we want to know is how the type achieves this; perhaps we again need to state that the constraints themselves are only ``borrowed''}
%
% Here, the return type of the scope, |r|,
% is not in |Ur|: since the scope must return the |constraint(RW p)| constraint, it is
% not possible to leak it out by packing it into |r|, so it's not necessary to
% wrap the result in |Ur|.
Indeed, with this \textsc{api}, |constraint(RW n)| and |constraint(RW p)| are
never simultaneously available.

> lendMut  :: constraint (RW n) =>. PArray a n -> Int -> (forall p. ^^ constraint (RW p) =>. a p -> r .<= constraint (RW p)) ⊸ r .<= constraint (RW n)
%
Because the elements of an array can be mutable structures (such as
other arrays), reading can be done safely only if we can ensure that
no one else has access to the array while the element is accessed. Otherwise,
the array -- including the element being read -- could be mutated. \jp{This isn't very clear. I believe it should be recalled that all the array contents recursively share the same location}
Therefore,
gaining simple read access to an element needs to be done using a
scoped \textsc{api} as well:

> lend  ::  constraint (Read n) =>. PArray a n -> Int ->  (forall p. ^^ constraint (Read p) =>. a p -> r .<= constraint (Read p)) ⊸ r .<= constraint (Read n)

For the special case of |UArray|s, a more traditional reading
operation can be implemented, by lending the reference to |readRef|
which creates an unrestricted \emph{copy} of the value. This copy is
under control of the garbage collector, and can escape the scope of
the borrowing freely.

> read :: constraint (Read n) =>. UArray a n -> Int -> Ur a .<= constraint (Read n)
> read arr i = lend arr i readRef


% \subsubsection{Freezing}

% Finally, we can freeze arrays, using the
% following primitive:

% > freezePArray :: constraint (RW n) =>. PArray a n -> () .<= constraint (omega ⋅ (Read n))

% Where |constraint(omega ⋅ (Read n))| means that the returned constraint is not linear. That is, after |freezePArray n|, we have unrestricted read access to |n| (and
% any element of |n|), as expected. We describe this syntax in more
% details in the next
% section, where, similarly, we shall treat |constraint(Read n) =>| as
% an abbreviation for |constraint(omega ⋅ (Read n)) =>.|.

% With an unrestricted |constraint(Read n)| capability, we can read from the array
% more directly with the following primitive

% > readP :: constraint (Read n) => PArray a n -> Int -> a n

\subsubsection{Slices}

It is also possible to give a safe interface to array
\emph{slices}. A slice represents a part of an array and allows
splitting the ownership of the array into multiple parts,
shared between different consumers.  The ownership system
means that slicing does not require copying.

Splitting consumes all capabilities of an array and returns two new
arrays that represent the contiguous blocks of memory before and
starting at a given index.

> split :: constraint (RW n) =>. PArray a n -> Int -> exists l r. Ur (PArray a l, PArray a r) .<= constraint ((RW l, RW r, Slices n l r))

In addition to the array capabilities, the output constraints also include
|constraint (Slices n l r)|, witnessing the fact that locations
|l| and |r| are components of |n|, so that they can be joined back
together:

> join :: constraint ((Slices n l r, RW r, RW l)) =>. PArray a l -> PArray a r -> Ur (PArray a n) .<= constraint (RW n)

%format a_i_val = a_i "\_val"
%format a_j_val = a_j "\_val"
\begin{figure}
\maybesmall
\begin{code}
swap :: constraint(RW n) =>. PArray AtomRef n -> Int -> Int -> () .<= constraint(RW n)
swap arr i j  | i == j   =  pack ()
              | i > j    =  swap arr j i
              | i < j    =  let   pack (Ur (l, r))  =  split arr (i + 1)
                                  pack ()           =  lendMut l i (\a_i ->
                                                         let pack () = lendMut r (j - (i + 1)) (\a_j ->
                                                           let  pack (Ur a_i_val)  =  readRef a_i
                                                                pack (Ur a_j_val)  =  readRef a_j
                                                                pack ()            =  writeRef a_j a_i_val
                                                                pack ()            =  writeRef a_i a_j_val
                                                           in pack ()) in pack ())
                                  pack (Ur _)       =  join l r
                            in pack ()
\end{code}
\caption{Swapping two elements of an array}
\label{fig:swap}
\end{figure}


With these building blocks, we can now implement various utility functions on
arrays, such as swapping two elements of an array, which is shown in
\Cref{fig:swap}.  It is
not so simple to implement\footnote{Indeed, Rust's implementation uses
an \emph{unsafe} block.}\jp{is the statement of the footnote this still current? We should specify which version of Rust we're talking about.}, because we need two elements of an array
simultaneously, but only one element can be borrowed at a time.\jp{This is because, essentially, borrowing an element actually borrows the whole array. The reader might expect something more flexible here.} To
solve this problem, we split the array into two slices such that the
two indices fall in two different slices. Then simply borrow the
element |i| from the first slice, and |j| from the second slice (using
|lendMut|). Finally, we join the two slices back together.

\subsubsection{In-Place Quicksort}

As an example of using the machinery defined above, we implement an in-place, pure
quicksort algorithm, given in \Cref{fig:quicksort}.
%
\begin{figure}
\maybesmall
\noindent
\begin{minipage}[t]{0.45\linewidth}
\begin{code}
sort :: constraint (RW n) =>. UArray Int n -> () .<= constraint (RW n)
sort arr = let len = length arr in
  if len <= 1 then pack ()
  else   let  pack pivotIdx       =  partition arr
              pack (Ur (l, r))    =  split arr pivotIdx
              pack ()             =  sort l
              pack ()             =  sort r
              pack (Ur _)         =  join l r
         in pack ()
\end{code}
\end{minipage}
\begin{minipage}[t]{0.4\linewidth}
\begin{code}
partition :: constraint (RW n) =>. UArray Int n -> Int .<= constraint (RW n)
partition arr =
  let  last             =  length arr - 1
       pack (Ur pivot)  =  read arr last
       go :: constraint (RW n) =>. Int -> Int -> Int .<= constraint (RW n)
       go l r
         |  l > r
         =  let pack () = swap arr last l in pack l
         |  otherwise
         =  let pack (Ur lVal) = read arr l in
            if lVal > pivot
            then  let pack () = swap arr l r
                  in go l (r - 1)
            else  go (l + 1) r
  in go 0 (last - 1)
\end{code}
\end{minipage}
\caption{In-place quicksort}
\label{fig:quicksort}
\end{figure}
%
The |partition| function is responsible for picking a pivot element and
reorganising the array elements such that each element preceding the pivot will
be less than or equal to it, and the elements after will be greater than the
pivot. Once finished, it returns the index of the pivot element; |sort| then
splits the array at the pivot element and recursively operates on the two
slices.


\section{A qualified type system for linear constraints}
\label{sec:qualified-type-system}

We
now present our design for a qualified type system~\cite{QualifiedTypes} that supports
linear constraints. Our design, based on the work of \citet{OutsideIn}, is compatible with Haskell and \textsc{ghc}.


\subsection{Simple Constraints and Entailment}
\label{sec:constraint-domain}

We call constraints such as
|constraint(Read n)| or |constraint(Write n)| \emph{atomic
  constraints}. The set of atomic constraints is a parameter of our
qualified type system.

\begin{definition}[Atomic constraints]
  The qualified type system is parameterised by a set, whose elements
  are called \emph{atomic constraints}. We use the variable $[[{q}]]$
  to denote atomic constraints.
\end{definition}

Atomic constraints are assembled into \emph{simple constraints}
$[[{Q}]]$, which play the hybrid role of constraint contexts and
(linear) logic formulae.
The following operations work with simple constraints:
\begin{description}
\item[Scaled atomic constraints] $[[{pi.q}]]$ is a simple constraint,
  where $[[{pi}]]$ specifies whether $[[{q}]]$ is to be used linearly
  or not.
\item[Conjunction] Two simple constraints can be paired up
  $[[{Q1 * Q2}]]$. Semantically, this corresponds to the multiplicative
  conjunction of linear logic. Tensor products represent pairs of
  constraints such as |constraint((Read n, Write n))| from Haskell.
\item[Empty conjunction] Finally we need a neutral element
  $[[{Empty}]]$ to the tensor product. The empty conjunction is used
  to represent functions which don't require any constraints.
\end{description}
%
However, we do not define $[[{Q}]]$ inductively, because we
require certain equalities to hold:

\smallskip
\begin{minipage}[c]{0.5\linewidth}
$$
\begin{array}{rcl}
  [[{Q1 * Q2}]] & = & [[{Q2 * Q1}]] \\
  [[{(Q1*Q2)*Q3}]] & = & [[{Q1*(Q2*Q3)}]]
\end{array}
$$
\end{minipage}
\begin{minipage}[c]{0.4\linewidth}
$$
\begin{array}{rcl}
  [[{omega.q * omega.q}]] & = & [[{omega.q}]] \\
  [[{Q * Empty}]] & = & [[{Q}]]
\end{array}
$$
\end{minipage}
\smallskip

We thus say that a simple constraint is a pair combining a set of unrestricted
constraints $[[{UCtx}]]$ and a multiset of linear constraints $[[{LCtx}]]$.
The linear constraints must
be stored in a multiset, because assuming the same constraint twice is distinct
from assuming it only once.

\begin{definition}[Simple constraints]
$$
\begin{array}{rcll}
  [[{UCtx}]] & \bnfeq & \ldots & \text{set of atomic constraints $[[{q}]]$} \\
  [[{LCtx}]] & \bnfeq & \ldots & \text{multiset of atomic constraints $[[{q}]]$} \\
  [[{Q}]] & \bnfeq & [[{(UCtx,LCtx)}]] & \text{simple constraints}
\end{array}
$$
We can now straightforwardly define the operations we need on simple
constraints:
$$
\begin{array}{ccc}
  \begin{array}{r@@{\;}c@@{\;}l}
    [[{Empty}]] &=& [[{(emptyset, emptyset)}]]
  \end{array}
  &
    \left\{
    \begin{array}{r@@{\;}c@@{\;}l}
      [[{1.q}]] &=& [[{(emptyset, q)}]] \\
      [[{omega.q}]] &=& [[{(q, emptyset)}]]
    \end{array}
                        \right.
  &
    \begin{array}{r@@{\;}c@@{\;}l}
      [[{(UCtx1,LCtx1)*(UCtx2,LCtx2)}]] &=& [[{(UCtx1 \u UCtx2, LCtx1 \u LCtx2)}]]
    \end{array}
\end{array}
$$
\end{definition}

In practice, we do not need to concern ourselves with the
concrete representation of $[[{Q}]]$ as a pair of sets, instead
using the operations defined just above.

The semantics of simple constraints (and, indeed, of atomic
constraints) is given by an \emph{entailment relation}. Just like the
set of atomic constraints, the entailment relation is a parameter of
our system.

\begin{figure}
  \maybesmall
  \begin{enumerate}
  \item $[[Q ||- Q]]$.
  \item If $[[Q1 ||- Q2]]$  and $[[Q * Q2 ||- Q3]]$, then $[[Q * Q1 ||- Q3]]$.
  \item If $[[Q ||- Q1 * Q2]]$, then there exist $[[{Q'}]]$, $[[{Qdup}]]$, and $[[{Q''}]]$
        such that:
        $$
         [[Qdup \in Dup]], \quad [[{Q}]]=[[{Q' * Qdup * Q''}]], \quad [[Q' * Qdup ||- Q1]]\text{, and } \quad
        [[Qdup * Q'' ||- Q2]].
        $$
  \item If $[[Q ||- Empty]]$, then $[[Q \in Dup]]$.
  \item If $[[Q1 ||- Q1']]$ and $[[Q2 ||- Q2']]$, then $[[Q1 * Q2 ||- Q1' * Q2']]$.
  \item If $[[Q ||- rho. q]]$, then $[[pi . Q ||- (pi.rho). q]]$.
  \item If $[[Q ||- (pi.rho) . q]]$, then there exists $[[{Q'}]]$ such that $[[{Q}]] = [[{pi. Q'}]]$ and $[[Q' ||- rho . q]]$.
  \item If $[[Q1 ||- Q2]]$, then $[[omega.Q1 ||- Q2]]$.
  \item If $[[Q1 ||- Q2]]$, then for all $[[{Q'}]]$, it is the case that $[[omega.Q' * Q1 ||- Q2]]$.
  \item If $[[q \in Dup]]$, then $[[1.q ||- 1.q * 1.q]]$.
  \item If $[[q \in Dup]]$, then $[[1.q ||- Empty]]$.
  \item If $[[Q \in Dup]]$ and $[[Q' ||- Q]]$, then $[[Q' \in Dup]]$.
  \end{enumerate}
\caption{Requirements for the entailment relation $[[Q1 ||- Q2]]$}
\label{fig:entailment-relation}
\end{figure}
\jp{In the requirements, the RHS of entailment has a variable form. Clarify.}
\begin{definition}[Entailment relation]
  \label{def:entailment-relation}
  The qualified type system is parameterised by a relation
  $[[Q1 ||- Q2]]$ between two simple constraints, as well as by a
  distinguished set $[[{Dup}]]$ of duplicable atomic constraints.

  We write, abusing notation, $[[Q \in Dup]]$ for a simple constraint
  $[[{Q}]]=[[{(UCtx, LCtx)}]]$ if for all $[[{q}]]\in[[{LCtx}]]$ we
  have $[[q \in Dup]]$. \jp{How about writing using set inclusion?}

  The entailment relation must obey the laws listed in
  \Cref{fig:entailment-relation}.
\end{definition}
%
\info{See Fig 3, p14 of OutsideIn\cite{OutsideIn}.}
%
The set $[[{Dup}]]$ is a set of constraints which can be duplicated and
discarded (see~\cref{fig:entailment-relation}). We use $[[{Dup}]]$ to
model the |constraint(Unique)| constraint. Crucially, it is \emph{not
  the case} that $[[1.q ||- omega.q]]$ for $[[q\in Dup]]$; such an
entailment is, in fact, prohibited (\cref{lem:q:scaling-inversion}) by
the rules of~\cref{fig:entailment-relation}. While it may seem
counter-intuitive, there is nothing in linear logic mandating that a
formula that can be duplicated and discarded be (equivalent to) an
unrestricted formula. This observation has been exploited, for
instance, to introduce so-called
subexponentials~\cite{subexponentials}. For our use case, it lets the
typechecker dispatch |constraint(Unique)| constraints (using
duplication), but prevents the result of constrained functions to be used
unrestrictedly.

An important feature of simple constraints is that, while scaling
syntactically happens at the level of atomic constraints, these properties
of scaling extend to scaling of arbitrary constraints. Define
$[[{pi.Q}]]$ as:

$$
                      \left\{
                      \begin{array}{r@@{\;}c@@{\;}l}
                        [[{1.(UCtx,LCtx)}]] &=& [[{(UCtx,LCtx)}]] \\
                        [[{omega.(UCtx,LCtx)}]] &=& [[{(UCtx \u LCtx, emptyset)}]]
                      \end{array}
                                                    \right.
$$
%
Then the following properties hold
%
\begin{lemma}[Scaling]
  \label{lem:q:scaling}
  If $[[Q1 ||- Q2]]$, then $[[pi.Q1 ||- pi.Q2]]$.
\end{lemma}

\begin{lemma}[Inversion of scaling]
  \label{lem:q:scaling-inversion}
  If $[[Q1 ||- pi.Q2]]$, then $[[{Q1}]]=[[{pi.Q'}]]$ and $[[Q' ||- Q2]]$ for some $[[{Q'}]]$.
\end{lemma}

\begin{corollary}[Linear assumptions]
If $[[Q1 ||- omega.Q2]]$, then $[[{Q1}]]$ contains no linear assumptions.
\end{corollary}

Proofs of these lemmas (and others) appear in Appendix~\ref{sec:appendix:proofs-lemmas};
they can be proved by straightforward use of the properties in \Cref{fig:entailment-relation}.

\subsection{Typing Rules}
\label{sec:typing-rules}

With this material in place, we can now present our type system. The
grammar is given in \Cref{fig:declarative:grammar}, which also
includes the definitions of scaling on contexts $[[{pi.G}]]$ and addition
of contexts $[[{G1+G2}]]$. Note that addition on contexts is actually
a partial function, as it requires that, if a variable $[[{x}]]$ is bound
in both $[[{G1}]]$ and $[[{G2}]]$, then $[[{x}]]$ is assigned the same
type in both (but perhaps different multiplicities). This partiality
is not a problem in practice, as the required condition for combining
contexts is always satisfied.

\begin{figure}
  \maybesmall
  $$
  \begin{array}{@@{}c@@{}}
  [[{a}]], [[{b}]] \quad \text{Type vars} \qquad
  [[{x}]], [[{y}]] \quad \text{Expression vars} \qquad
  [[T]] \quad \text{Type constructors} \qquad
  [[{K}]] \quad \text{Data constructors} \\
  \begin{array}[b]{lcll}
    % [[{a}]], [[{b}]] & \bnfeq & \ldots & \text{Type variables} \\
    % [[{x}]], [[{y}]] & \bnfeq & \ldots & \text{Expression variables} \\
    % [[T]] & \bnfeq & \ldots & \text{Type constructors} \\
    % [[{K}]] & \bnfeq & \ldots & \text{Data constructors} \\
    [[{s}]] & \bnfeq & [[{forall as. Q =o t}]] & \text{Type schemes} \\
    [[{t}]], [[{u}]] & \bnfeq & [[{a}]] \bnfor [[{exists as. t o= Q}]] \bnfor [[{t1 ->_pi t2}]]
                            \bnfor [[{T ts}]] & \text{Types} \\
    [[{G}]], [[{D}]] & \bnfeq & [[{empty}]] \bnfor [[{G, x:_pi s}]] &
                                                              \text{Contexts} \\
    [[{e}]] & \bnfeq & [[{x}]] \bnfor [[{K}]] \bnfor [[{\x. e}]] \bnfor [[e1
                     e2]] \bnfor [[{pack e}]] & \text{Expressions}\\
                 &\bnfor & [[unpack x=e1 in
                     e2]] \bnfor [[{case_pi e of { alts }}]] &\\
                 &\bnfor & [[let_pi
                     x=e1 in e2]] \bnfor [[{let_pi x : s = e1 in e2}]] &
  \end{array} \\[1ex]
  \end{array}
  $$
  Context scaling $[[{pi.G}]]$ and addition of contexts $[[{G1+G2}]]$ is defined as follows:
  $$
  \begin{array}{cc}
  \left\{
  \begin{array}{r@@{\;}c@@{\;}l}
  [[{pi.empty}]] &=& [[{empty}]] \\
  [[{pi.(G,x:_rho s)}]] &=& [[{pi.G, x:_( pi.rho ) s}]]
  \end{array}
  \right.
  &
  \left\{
  \begin{array}{r@@{\;}c@@{\;}lll}
  [[{(G1, x:_pi s) + G2}]] &=& [[{ G1 + G2', x:_( pi+rho ) s }]] & \text{where} & [[G2 = {x:_rho s} \u G2']] \\
  &&&& [[x \notin G2']] \\
  [[{(G1, x:_pi s) + G2}]] &=& [[{ G1 + G2, x:_pi s }]] & \text{where} & [[x \notin G2]] \\
  [[{empty + G2}]] &=& [[{G2}]]
  \end{array}
  \right.
  \end{array}
  $$
  \caption{Grammar of the qualified type system}
  \label{fig:declarative:grammar}
\end{figure}

\begin{figure}
  \centering
  \drules[E]{$[[Q;G |- e : t]]$}{Expression
    typing}{Var,Abs,App,Pack,Unpack,Let,LetSig,Case,Sub}
  \caption{Qualified type system}
  \label{fig:typing-rules}
\end{figure}
\jp{in the above figure; I'm unclear if only having linear variable occurences is enough. omega is convertible to 1, but where is this captured? }

The typing rules are in \Cref{fig:typing-rules}.
A qualified type system~\cite{QualifiedTypes} such as ours introduces a
judgement of the form $[[Q;G |- e : t]]$, where $[[{G}]]$ is a standard
type context, and $[[{Q}]]$ is a constraint we have assumed to be true.
$[[{Q}]]$ behaves
much like $[[{G}]]$, which will be instrumental for
desugaring in \cref{sec:desugaring}; the main difference is
that $[[{G}]]$ is addressed explicitly, whereas $[[{Q}]]$
is used implicitly in \rref{E-Var}.

Because constraints are used implicitly, if there are several instances
of the same $[[{1.q}]]$\jp{it is unclear to me why there is an explicit scaling by 1 here}, it is non-deterministic which one is used in
which instance of \rref*{E-Var}. As a consequence, we must require
that any two instances of $[[{1.q}]]$ in a constraint $[[{Q}]]$ have
the same computational content (see \cref{sec:desugaring}). How do we
reconcile this non-determinism with the use of linear constraints, in
\cref{sec:arrays} to thread mutations?\jp{reconcile ... with ?} We certainly don't want type
inference to non-deterministically reorder a |readRef| and a
|writeRef|! The solution is that the \textsc{api} is arranged so that
only a single instance of |constraint(RW n)| is ever
provided. Therefore there is a single possible threading of the reads
and writes. In contrast there will often be several instances of
|Unique| in scope.

The type system of \Cref{fig:typing-rules} is purely
declarative: note, for example, that \rref{E-App} does not describe
how to break the typing assumptions into constraints
$[[{Q1}]]$/$[[{Q2}]]$ and contexts $[[{G1}]]$/$[[{G2}]]$. We will see
how to infer constraints in \cref{sec:type-inference}. Yet,
this system is our ground truth: a system with a simple enough
definition that programmers can reason about typing.\jp{about typing but not operational meaning? I'm unclear here.} As is standard in
the qualified-type literature (since the original paper~\cite{QualifiedTypes}), we do not
directly give a dynamic
semantics to this language; instead, we will give it meaning via
desugaring to a simpler core language in \cref{sec:desugaring}.

We survey several distinctive features of our qualified type system below:

\info{See Fig 10, p25 of OutsideIn\cite{OutsideIn}.}
\paragraph*{Linear functions.}
The type of linear functions is written $[[{a ->_1 b}]]$.
  Despite our focus on linear constraints,
  we still need linearity in ordinary arguments.
%
  Indeed, the linearity of arrows interacts in interesting
  ways with linear constraints: If $[[f : a ->_omega b]]$ and
  $[[x : 1.q =o a]]$, then calling $[[{f x}]]$ would actually use $[[{q}]]$
  many times. We must make sure it is impossible to derive
  $[[1.q ; f :_omega a ->_omega b, x :_omega 1.q =o a |- f x : b]]$.
  Otherwise we could make, for instance, the |overusing| function from
  \cref{sec:overusing}.
  You can check that $[[1.q ; f :_omega a ->_omega b, x :_omega 1.q =o a |- f x : b]]$
  indeed does not
  type check, because the scaling of $[[{Q2}]]$ in \rref{E-App} ensures that
  the constraint would be $[[{omega.q}]]$ instead. On the other hand,
  it is perfectly fine to have $[[1.q ; f :_omega a ->_1 b, x :_omega 1.q
  =o a |- f x : b]]$ when $[[{f}]]$ is a linear function.

\paragraph*{Variables.}
As is standard, the \rref{E-Var} rule works in a context containing more
than just the used binding for $[[{x}]]$. However, crucially,
our rule allows only
\emph{unrestricted} variables to be discarded; linear variables \emph{must} be
used. We can see this in the rule by noticing that the context has an unrestricted
component $[[{omega.G_2}]]$. The $[[{G1}]]$ component might be restricted or might not,
allowing this rule to apply both for restricted and unrestricted $[[{x}]]$.

\paragraph*{Data constructors.}
Data constructors $[[{K}]]$ don't have a dedicated typing
rule. Instead they are typed using the \rref{E-Var}, where they are
treated as if they were unrestricted variables.

\paragraph*{Let-bindings.}
Bindings in a |let| may be for either linear or unrestricted variables.
  We could require all bindings to be linear and to implement unrestricted
  information only using |Ur|, but it is very easy to add a multiplicity
  annotation on |let|, and so we do.

\paragraph*{Local assumptions.}
\Rref{E-Let} includes support for local
  assumptions. We thus have the ability to generalise a subset of
  the constraints needed by $[[{e1}]]$ (but not the type variables---no
  |let|-generalisation here, though it could be added). The inference algorithm of
  \cref{sec:type-inference} will not make use of this
  possibility. % but we revisit this capability in \cref{sec:let-generalisation}.
%% \item Data types are not \textsc{gadt}s.
%%   This serves to considerably simplify the \rref*{E-Case}
%%   rule. It would be
%%   straightforward, yet tedious, to extend data types here to full
%%   \textsc{gadt}s.

\paragraph*{Existentials.}
 We include $[[{exists as. t o= Q}]]$, as
  introduced in \cref{sec:what-it-looks-like}, together with
  the $\packbox$ constructor. See rules~\rref*{E-Pack} and
  \rref*{E-Unpack}.
\info{No substitution on $[[{Q1}]]$ in the E-Unpack rule, because there is
  only existential quantification.}

\section{Constraint inference}
\label{sec:type-inference}

The type system of \Cref{fig:typing-rules} gives a declarative description
of what programs are acceptable. We now present the algorithmic counterpart to
this system. Our algorithm is structured, unsurprisingly, around generating and
solving constraints, broadly following the template of
\citet{essence-of-ml-type-inference}.
That is, our algorithm takes a pass over the abstract syntax entered by the
user, generating constraints as it goes. Then, separately, we solve those
constraints (that is, try to satisfy them) in the presence of a set of assumptions,
or we determine that the assumptions do not imply that the constraints hold. In the
latter case, we issue an error to the programmer.

The procedure is responsible for inferring both \emph{types} and \emph{constraints}.
For our type system, type inference can be done independently from constraint
inference. Indeed, we focus on the latter, and defer type inference to
an external oracle (such as~\cite{linear-types-inference}).
That is, we assume an algorithm that produces typing derivations for the
judgement $[[G |- e : t]]$, ignoring all the constraints. Then, we describe a
constraint generation algorithm that passes over these typing derivations.
%
% A typical generate-and-solve algorithm is built around unification variables.
% A unification variable stands for some unknown type. When we see, for example,
% |\x -> ...|, we let the type of |x| be a unification variable, and then
% constraints arising from the body of the expression (or its context) might tell
% us that the unknown type is |Int|. Our system does not do this, however:
% using constraints to solve for unification variables is well understood~\cite{OutsideIn}
% and orthogonal to the concerns that drive the innovations in this paper.
% Instead, the description of the aspects of our algorithm regarding inferring types---as opposed to
% inferring \emph{constraints}---nondeterministically just guess the correct
% type. A real implementation would use unification variables and constraints,
% but they just add clutter here and distract us from the novel parts of our
% algorithm.
%
We can make this simplification for two reasons:
\begin{itemize}
\item We do not formalise type equality constraints, and our implementation
  in \textsc{ghc} (\cref{sec:equality-constraints}) takes care to not allow linear equality constraints to influence type inference.
  Indeed, a typical treatment of unification
  would be unsound for linear equalities, because it reuses the same
  equality many times (or none at all). Linear equalities make sense
  (\citet{shulman2018linear} puts linear
  equalities to great use), but they do not seem to lend themselves to
  automation.
\item We do not support, or intend to support, multiplicity
  polymorphism in constraint arrows. That is, the multiplicity of a
  constraint is always syntactically known to be either linear or
  unrestricted. This way, no equality constraints (which might, conceivably,
  relate multiplicity variables) can interfere with
  constraint resolution.
\end{itemize}
%
%% Our current focus is more narrow than a general typechecking algorithm for
%% all of \textsc{ghc}'s features.
%% As a consequence of these two restrictions (no linear equalities and no
%% multiplicity polymorphic constraints), type inference and (linear) class
%% constraint resolution are completely orthogonal. Therefore, the syntax-directed
%% constraint generation system presented in this section can legitimately assume
%% that type inference is solved elsewhere, greatly simplifying the presentation.


\subsection{Wanted Constraints}
\label{sec:wanteds}

The constraints $[[{C}]]$ generated in our system have a richer
logical structure than the simple constraints $[[{Q}]]$, above. Following
\textsc{ghc} and echoing \citet{OutsideIn}, we call these \emph{wanted constraints}:
they are constraints which the constraint solver \emph{wants} to prove.
An unproved wanted constraint results in a type error reported to the programmer.
%
$$
\begin{array}{lcll}
  [[{C}]] & \bnfeq & [[{Q}]] \bnfor [[{C1*C2}]] \bnfor [[{C1&C2}]] \bnfor [[{pi.(Q=>C)}]]&
                                                                \text{Wanted constraints}
\end{array}
$$
%
A simple constraint is a valid wanted constraint, and we have two forms of
conjunction for wanted constraints:
the new
$[[{C1 & C2}]]$ construction (read $[[{C1}]]$ \emph{with} $[[{C2}]]$), alongside
the more typical $[[{C1 * C2}]]$. These are
connectives from linear logic: $[[{C1*C2}]]$ is the
\emph{multiplicative} conjunction, and $[[{C1&C2}]]$ is the \emph{additive}
conjunction. Both connectives are conjunctions, but they differ
% rather dramatically % weasel words combo
in meaning. To satisfy $[[{C1*C2}]]$ one consumes the (linear)
assumptions consumed by satisfying $[[{C1}]]$ and those consumed by $[[{C2}]]$;
if an assumed linear constraint is needed to prove both $[[{C1}]]$ and $[[{C2}]]$,
then $[[{C1*C2}]]$ will not be provable, because that linear assumption cannot
be used twice. On the
other hand, satisfying $[[{C1&C2}]]$ requires that satisfying $[[{C1}]]$
and $[[{C2}]]$ must each
consume the \emph{same} assumptions, which $[[{C1 & C2}]]$ consumes as well.
Thus, if $[[{C}]]$ is assumed linearly (and we have no other assumptions),
then $[[{C*C}]]$ is not provable, while $[[{C&C}]]$ is.
The intuition, here, is that in $[[{C1 & C2}]]$, only
one of $[[{C1}]]$ or $[[{C2}]]$ will be eventually used. ``With'' constraints
arise from the branches in a $\kcase$-expression.

The last form of wanted constraint $[[{C}]]$ is an implication
$[[{pi.(Q=>C)}]]$. The more interesting case is $[[{omega.(Q=>C)}]]$:
to prove $[[{omega.(Q=>C)}]]$, you need to prove $[[{C}]]$ under the
\emph{linear} assumption $[[{Q}]]$, but without using any other linear
assumptions.

These implications arise when we unpack an existential
package that contains a linear constraint and also when checking a |let|-binding.
We can define scaling over wanted constraints by recursion as follows, where we
use scaling over simple constraints in the simple-constraint case:
$$
\left\{
  \begin{array}{lcl}
    [[{pi.(C1 * C2)}]] & = & [[{pi.C1 * pi.C2}]] \\
    [[{1.(C1 & C2)}]] & = & [[{C1 & C2}]] \\
    [[{omega.(C1 & C2)}]] & = & [[{omega.C1 * omega.C2}]] \\
    [[{pi.(rho.(Q => C))}]] & = & [[{(pi.rho).(Q => C)}]]
  \end{array}
\right.
$$
For the most part, scaling of wanted constraints is straightforward. The only
peculiar case is when we scale the additive conjunction $[[{C1&C2}]]$ by
$[[{omega}]]$, the result is a multiplicative conjunction. The intuition here is
that when if we have both $[[{omega.C1}]]$ and $[[{omega.C2}]]$, then
a choice between $[[{C1}]]$ and $[[{C2}]]$ can be made $[[{omega}]]$ times.

We define an entailment relation over wanteds in \Cref{fig:wanted:entailment}.
Note that this relation uses only simple constraints $[[{Q}]]$ as assumptions, as
there is no way to assume the more elaborate $[[{C}]]$\footnote{Allowing the full wanted-constraint syntax
in assumptions is the subject of work by \citet{quantified-constraints}.}.
\begin{figure}
  \maybesmall
  \centering
  \drules[C]{$[[Q |- C]]$} {Wanted-constraint entailment}
  {Dom,Id,Tensor,With,Impl}
  \caption{Wanted-constraint entailment}
  \label{fig:wanted:entailment}
\end{figure}

Before we move on to constraint generation proper, let us highlight a few
technical, yet essential, lemmas about the wanted-constraint
entailment relation.

\begin{lemma}[Inversion]
  \label{lem:inversion}
  The inference rules of $[[Q |- C]]$ can be read bottom-up (up to the
  set $[[{Dup}]]$) as well
  as top-down, as is required of $[[Q1 ||- Q2]]$ in
  \Cref{fig:entailment-relation}. That is:
  \begin{itemize}
  \item If $[[Q |- C1*C2]]$, then there exists $[[{Q1}]]$, $[[{Qdup}]]$ and $[[{Q2}]]$
    such that $[[Qdup \in Dup]]$, $[[Q1 * Qdup |- C1]]$, $[[Qdup * Q2 |- C2]]$, and
    $[[{Q}]] = [[{Q1 * Qdup * Q2}]]$.
  \item If $[[Q |- C1 & C2]]$, then $[[Q |- C1]]$ and $[[Q |- C2]]$.
  \item If $[[Q |- pi.(Q2 => C)]]$, then there exists $[[{Q1}]]$ such
    that $[[Q1 * Q2 |- C]]$ and  $[[{Q}]] = [[{pi.Q1}]]$
  \end{itemize}
\end{lemma}

\begin{lemma}[Scaling]
  \label{lem:wanted:promote}
  If $[[Q |- C]]$, then $[[pi.Q |- pi.C]]$.
\end{lemma}

\begin{lemma}[Inversion of scaling]
  \label{lem:wanted:demote}
  If $[[Q |- pi.C]]$ then $[[Q' |- C]]$ and $[[{Q}]] = [[{pi.Q'}]]$ for some $[[{Q'}]]$.
\end{lemma}

\subsection{Constraint Generation}
\label{sec:constraint-generation}
\label{sec:constraint-generation-soundness}

The process of inferring constraints is split into two parts: generating
constraints, which we do in this section, then solving them in
\cref{sec:constraint-solver}. Constraint generation is described by
the judgement $[[G |-> e : t ~> C]]$ (defined in
\Cref{fig:constraint-generation}) which outputs a constraint $[[{C}]]$
required to make $[[e]]$ typecheck.
The definition
$[[G |-> e : t ~> C]]$ is syntax directed, so it can directly be read as an
algorithm, taking as input a \emph{typing derivation} for $[[G |- e : t]]$
(produced by an external type inference oracle as discussed above). Notably, the
algorithm has access to the context splitting from the (previously computed)
typing derivation, and is
thus indeed syntax directed.
\info{See Fig.13, p39 of OutsideIn~\cite{OutsideIn}}

\info{Not caring about inferences simplifies $\packbox$ quite a bit, we
  are using the pseudo-inferred type to generate constraint. In a real
  system, we would need $\packbox$ to know its type (\emph{e.g.} using
  bidirectional type checking).}
\begin{figure}
  \maybesmall
  \centering
  \drules[G]{$[[G |-> e : t ~> C]]$}{Constraint generation}{Var, Abs,
    App, Pack, Unpack, Case, Let, LetSig}

  \caption{Constraint generation}
  \label{fig:constraint-generation}
\end{figure}

The rules of \Cref{fig:constraint-generation} constitute a mostly
unsurprising translation of the rules of \Cref{fig:typing-rules},
except for the following points of interest:

\emph{Case expressions.}
Note the use of $[[&]]$ in the conclusion of \rref{G-Case}.
We require that each branch of a $\kcase$ expression use the exact
same (linear) assumptions; this is enforced by combining the
emitted constraints with $[[&]]$, not $[[*]]$.
%
  This can also be understood in terms of the array example of
  \cref{sec:introduction}:
  if an array is freed in one branch of a $\kcase$, we require it to be freed (or frozen) in
the other branches too.
  Otherwise, the array's state will be unknown to the type system
  after the $\kcase$.
%

\emph{Implications.} The introduction of constraints local to a
  definition (\rref{G-LetSig}) corresponds to
  emitting an implication constraint.

\emph{Unannotated |let|.}
 However, the~\rref*{G-Let} rule does not produce an implication
  constraint, as we do not model |let|-generalisation~\cite{let-should-not-be-generalised}.
  % \cref{sec:let-generalisation} discusses this design
  % choice further.


\vspace{1ex}
The key property of the constraint-generation algorithm is that,
if the generated constraint is solvable, then we can indeed type the
term in the qualified type system of
\cref{sec:qualified-type-system}. That is,
these rules are simply an implementation of our declarative qualified
type system.

\begin{lemma}[Soundness of constraint generation]\label{lem:generation-soundness}
  For all $[[{Q_g}]]$, if $[[G |-> e : t ~> C]]$ and $[[Q_g |- C]]$ then
  $[[Q_g; G |- e : t]]$.
\end{lemma}

\subsection{Constraint Solving}
\label{sec:constraint-solver}

In this section,
we build a \emph{constraint solver} that proves
that $[[Q_g |- C]]$ holds, as required by \cref{lem:generation-soundness}.
The constraint solver is represented by the following judgement:
%
$$
[[ |-s C ~> Q]]
$$
%
The judgement doesn't take any context as an input\unsure{Is this
  over-simplifying. In real life we do need a context in order to dereference
  names and all that.}. Instead the judgement outputs a simple constraint
$[[{Q}]]$, which we want to read as a context which entails $[[{C}]]$ (see
\cref{lem:solver-soundness}).

Returning a context rather than taking it as an argument lets us effectively
count the occurrence of atomic constraint in the solution, which we can then
reject if it is not compatible with the multiplicity of the given constraint.
This is essentially the same technique that \textsc{ghc} uses to implement
linearity of regular terms in its typechecker. Note that we return the whole
context here, whereas \textsc{ghc}'s typechecker only returns multiplicity,
which is more suited for a concrete implementation.

Returning whole contexts is unusual but not unheard of, see for instance
\cite{algebraic-subtyping}, which returns whole contexts in order to implement
subtyping. This particular presentation is, however, very unusual when it comes
to proof search in linear logic. Most typically, linear-logic proof search is
presented in state-passing style (\emph{e.g.}
\cite{resource-management-for-ll-proof-search}): rules take an input context,
and return a “leftover” context which contains all the remaining, unused
hypotheses.

The reasons to choose this presentation, which, for the Haskell practioner, we
could describe as writer-style rather than state-style, are\unsure{Is the item list below readable without giving
  an example of a state-passing rule? In fact, I haven't explained the rules at
  all yet. Maybe I should move this paragraph below}
\begin{itemize}
  \item When solving $[[{C1 * C2}]]$, $[[{C1}]]$ and $[[{C2}]]$ are perfectly
        symmetric, making typechecking robust to reordering the source program.
        This isn't the case in state-passing style where $[[{C1}]]$ and
        $[[{C2}]]$ are checked in different contexts.
  \item Solving $[[{C1 * C2}]]$ involves solving $[[{C1}]]$ and $[[{C2}]]$ in
        parallel, whereas the state-passing style sequentialise $[[{C1}]]$ and
        $[[{C2}]]$. This is important to integrate in \textsc{ghc}'s constraint
        solver, which likes to suspend constraints it doesn't know how to solve
        yet. Suspension isn't compatible with sequentialised state-passing
        style: it isn't possible to wait until $[[{C2}]]$ is solved to solve
        $[[{C1}]]$ if solving $[[{C2}]]$ requires the output of $[[{C1}]]$.
  \item Incidentally, counting down from a context like the state-passing style
        does doesn't generalise to arbitrary semiring. There is no current plan
        to extend \text{ghc} with a richer semiring than multiplicities, but the
        writer-style is more future proof.
\end{itemize}
However, a writer-style solver will explore fewer potential proofs than a
state-style solver. Therefore this writer style is more suitable to produce an
incomplete, guess-free solver; to write a complete solver, one should prefer the
state style.\footnote{If you have
  read the conference version of this article, you may remember that in that
  version, we presented a state-passing constraint solver. We didn't understand
  this trade-off at the time.}

If the constraint solver finds a solution then $[[|-s C ~> Q]]$ then
$[[{Q}]]$ entails $[[{C}]]$. In order to check that $[[Q_g |- C]]$, it therefore suffices to
check that $[[|-s 1.(Q_g => C) ~> Empty]]$.

\begin{lemma}[Constraint solver soundness]
  \label{lem:solver-soundness}
  If $[[|-s C ~> Q]]$, then $[[Q |- C]]$
\end{lemma}

To handle simple wanted constraints, we will need  a domain-specific
\emph{atomic-constraint solver} to be the algorithmic counterpart of the
abstract entailment relation of \cref{sec:constraint-domain}. The
main solver will appeal to this atomic-constraint solver when solving atomic
constraints.  The atomic-constraint solver is represented by the following
judgement:
%
$$
[[ |-simp pi.q ~> Q ]]
$$

It has a similar structure to the main solver, but only deals with atomic
constraints. Even though the main solver is parameterised by this
atomic-constraint solver, we will give an instantiation in
\cref{sec:simple-constr-solv}.
%
We require the following property of the atomic-constraint solver:

\begin{property}[Atomic-constraint solver soundness]
\label{prop:atomic-solver-soundness} If $[[ |-simp pi.q ~> Q ]]$, then $[[Q ||- pi.q]]$.
\end{property}

\subsubsection{Constraint Solver Algorithm}

Building on this atomic-constraint solver, we use a linear proof
search algorithm based on the recipe given
by~\citet{resource-management-for-ll-proof-search}, though adapted to our writer
style. \Cref{fig:constraint-solver}
presents the rules of the constraint solver.

\begin{figure}
  \maybesmall
  \centering
  \drules[S]{$[[|-s C_w ~> Q ]]$}{Constraint solving}{Atom, Mult, Impl, Add}
  \drules[D]{$[[|-d Q_i \d Q_b ~> Q_o ]]$}{Check bounds}{Linear, Dup, Ur}
  \caption{Constraint solver}
  \label{fig:constraint-solver}
\end{figure}
\critical{Define the sup}

\begin{itemize}
  \item The~\rref*{S-Mult} rule proceeds by solving both sides then combining
  the output context with a linear product.
  \item The~\rref*{S-Add} rule handles additive conjunction. Additive
        conjunction is generated from $\kcase$ expressions, only one of them is
        actually going to be executed, therefore both branches must consume
        exactly the same resources. This is handled by the \emph{join}
        $[[{Q1 \/ Q2}]]$, which computes a context which is compatible with
        $[[{Q1}]]$ and $[[{Q2}]]$. That is $[[Q1 \/ Q2 ||- Q1]]$ and
        $[[Q1 \/ Q2 ||- Q2]]$.
  \item The~\rref*{S-Impl} rule handles implications. What implications
        $[[{pi . ( Q_b => C )}]]$ do is limit the scope of the constraints in
        $[[{Q_b}]]$. This is achieved via the judgement
        $[[|-d Q_i \d Q_b ~> Q_o]]$, the rules for which are quite formalistic,
        but are easily expressed in English: for each atomic constraint
        $[[{q}]]$ in $[[{Q_b}]]$, there must be a single occurrence of $[[{q}]]$
        in $[[{Q_b}]]$, and all occurrences of $[[{q}]]$ must then removed from
        $[[{Q_i}]]$ to yield $[[{Q_o}]]$. Then a linear atomic constraint
        $[[1.q \notin Dup]]$ removes a single linear constraint from
        $[[{Q_i}]]$, a linear atomic constraint $[[1.q \in Dup]]$ removes any
        number of linear constraints (but no unrestricted constraints), and an
        unrestricted constraint $[[{omega . q}]]$ removes any number of
        constraints with arbitrary multiplicity. If this fails to remove all
        occurrences of $[[{q}]]$, then the solver fails.

\end{itemize}

The solving strategy is mainly embodied by the~\rref*{S-Impl} rule. It makes
strong assumptions in order to avoid guesses. Avoiding guesses is a key property
of \textsc{ghc}'s solver~\cite[Section~6.4]{OutsideIn}, one we must maintain if
we are to be compatible with \textsc{ghc}.\unsure{We probably want a forward
  reference to the discussion on implementation; should that discussion happen
  in the related work section, like it currently sort of does, or in a separate
  subsection of the new Design consideration section?}

One consequence of our strategy is that the solver can only ever use
the occurrence of $[[{1.q}]]$ introduced by the innermost implication.
Even though there could be valid solutions using more outer
implications. In particular the solver will fail on constraints of the form
$[[{1.(1.q => 1.(1.q => 1.q * 1.q))}]]$ even though it has a valid
solution. For instance, the following would fail to typecheck with our solver.

\begin{code}
class constraint (C)
giveC :: (constraint(C) =>. Int) -> Int

counting :: (constraint((C, C)) =>. Int) -> Int
counting take_two =
  giveC $
  giveC $ -- Multiplicity error: this linear |constraint(C)| is used several times.
  take_two
\end{code}

Likewise, if there are several occurrences of the same $[[{1.q}]]$ in
$[[{Q_b}]]$, then the solver considers this an ambiguity and fails. For instance

\begin{code}
class constraint (C)
giveTwoC :: (constraint((C, C)) =>. Int) -> Int

repeating :: (constraint(C) =>. Int) -> Int
repeating take_one =
  giveTwoC $
    take_one + take_one -- Ambiguity error: there are two different |constraint(C)| to choose from
\end{code}

In both of these are examples of incompleteness of the solver, as both of these
example can be ascribed a type in the declarative type system of
\cref{sec:typing-rules}. Although we can imagine applications where solving
similar constraints would be helpful, we consider it to be a reasonable
restrictions as it's compatible with all our motivating examples
(\cref{sec:memory-ownership}), and in exchange we get a solver which is only
marginally more complex than, say, \textsc{ghc}'s solver, solves $[[{Q1 *
  Q2}]]$ in parallel, and is guess free.

We also believe that our strategy tends to match expectations in many cases.
Consider the following example:
\begin{code}
f =   unique $ Linearly.do
        Ur arr <- new 10
        fr   ::  constraint (RW n) =>. () -- fails here with |constraint(RW n)| used more than once
        fr   =   Linearly.do
          free arr
          free arr
        ()   =   fr -- A cleverer solver may fail here saying that there is no |constraint(RW n)| left to use
        Linearly.return $ Ur ()
\end{code}
In this example, it is possible to type |fr| in the declarative type system.
However, |fr| is incorrect as it frees the array several time, which isn't
permitted. It would only succeed because it can make use of the |constraint(RW
n)| constraint which is meant to be used to call |fr| itself. Doing so would
point at the wrong location for a mistake. Whereas our strategy points at the
actual mistake. The fixed code, on the other hand, does typecheck
\begin{code}
f =   unique $ Linearly.do
        Ur arr <- new 10
        fr   ::  constraint (RW n) =>. ()
        fr   =   free arr
        ()   =   fr
        Linearly.return $ Ur ()
\end{code}
As their is a strict nesting between the two occurrences of |constraint(RW n)|
to choose from when calling |free|, so the solver chooses the innermost.

\subsubsection{An Atomic-Constraint Solver}
\label{sec:simple-constr-solv}

So far, the atomic-constraint domain has been
an abstract parameter. In this section, though, we offer a concrete
domain which supports our examples.

For the sake of our examples, we need very little: is suffices that linear
constraints be atoms, whose only meaningful operation is to compare them for
equality.
It is thus sufficient for the entailment relation
(\Cref{fig:simpl-entailment}) to prove $[[{q}]]$ if and only if it
is already assumed---while respecting linearity. That is, with the
exception of a distinguished constraint $[[{Linearly}]]$, which can be
duplicated and discarded, and we use to model the |Unique|
constraint from~\ref{sec:Unique-constraint}. That is, the set $[[{Dup}]]$ is
defined to only contain $[[{Linearly}]]$.

\begin{figure}
  \maybesmall
  \centering
  \begin{subfigure}{\linewidth}
    \drules[Q]{$[[Q1 ||- Q2]]$}{Entailment relation}{Hyp,Prod,Empty,
      DiscardD, DupD}
    \caption{Entailment relation}
    \label{fig:simpl-entailment}
  \end{subfigure}
  \begin{subfigure}{\linewidth}
    \drules[Atom]{$[[|-simp pi.q ~> Q]]$}{Atomic-constraint solver}{Use}
    \caption{Atomic-constraint solver}
    \label{fig:simpl-solver}
  \end{subfigure}
  \caption{A stripped-down constraint domain}
  \label{fig:predicate-domain}
\end{figure}

The corresponding atomic-constraint solver (\Cref{fig:simpl-solver}) is as
simple as it gets. It consists in a single rule saying that the only way to
prove a constraint $[[{q}]]$ is to use an hypothesis of type $[[{q}]]$. This
solver never guesses since it only every apply this one rule.

\critical{TODO: below}

\Cref{fig:simpl-solver} is also where the fact that the
$[[{LCtx}]]$ are lists comes into play. Indeed, \rref{Atom-OneL}
takes care to use the most recent occurrence of $[[{q}]]$
(remember that \rref{S-ImplOne} adds the new hypotheses on the front of
the list). To understand why, consider the following example:
|free| to use the |constraint(RW n)| constraint introduced locally in the type
of |fr|. Yet
there are actually two linear |constraint(RW n)| constraints: this local one and the
one assumed when unpacking |arr|. The wrong
choice among the constraints will lead the algorithm to fail.
Choosing the first $[[{q}]]$ linear assumption guarantees we get the
most local one.\jp{In the above paragraph, it says "most recent" I suggest sticking to this terminology here too.}

Another interesting feature of the solver (\Cref{fig:simpl-solver}) is that
no rule solves a linear constraint if it appears both in the
unrestricted and a linear context.
Consider the following (contrived) \textsc{api}:
\begin{code}
class constraint (C)
\end{code}

\vspace{-2ex}\noindent
\begin{minipage}{0.5\linewidth}
> giveC :: (constraint (C) => Int) -> Int
\end{minipage}
\begin{minipage}{0.5\linewidth}
> useC :: constraint (C) =>. Int
\end{minipage}
|giveC| gives an unrestricted copy of |constraint (C)| to some continuation, while |useC|
uses |constraint (C)| linearly. Now consider two potential consumers of this \textsc{api}:

\noindent
\begin{minipage}{0.5\linewidth}
> ambiguous1 :: constraint (C) =>. Int
> ambiguous1 = giveC useC
\end{minipage}
\begin{minipage}{0.5\linewidth}
> ambiguous2 :: constraint (C) =>. (Int, Int)
> ambiguous2 = (giveC useC, useC)
\end{minipage}
Looking at |ambiguous1|, the invocation of |useC| has both a linear |constraint (C)| in scope, and
a more local unrestricted |constraint (C)|. The strategy to pick the more local constraint
fails here, because it would leave the linear |constraint (C)| unconsumed. A
tempting refinement might be to always consume the most local \emph{linear}
constraint. That would handle |ambiguous1| correctly, but fail on |ambiguous2|. In
the case of the latter, if the invocation of |giveC useC| consumes the linear
|constraint (C)|, then the second |useC| invocation will fail. It is possible to
give a type derivation to |ambiguous2| in the qualified type system
of \cref{sec:qualified-type-system} by making the first |useC| consume the
unrestricted |constraint (C)| and the second |useC| consume the linear
|constraint (C)|.
This assignment, however, would require
the constraint solver to guess when solving the constraint from the first |useC|.
Accordingly, in order to both avoid backtracking and to keep type inference
independent of the order terms appear in the program text, |bad| is
rejected.
This introduces incompleteness with respect the entailment
relation. We conjecture that this is the only source of
incompleteness that we introduce beyond what is already in
\textsc{ghc}~\cite[Section~6]{OutsideIn}.

\section{Desugaring}
\label{sec:desugaring}

The semantics of our language is given by desugaring it into
a simpler core language: a variant of the $λ^q$
calculus~\cite{LinearHaskell}. We
define the core language's type system here; its operational semantics
is the same, \emph{mutatis mutandis}, as that of Linear Haskell.

\subsection{The Core Calculus}
\label{sec:core-calculus}
\label{sec:ds:inferred-constraints}

\begin{figure}
  \maybesmall
  \centering
  $$
  \begin{array}{lcll}
    [[{s}]] & \bnfeq & [[{forall as. t}]] & \text{Type schemes} \\
    [[{t}]], [[{u}]] & \bnfeq & ... \bnfor [[{exists as. t o- u}]] & \text{Types} \\
    [[{e}]] & \bnfeq & ... \bnfor [[{pack (e1, e2)}]] \bnfor [[{unpack (x,y)=e1 in e2}]] & \text{Expressions}
  \end{array}
  $$

  \drules[L]{$[[G |- e : t]]$}{Core language
    typing}{Pack,Unpack}
  \caption{Core calculus (subset)}
  \label{fig:core-typing-rules}\label{fig:core-grammar}
\end{figure}

The core calculus is a variant of the type system defined in
\cref{sec:qualified-type-system}, but without constraints. That is, the evidence for constraints is passed explicitly in this core calculus.
%
Following $λ^q$, we assume the existence of the following data types:
\begin{itemize}
\item $[[{t1 ** t2}]]$ with sole constructor
  $[[ (,) : forall a b. a ->_1 b ->_1 a ** b ]]$. We will write $[[(e1,
  e2)]]$ for $[[{(,) e1 e2}]]$.
\item $[[{unit}]]$ with sole constructor $[[() : unit]]$.
\item $[[{Ur t}]]$ with sole constructor $[[ Ur : forall a. a ->_omega
  Ur a]]$
\end{itemize}
%
\Cref{fig:core-typing-rules}
highlights the differences from the qualified system:
\begin{itemize}
  \item Type schemes $[[{s}]]$ do not support qualified types.
  \item Existentially quantified types ($[[{exists as. t o= Q}]]$) are now represented as an (existentially quantified, linear) pair of values ($[[{exists as. t2 o- t1}]]$).
Accordingly, $\packbox$ operates on pairs.
\end{itemize}
%
The differences between our core calculus and $λ^q$ are as follows:
\begin{itemize}
\item We do not support multiplicity polymorphism.
\item On the other hand, we do include type polymorphism.
\item Polymorphism is implicit rather than explicit. This is not an
  essential difference, but it simplifies the presentation. We could,
for example, include more details in the terms in order to make type-checking
more obvious; this amounts essentially to an encoding of typing derivations
in the terms\footnote{See, for example, \citet{weirich-icfp17} and their
comparison between an implicit core language D and an explicit one DC.}.
\item We have existential types. These can be realised in regular Haskell as a
  family of datatypes.
\end{itemize}

Using \cref{lem:generation-soundness} together with
\cref{lem:solver-soundness} we know that if
$[[G |-> e : t ~> C]]$ and $[[UCtx ; DCtx ; LCtx |-s C ~> emptyset ]]$, then
$[[(UCtx, DCtx \u LCtx) ; G |- e : t]]$.
%
It only remains to desugar derivations of $[[Q;G|-e : t]]$ into the
core calculus.

\subsection{From Qualified to Core}
\label{sec:ds:from-qualified-core}

\subsubsection{Evidence}
In order to desugar derivations of the qualified system to the core calculus,
we pass evidence explicitly\footnote{This technique is also often called
  dictionary-passing style \cite{type-classes-impl} because, in the case of type classes, evidences are
  dictionaries, and because type classes were the original form of constraints
  in Haskell.}.
%
To do so, we require some more material from
constraints. Namely, we assume a type $[[{Ev(q)}]]$ for each atomic
constraint $[[{q}]]$,
defined in \Cref{fig:evidence}.  The $[[Ev(Hole)]]$ operation
extends to simple constraints as
$[[{Ev(Q)}]]$.
Furthermore, we require that for every $[[{Q1}]]$ and $[[{Q2}]]$
such that $[[Q1 ||- Q2]]$, there is a (linear) function
$[[Ev(Q1 ||- Q2) : Ev(Q1) ->_1 Ev(Q2)]]$.

Let us now define a family of functions $[[{Ds(Hole)}]]$ to translate
the type schemes, types, contexts, and typing derivations of the qualified system into the
types, type schemes, contexts, and terms of the core calculus.

\subsubsection{Translating Types}
Type schemes $[[{s}]]$ are translated by turning the implicit argument $[[{Q}]]$
into an explicit one of type $[[{Ev(Q)}]]$. Translating types $[[{t}]]$
and contexts $[[{G}]]$ proceeds as
expected.

\begin{minipage}{0.5\linewidth}
%
$$
\left\{
  \begin{array}{lcl}
    [[{Ds(forall as. Q =o t)}]] & = & [[{forall as. Ev(Q) ->_1 Ds(t)}]] \\
  \end{array}
\right.
$$
$$
\left\{
  \begin{array}{lcl}
    [[{Ds(t1 ->_pi t2)}]] & = & [[{Ds(t1) ->_pi Ds(t2)}]] \\
    [[{Ds(exists as. t o= Q)}]] & = & [[{exists as. Ds(t) o- Ev(Q)}]]
  \end{array}
\right.
$$
%
\end{minipage}%
\begin{minipage}{0.5\linewidth}
$$
\left\{
  \begin{array}{lcl}
    [[{Ds(empty)}]] &=& [[{empty}]] \\
    [[{Ds(G, x :_pi t)}]] &=& [[{Ds(G), x :_pi Ds(t)}]]
  \end{array}
\right.
$$
\end{minipage}

\subsubsection{Translating Terms}
Given a derivation $[[Q;G |- e : t]]$, we can build an expression
$[[Ds(z;Q;G |- e : t)]]$, such that
$[[Ds(G), z:_1 Ev(Q) |- Ds(z;Q;G |- e : t) : Ds(t)]]$ (for some fresh variable
$[[{z}]]$). Even though we abbreviate the derivation as only its
concluding judgement, the translation is defined recursively on the
whole typing derivation: in particular, we have access to typing rule
premises in the body of the definition.
%
We present some of the interesting cases in \Cref{fig:desugaring}.
\begin{figure}
    \maybesmall
\centering
  \begin{subfigure}{0.3\linewidth}%
$$
\left\{
  \begin{array}{lcl}
    [[{Ev(1.q)}]] & = & [[{Ev(q)}]] \\
    [[{Ev(omega.q)}]] & = & [[{Ur (Ev(q))}]] \\
    [[{Ev(Empty)}]] & = & [[{unit}]] \\
    [[{Ev(Q1 * Q2)}]] & = & [[{Ev(Q1) ** Ev(Q2)}]]
  \end{array}
\right.
$$
  \caption{Evidence passing}
  \label{fig:evidence}
  \end{subfigure}\hfill
  \begin{subfigure}{0.7\linewidth}%
%{
%format |- = "[[|-]]"
%format ||- = "[[||-]]"
%format G = "[[{G}]]"
%format G1 = "[[{G1}]]"
%format G2 = "[[{G2}]]"
%format Q = "[[{Q}]]"
%format Q1 = "[[{Q1}]]"
%format Q2 = "[[{Q2}]]"
%format * = "[[*]]"
%format Ds(z)(j) = "\dsterm{\ottmv{" z "}}{" j "}"
%format Ev(x) = "\dsevidence{" x "}"
%format unpack(x) = "\klet\ \packbox " x
%format u = "[[{u}]]"
%format OneOf (a) (b) = a"\mathop{:_{1}}"b
%format Sub t as bs = t "[" as "/" bs "]"
%format case_1 = "[[case_1]]"
%format e1 = "[[{e1}]]"
%format e2 = "[[{e2}]]"
%format t1 = "[[{t1}]]"
%format as = "[[{as}]]"
%format ts = "[[{ts}]]"
%format us = "[[{us}]]"
%format let_1 = "[[let_1]]"
%format z1 = "[[{z1}]]"
%format z2 = "[[{z2}]]"
%format z2' = "[[{z2}]]''"
%format + = "\ottsym{+}"
%format t = "\tau"
$$
\left\{
  \;
  \begin{minipage}{0.5\linewidth}
\begin{code}
Ds(z)(Q;G |- x : Sub u ts as) = x z
Ds(z)(Q * Sub Q1 us as;G |- pack e : exists as. t .<= Q1) =
  case_1 z of { (z', z'') ->
    pack (z'', Ds(z')( Q ; G |- e : Sub t us as))}
Ds(z)(Q1 * Q2;G1 + G2 |- unpack x = e1 in e2 : t)  =
  case_1 z of { (z1, z2) ->
    unpack (z',x) = Ds(z1)(Q1;G1 |- e1 : exists as. t1 .<= Q) in
    let_1 z2' = (z2,z') in
    Ds(z2')(Q2 * Q;G2, OneOf x t1 |- e2 : t) }
Ds(z)(Q;G |- e : t)  =  -- \rref{E-Sub}
  let_1 z' = Ev(Q ||- Q1) z in Ds(z')(Q1;G |- e : t)
...
\end{code}
  \end{minipage}
\right.
$$
%}
  \caption{Desugaring (subset)}
  \label{fig:desugaring}
  \end{subfigure}
  \caption{Evidence passing and desugaring}
\end{figure}

The cases correspond to the~\rref*{E-Var},~\rref*{E-Unpack}\footnote{The attentive
reader may note that the case for $\kunpack$ extracts out $[[{Q1}]]$ and $[[{Q2}]]$
from the provided simple constraint. Given that simple constraints $[[{Q}]]$ have no
internal ordering and allow duplicates (in the non-linear component), this splitting
is not well defined. To fix this, an implementation would have to \emph{name} individual
components of $[[{Q}]]$, and then the typing derivation can indicate which constraints
go with which sub-expression. Happily, \textsc{ghc} \emph{already} names its constraints,
and so this approach fits easily in the implementation. We could also augment our formalism
here with these details, but they add clutter with little insight.}, and~\rref*{E-Sub} rules, respectively.
Variables are stored with qualified types in the environment, so they get
translated to functions that take the evidence as argument. Accordingly, the evidence
is inserted by passing $[[{z}]]$ as an argument.
Handling \rref*{E-Unpack} requires splitting the context into two: $[[{e1}]]$ is desugared as a pair, and the evidence
it contains is passed to $[[{e2}]]$. Finally, subsumption summons the function corresponding to the entailment relation $[[Q ||- Q1]]$
and applies it to $[[{z}]]$ : $[[{Ev(Q)}]]$ then proceeds to desugar $[[{e}]]$ with the resulting evidence for $[[{Q1}]]$.
Crucially, since $[[{Ds(z;Hole)}]]$ is defined on \emph{derivations}, we can access the premises used in the rule.
Namely, $[[{Q1}]]$ is available in this last case from the~\rref*{E-Sub} rule's premise.

It is straightforward by induction, to verify that desugaring is correct:
%
\begin{theorem}[Desugaring]
If $[[Q;G |- e : t]]$, then
$[[Ds(G), z:_1 Ev(Q) |- Ds(z;Q;G |- e : t) : Ds(t)]]$, for any fresh
variable $[[{z}]]$.
\end{theorem}

Thanks to the desugaring machinery, the semantics of a language with linear
constraints can be understood in terms of a simple core language with linear
types, such as $λ^q$, or indeed, \textsc{ghc} Core.

\section{Integrating into \textsc{ghc}}

One of the guiding principles behind our design was ease of integration with
modern Haskell. In this section we describe some of the particulars of adding
linear constraints to \textsc{ghc}.

\subsection{Implementation}
\label{sec:implementation}

We have written a prototype implementation~\cite{prototype} of linear constraints on top of \textsc{ghc} 9.1, a version that already
ships with the @LinearTypes@ extension. Function arrows (|->|) and context arrows
(|=>|) share the same internal representation in the typechecker, differentiated
only by a boolean flag. Thus, the @LinearTypes@ implementation effort has already
laid down the bureaucratic ground work of annotating these arrows with
multiplicity information.

The key changes affect constraint generation and constraint solving. Constraints
are now annotated with a multiplicity, according to the context from
which they arise. With @LinearTypes@, \textsc{ghc} already scales the usage
of term variables. We simply modified the scaling function to capture all the
generated constraints and re-emit a scaled version of them, which is a fairly local
change.

The constraint solver maintains a set of given constraints (the \emph{inert set}
in \textsc{ghc} jargon), which corresponds to the $[[{UCtx}]]$, $[[{DCtx}]]$, and $[[{LCtx}]]$
contexts in our solver judgements in \cref{sec:constraint-solver}. When
the solver goes under an implication, the assumptions of the implication are
added to set of givens. When a new given is added, we record the \emph{level} of
the implication (how many implications deep the constraint arises from) along
with the constraint. So that in case there are multiple matching
givens, the constraint solver selects the innermost one
(in \cref{sec:constraint-solver} we use an ordered list
for this purpose).

As constraint solving proceeds, the compiler pipeline constructs a
term in a typed language known as \textsc{ghc} Core~\cite{system-fc}.
In Core, type class constraints are turned into explicit evidence (see
\cref{sec:desugaring}). Thanks to being fully annotated, Core has
decidable typechecking, which is used to find and fix bugs in
the compiler (the Haskell type checker finds mistakes in user
programs). Thus, the Core typechecker verifies that the desugaring
procedure produced a linearity-respecting program before code
generation occurs.

\subsection{Interaction with Other Features}

Since constraints play an important role in \textsc{ghc}'s type system, we must
pay close attention to the interaction of linearity with other language features
related to constraints. Of these, we point out two that require some extra care.
\info{There isn't room to properly explain how we can implement
|Unique| constraints. We don't already speak of
desugaring in the implementation section, so I'd need to give a bit of
context about wrappers or something.

The right approach is to count the number of `Linearly` used. We need
wrappers at the toplevel of definitions, and at each branch of a match
(even if it doesn't introduce an implication, as we may need to adjust
the number of `Linearly` in some branches (presumably by
weakening)). And we do the appropriate amount of
duplications/discards in these wrappers.}

\subsubsection{Superclasses}

Haskell's type classes can have \emph{superclasses}, which place constraints on
all of the instances of that class. For example, the |Ord| class is defined as
\begin{code}
class constraint(Eq a) => constraint(Ord a) where ...
\end{code}
which means that every ordered type must also support equality. Such
superclass declarations extend the entailment relation: if we know that a type
is ordered, we also know that it supports equality. This is troublesome if we
have a linear occurrence of |constraint(Ord a)|, because then using this entailment, we could
conclude that a linear constraint (|constraint(Ord a)|) implies an unrestricted constraint
(|constraint(Eq a)|), which violates \cref{lem:q:scaling-inversion}.

But even linear superclass constraints cause trouble. Consider a version of |constraint(Ord a)|
that has |constraint(Eq a)| as a linear superclass.
\begin{code}
class constraint(Eq a) =>. constraint(Ord a) where ...
\end{code}
When given a linear |constraint(Ord a)|, should we keep it as |constraint(Ord a)|, or rewrite to
|constraint(Eq a)| using the entailment? Short of backtracking, the constraint solver
needs to make a guess, which \textsc{ghc} never does.

To address both of these issues at once, we make the following rule: the
superclasses of a linear constraint are ignored.

\subsubsection{Equality Constraints}
\label{sec:equality-constraints}

In \cref{sec:type-inference} we argued that \emph{type} inference and
\emph{constraint} inference can be performed independently. However, this is not
the case for \textsc{ghc}'s constraint domain, because it supports equality
constraints, which allows unification problems to be deferred, and potentially
be solvable only after solving other constraints first.

To reconcile this with our presentation, we need to ensure that
\emph{unrestricted constraint} inference and \emph{linear constraint} inference
can be performed independently. That is, solving a linear constraint should
never be required for solving an unrestricted constraint. This is ensured by
\cref{lem:q:scaling-inversion}.

They key is to represent unification problems as \emph{unrestricted} equality
constraints, so a given linear equality constraint cannot be used during type
inference.  This way, linear equalities require no
special treatment, and are harmless.

% \section{Extensions}
% \label{sec:design-decisions}

% The system presented in \cref{sec:qualified-type-system,sec:type-inference} is already capable of supporting the examples
% in \cref{sec:what-it-looks-like,sec:memory-ownership}. In this
% section, we consider some potential avenues for extensions.

% \subsection{let generalisation}
% \label{sec:let-generalisation}

% As discussed in \cref{sec:constraint-generation}, the~\rref*{G-Let} rule of our
% constraint generator does not generalise the type of |let|-bindings, which is in
% line with \textsc{ghc}'s existing behaviour~\cite[Section 4.2]{OutsideIn}.
% There, this behaviour was guided by concerns around inferring type variables,
% which is harder in the presence of local equality assumptions (\emph{i.e.}
% \textsc{gadt} pattern matching).

% In this section, however, we argue that generalising over linear constraints
% may, in fact, improve user experience.
% Let us revisit the |firstLine| example from \cref{sec:introduction}, but
% this time, instead of executing |closeFile| directly, we assign it to a variable
% in a |let|-binding:
% \begin{code}
% firstLine :: FilePath -> IOL String
% firstLine fp =   do  {  pack (Ur h) <- openFile fp
%                      ;  let closeOp = closeFile h
%                      ;  pack (Ur xs) <- readLine h
%                      ;  closeOp
%                      ;  return xs }
% \end{code}
% This program looks reasonable; however, it is rejected. The type of
% |closeOp| is |IOL ()|, which means that the definition of |closeOp|
% consumes the linear constraint |Open h|. So, by the time we attempt
% |readLine h|, the constraint is no longer available.

% What the programmer really meant, here, was for |closeOp| to have type
% |constraint (Open h) =>. IOL ()|. After all, a |let| definition is not part of the
% sequence of instructions: it is just a definition for later, not
% intended to consume the current state of the file. With no |let|-generalisation,
% the only way to give |closeOp| the type |constraint (Open h) =>. IOL
% ()| is to give |closeOp| a type signature. In current \textsc{ghc}, we
% can't write that signature down, since there is no syntax to bind
% the type variable |h| in the program text\footnote{\citet{variables-in-patterns} describe a way to fix this shortcoming.}. But
% even ignoring this, it would be rather unfortunate if the default
% behaviour of |let|, in the presence of linear constraints, almost never was
% what the programmer wants.

% To handle $\klet$-generalisation, let us consider the following rule
% %
% $$
% \drule{G-LetGen}
% $$
% %
% This rule is non-deterministic, because it requires finding $[[{Q_r}]]$ and
% $[[{Q}]]$. We can modify the constraint solver of
% \cref{sec:constraint-solver} to find $[[{Q_r*Q}]]$, but we
% still have to split the residual into $[[{Q_r}]]$ and
% $[[{Q}]]$ somehow.

% %% What we would like to say is ``$[[{Q}]]$ is the set of linear
% %% constraints''. But it's not clear how to make it formal.

% Any predictable strategy would do: as long as our rule an instance of the
% \rref*{G-LetGen} rule, constraint generation will be sound. Experience
% will tell whether we can find a better suited strategy than the current
% one, which never generalises any constraint.

% \subsection{Empty cases}
% \label{sec:empty-cases}

% Throughout the article we have assumed that $\kcase$-expressions
% always have a non-empty list of alternatives. This is, incidentally,
% also how Haskell originally behaved; though \textsc{ghc} now has an
% |EmptyCase| extension to allow empty lists of alternatives.

% % Not allowing empty lists of alternatives is, therefore not terrible in
% % principle. Though it makes empty types more awkward than they need to
% % be, and, of course, to support the entirety of \textsc{ghc}, we will
% % need to support empty lists of alternatives.

% The reason why it has been omitted from the rest of the article is
% that generating constraints for an empty $\kcase$ requires an $0$-ary version
% of $[[{C1&C2}]]$, usually written $[[{Top}]]$ in Linear Logic. The
% corresponding entailment rule would be
% $$
% \drule{C-Top}
% $$
% That is $[[{Top}]]$ is unconditionally true, and can consume any number
% of linear given constraints--- indeed, the corresponding program is already crashing.
% The \rref*{C-Top} rule thus induces a
% considerable amount of non-determinism in the constraint solver. Eliminating the
% non-determinism induced by $[[{Top}]]$ is ultimately
% what~\citet{resource-management-for-ll-proof-search} builds up
% to. Their methods can be adapted to the constraint solver of
% \cref{sec:constraint-solver} without any technical
% difficulty. We chose, however, to keep empty cases out the
% presentation because they have a very high overhead and would distract from
% the point. Instead, we refer readers
% to~\citet[Section 4]{resource-management-for-ll-proof-search} for a
% careful treatment of $[[{Top}]]$.

\subsection{Inferring Packing and Unpacking}
\label{sec:implicit-existentials}
Recent work~\cite{existentials} describes an algorithm (call it \textsc{edwl}, after the
authors' names) that
can infer the location of the pack and unpack annotations (our $\packbox$ and $\kunpack$)
in a program.%
\footnote{Actually, \citet{existentials} use an $\ottkw{open}$ construct instead of $\kunpack$
to access the contents of an existential package, but that distinction does
not affect our usage of existentials with linear constraints.}
In Section~9.2 of that paper,
the authors extend their system to include class constraints,
much as we allow our existential packages to carry linear constraints.

Accordingly, \textsc{edwl} would work well for us here and remove the need for these annotations.
The \textsc{edwl} algorithm is only a small change on the way some types are treated during
bidirectional type-checking. Though the presentation of linear constraints is not
written using a bidirectional algorithm, our implementation in \textsc{ghc}
is indeed bidirectional (as \textsc{ghc}'s existing type inference algorithm
is bidirectional, as described by \citet{practical-type-inference} and
\citet{visible-type-application}) and produces constraints much like we
have presented here, formally. None of this would change in adapting \textsc{edwl}.
Indeed, it would seem that the two extensions are orthogonal in implementation,
though avoiding the need for explicit packing and unpacking would
make linear constraints easier to use.

% One challenge if existential packing and unpacking are inferred is that
% the order in which a program is executed might become ambiguous.
% Picking up the example from \cref{sec:atomic-references},
% consider this function:

% > writeTwo :: constraint (RW n) =>. AtomRef a n -> a -> a -> () .<= constraint (RW n)
% > writeTwo ref val1 val2 =  let  unit1 = writeRef ref val1
% >                                unit2 = writeRef ref val2 in
% >                           ()

% In understanding this code, we first must worry about laziness. Haskell's |let|
% is lazy, meaning that the calls to |writeRef| might never be evaluated, if nothing
% forces them. Surprisingly, whether or not these get evaluated depends on the types
% that are inferred for |unit1| and |unit2|.

% One possibility is
% |unit1, unit2 :: constraint (RW n) =>. () .<= constraint (RW n)|. With this inferred type,
% the calls to |writeRef| are never evaluated: the provided |constraint (RW n)| is just
% packed with the |()| in the result, ignoring the two |unit|s.

% Another possibility is |unit1, unit2 :: ()|. With this inferred type, both |writeRef|s
% must consume and re-produce the |constraint (RW n)| constraint. Because the produced
% constraint is used, the |writeRef| call must be evaluated (so it can produce that |constraint (RW n)|
% constraint), and the reference |ref| will be updated. However, we still do not
% know the order in which the |writeRef|s will be evaluated: perhaps |unit1| consumes
% the |constraint (RW n)| produced by |unit2|, forcing the |writeRef|s in the
% opposite order to how they are written.

% This is disappointing: we cannot have type inference tell us what order
% our program is to be evaluated. One solution is to reject ambiguous programs
% like |writeTwo|. This could be achieved by changing \rref{Atom-OneL} of
% \Cref{fig:simpl-solver} to require that the desired constraint
% has precisely one matching assumption. Then, when there is any ambiguity,
% we simply reject. Would this be too restrictive in practice? A middle ground
% might be to track (in our list of linear assumptions) when we enter a more
% local scope (this is actually already done by \textsc{ghc}), and reject only
% programs with multiple identical assumptions in the same local scope.

% The issues here---similar to those raised in \cref{sec:let-generalisation}---have
% potential solutions, but the precise way forward is best informed by
% experience, as users begin to adopt these features and we get a better
% sense for prominent patterns and how our choices should be tuned.

\section{Design considerations}
\label{sec:design-considerations}

\critical{TODO}

\subsection{Variation on release functions}
\label{sec:unrestricted-release}

\subsection{Linearly vs sticky scopes}
\label{sec:linearly-vs-sticky}

\subsection{Further considerations on freezing}
\label{sec:freezing-in-details}

\unsure{I don't know yet whether we will need this space}

\section{Related work}
\label{sec:related-work}

\paragraph*{OutsideIn}
\label{sec:outsidein}

Our aim is to integrate the present work in \textsc{ghc}, and
accordingly the qualified type system in
\cref{sec:qualified-type-system} and the constraint inference
algorithm in \cref{sec:type-inference} follow a similar
presentation to that of OutsideIn~\cite{OutsideIn}, \textsc{ghc}'s
constraint solver algorithm.  Even though our presentation is
self-contained, we outline some of the differences from that work.

The solver judgement in OutsideIn takes the following form:
%
\[\mathcal{Q}\ ;\ Q_{\mathit{given}}\ ;\ \overline{\alpha}_{\mathit{tch}} \overset{\mathit{solv}}{\mapsto} C_{\mathit{wanted}} \leadsto Q_{\mathit{residual}}\  ; \ \theta\]
%
The main differences between OutsideIn's solver judgement and our solver judgements in \cref{sec:constraint-solver} are:
\begin{itemize}
  \item OutsideIn's judgement includes top-level axioms schemes separately
($\mathcal{Q}$), which we have omitted for the sake of brevity and are instead
included in $Q_{\mathit{given}}$.
  \item We present the \emph{given} constraints ($Q_{\mathit{given}}$ in OutsideIn) as two separate
constraint sets $[[{UCtx}]]$ and $[[{LCtx}]]$, standing for the unrestricted and linear
parts respectively.
  \item In addition to constraint inference, OutsideIn performs type
inference, requiring additional bookkeeping in the solver judgment. The solver
takes as input a set of \emph{touchable} variables $\overline{\alpha}_{tch}$
which record the type variables that can be unified at any given time, and
produces a type substitution $\theta$ as an output.
As discussed in \cref{sec:type-inference}, we do not perform type
inference, only constraint inference. Therefore, our solver need not return a
type assignment.
  \item Both
OutsideIn and our solver output a set of constraints, $Q_{\mathit{residual}}$ and
$[[{LCtx_o}]]$ respectively. However, the meaning of these contexts is different.
OutsideIn's \emph{residual} constraints $Q_{\mathit{residual}}$
correspond to the part of $C_{\mathit{wanted}}$ that could not be solved from the
assumptions. These residuals are then quantified over in the generalisation step
of the inference algorithm. We omit these residuals, which means that our
algorithm cannot infer qualified types.
Our \emph{output} constraints $[[{LCtx_o}]]$ instead correspond to the part of the
\emph{linear} givens $[[{LCtx_i}]]$ that were not used in the solution for $[[{C_w}]]$.

\item Finally, while OutsideIn has a single kind of conjunction, our constraint
language requires two: $[[{Q1*Q2}]]$ and $[[{Q1&Q2}]]$. This shows up when
generating constraints for $\kcase$ expressions in the~\rref{G-Case} rule.
OutsideIn accumulates constraints across branches (taking the union of each
branch), whereas we need to make sure that each branch of a $\kcase$-expression
consumes the same constraints.
\end{itemize}

%% I (csongor) don't think this is worth mentioning
%% \item A more minor difference with OutsideIn is that we have an
%%   explicit \rref*{E-Sub} rule, while OutsideIn uses simple constraint
%%   entailment directly in the relevant rules. In OutsideIn, only the
%%   \rref*{E-Var} rule needed subsumption; we would also need it for the
%%   \rref*{E-Pack} rule as well. So we preferred having one shared
%%   dedicated rule.
\paragraph*{Ownership}

% The memory ownership example of \cref{sec:memory-ownership} is
% strongly inspired by Rust.
%
Ownership and borrowing are the key features of Rust's safe memory management model.
% As a consequence, it has a much more convenient syntax
% than Linear Haskell with linear constraints can propose.
% Rust's
% convenient syntax comes at the price that it is almost impossible to
% write tail-recursive functions, which is surprising from the
% perspective of a functional programmer.
% On the other hand, the focus of Linear Haskell, as well as this paper,
% is to provide programmers with the tools to create safe interfaces and
% libraries.
In \cref{sec:memory-ownership} we show how linear constraints can be used to
implement such an ownership model as a library.
% The language itself is agnostic about what linear
% constraints mean.
Although linear constraints do not have the
convenience of Rust's syntax, we expect that they will support a
greater variety of abstractions.
% Even though Rust programmers have
% come up with varied abstractions which leverage the borrowing
% mechanism to support applications going beyond memory management (for
% instance, safe file handling), it is unclear that all applications
% supported by linear constraints are reducible to the borrowing
% mechanism.

Clean is another language with built-in ownership typing. Like Haskell
it is a lazy language. Mutation is performed by returning a new
reference, like in Linear Haskell without linear constraints.

\paragraph*{Languages with capabilities}

The idea of using capabilities to enforce high-level resource usage protocols is not new~\citep{DBLP:conf/pldi/DeLineF01},
and as such has been applied in practical programming languages before.
Both Mezzo~\cite{mezzo-permissions} and
\textsc{ats}~\cite{AtsLinearViews} served as inspiration for the
design of linear constraints. Of the two, Mezzo is more specialised,
being entirely built around its system of capabilities.  \textsc{Ats}
is the closest to our system because it appeals explicitly to linear
logic, and because the capabilities (known as \emph{stateful views})
are not tied to a particular use case. However,
\textsc{ats} does not have full inference of capabilities.

Other than that, the two systems have a lot of similarities. They have a
finer-grained capability system than is expressible in Rust (or our
encoding of it in \cref{sec:memory-ownership}) which makes it possible to change
the type of a reference cell upon write (though linear constraints could be used to implement such type-changing references too). They also eschew scoped
borrowing in favour of more traditional read and write capabilities.
% In exchange, neither Mezzo nor \textsc{ats} support $O(1)$ freezing like in
% \cref{sec:memory-ownership}.
% Mezzo, being geared towards functional programming, does support
% freezing, but freezing a nested data structure requires traversing it.
% As far as we know, \textsc{ats} doesn't support
% freezing. \textsc{Ats} is more oriented towards system programming.

%if False
We chose an example in the style of rust for
\cref{sec:memory-ownership} because freezing arrays of arrays
in $O(1)$ was one of the initial motivations of this article. However,
a Mezzo or \textsc{ats} style of capabilities could certainly be
encoded within linear constraints.
%endif

Linear constraints are more general than either Mezzo or \textsc{ats},
while maintaining a considerably simpler inference algorithm, and at
the same time supporting a richer set of constraints (such as \textsc{gadt}s). This
simplicity is a benefit of abstracting over the simple-constraint
domain. In fact, it should be possible to see Mezzo or \textsc{ats} as
particular instantiations of the simple-constraint domain, with linear
constraints providing the general inference mechanism.

% However, both Mezzo and \textsc{ats} have an advantage that we do not:
% they assume that their instructions are properly sequenced, whereas
% basing linear constraints on Haskell, a lazy language, we are forced
% to make sequencing explicit in \textsc{api}s.

\paragraph*{Linearly typed languages}

Affe~\cite{kindly-bent} is a linearly typed \textsc{ml}-style core
language with mutable references and arrays, augmented with a notion
of borrowing. It has dedicated syntax for the scope of borrows. In
contrast, we represent scopes as functions. Affe is presented as a
fully integrated solution, while linear constraints is a small layer
on top of Linear Haskell.

\paragraph*{Logic programming}

There are a lot of commonalities between \textsc{ghc}'s constraint and logic
programs. Traditional type classes can be seen as Horn clause programs, much
like Prolog programs. \textsc{ghc} puts further restrictions in order to
avoid backtracking for speed and predictability.

The recent addition of quantified
constraints~\cite{quantified-constraints} extends type class
resolution to Hereditary Harrop~\cite{hereditary-harrop} programs. A generalisation of the
Hereditary Harrop fragment to linear logic, described by~\citet{hh-ll},
is the foundation of the Lolli language~\cite{hodas-thesis-lolli}.
The authors also coin the notion of \emph{uniform} proof. A fragment where
uniform proofs are complete supports goal-oriented proof search, like
Prolog does.

Completeness of uniform proofs is equivalent to
\cref{lem:inversion}, which, in turn, is used in the proof of the
soundness \cref{lem:generation-soundness}. Therefore our linear
constraints are compatible with quantified constraints: we simply need
to adapt~\cref{lem:inversion}.

It is interesting that goal-oriented search is baked into the
definition of OutsideIn. It's not only used as the constraint solving
strategy, but it seems to required for the soundness of the constraint
generation algorithm. Or, if they are not required, uniform proofs are
at least an effective strategy to prove soundness.

% \paragraph*{Resource usage analysis}

% \Citet{resource-usage-analysis} introduce a framework which can be
% instantiated into many resource analyses (such as proper deallocation
% of resources). In particular they give a
% decision procedure for a wide class of such analyses. Although our
% objects of study intersect, our purpose is quite different as theirs
% is a tool for language designer to design analyses, while ours is for
% programmers to implement new abstractions as libraries.

\section{Conclusion}
\label{sec:conclusion}

We showed how a simple linear type system like that of Linear
Haskell can be extended with an inference mechanism which lets the
compiler manage some of the additional complexity of linear types
instead of the programmer. Linear constraints narrow the gap between linearly
typed languages and dedicated linear-like typing disciplines such as Rust's,
Mezzo's, or \textsc{ats}'s.

% We also demonstrate how an existing constraint solver can be extended to handle
% linearity. Our design of
% linear constraints fits nicely into Haskell. Indeed, linear constraints can be
% thought of as an extension of Haskell's type class mechanism. This way, the
% design also integrates well into \textsc{ghc}, as demonstrated by our prototype
% implementation, which required modest changes to the compiler. Remarkably, all we needed to do was to
% adapt the work of \citet{resource-management-for-ll-proof-search} to the OutsideIn
% framework. It is also quite serendipitous that the notion of uniform
% proof from \citet{hh-ll}, which was introduced to prove the
% completeness of a proof search strategy, ends up being crucial to the
% soundness of constraint generation.

% The memory management \textsc{api} of \cref{sec:memory-ownership} shows how
% Rust's memory ownership model can be implemented as a library using our
% framework. This would not be practical without linear constraints. Certainly,
% ownership proofs could be managed manually, but it is hard to imagine a
% circumstance where this tedious task would be worth the cost.

% This, really, is the philosophy of linear constraints: lowering
% the cost of linear types so that more theoretical applications become
% practical applications. And we achieved this at a surprisingly low price: teaching
% linear logic to \textsc{ghc}'s constraint solver.

% \begin{acks}
%   Jean-Philippe Bernardy is supported by grant
%   \grantnum{clasp}{2014-39} from the \grantsponsor{clasp}{Swedish
%     Research Council}{https://www.vr.se}, which funds the Centre for
%   Linguistic Theory and Studies in Probability (CLASP) in the
%   Department of Philosophy, Linguistics, and Theory of Science at the
%   University of Gothenburg.
% %
%   Nicolas Wu is supported by
%   \grantsponsor{EPSRC}{EPSRC}{https://www.ukri.org/councils/epsrc/}
%   Grant \grantnum{EPSRC}{EP/S028129/1}.


% \end{acks}

% For natbib:
\bibliographystyle{JFPlike}
\bibliography{bibliography}
% For biblatex:
% \printbibliography
\newpage

\appendix

\section{Full descriptions}
\label{sec:appendix:full-descriptions}

In this appendix, we give, for reference, complete descriptions of the
type systems, functions, etc. that we have abbreviated in the main % etc should never be followed by '…'
body of the article.

\subsection{Core calculus}
\label{sec:appendix:core-calculus}

This is the complete version of the core calculus described in
\cref{sec:core-calculus}. The full grammar is given by
\Cref{fig:full:core-grammar} and the type system by
\Cref{fig:full:core-typing-rules}.

\begin{figure}
  \maybesmall
  \centering
  $$
  \begin{array}{lcll}
    [[{a}]], [[{b}]] & \bnfeq & \ldots & \text{Type variables} \\
    [[{x}]], [[{y}]] & \bnfeq & \ldots & \text{Expression variables} \\
    [[{K}]] & \bnfeq & \ldots & \text{Data constructors} \\
    [[{s}]] & \bnfeq & [[{forall as. t}]] & \text{Type schemes} \\
    [[{t}]], [[{u}]] & \bnfeq & [[{a}]] \bnfor [[{exists as. t o- u}]] \bnfor [[{t1 ->_pi t2}]]
                            \bnfor [[{T ts}]] & \text{Types} \\
    [[{G}]], [[{D}]] & \bnfeq & [[{empty}]] \bnfor [[{G, x:_pi s}]] &
                                                              \text{Contexts} \\
    [[{e}]] & \bnfeq & [[{x}]] \bnfor [[{K}]] \bnfor [[{\x. e}]] \bnfor [[e1
                     e2]] \bnfor [[{pack (e1, e2)}]] & \text{Expressions}\\
                 &\bnfor & [[unpack (y,x)=e1 in
                           e2]] \bnfor [[{case_pi e of { alts }}]] &\\
                 &\bnfor & [[let_pi
                           x=e1 in e2]] \bnfor [[{let_pi x : s = e1 in e2}]] &
  \end{array}
  $$
  \caption{Grammar of the core calculus}
  \label{fig:full:core-grammar}
\end{figure}

\begin{figure}
  \maybesmall
  \centering
  \drules[L]{$[[G |- e : t]]$}{Core language
    typing}{Var,Abs,App,Pack,Unpack,Let,Case}
  \caption{Core calculus type system}
  \label{fig:full:core-typing-rules}
\end{figure}

\subsection{Desugaring}
\label{sec:appendix:desugaring}

The complete definition of the desugaring function from
\cref{sec:desugaring} can be found in
\Cref{fig:full:desugaring}.

For the sake of concision, we allow ourselves to write nested patterns
in $\kcase$ expressions of the core language. Desugaring nested patterns
into atomic $\kcase$ expression is routine.

In the complete description, we use a device which was omitted in the
main body of the article. Namely, we'll need a way to turn every
$[[{Ev(omega.Q)}]]$ into an $[[{Ur(Ev(Q))}]]$. For any
$[[e : Ev(omega.Q)]]$, we shall write $[[urify(Q;e) :
Ur(Ev(omega.Q))]]$. As a shorthand, particularly useful in nested
patterns, we will write $[[{case_pi e of {urified(Q;x) -> e'}}]]$ for
$[[{case_pi urify(Q;e) of {Ur x -> e'}}]]$.
%
$$
\left\{
  \begin{array}{lcl}
    [[{urify(Empty;e)}]]& = & [[{case_1 e of {() -> Ur ()}}]] \\
    [[{urify(1.q;e)}]] & = & [[{e}]] \\
    [[{urify(omega.q;e)}]] & = & [[{case_1 e of {Ur x -> Ur (Ur x)}}]] \\
    [[{urify(Q1*Q2;e)}]] & = & [[{case_1 e of {(urified(Q1;x), urified(Q2;y)) -> Ur (x,y)}}]]
  \end{array}
\right.
$$
We will omit the $[[{Q}]]$ in $[[{urify(Q;e)}]]$ and write
$[[{urify(e)}]]$ when it can be easily inferred from the context.


\begin{figure}
  \small
  \centering

%{
%format Ds(z)(j) = "\dsterm{\ottmv{" z "}}{" j "}"
%format * = "[[*]]"
%format ** = "\mathbin{⋅}"
%format ->. = "\to_{1}"
%format ->> = "\to_{\pi}"
%format ->>> = "\to_{\omega}"
%format Ev(x) = "\dsevidence{" x "}"
%format G = "[[{G}]]"
%format G1 = "[[{G1}]]"
%format G2 = "[[{G2}]]"
%format ListOf (b) = "\overline{" b "}"
%format Of (w) (a) (b) = a"\mathop{:_{" w "}}"b
%format OneOf (a) (b) = a"\mathop{:_{1}}"b
%format Q = "[[{Q}]]"
%format Q1 = "[[{Q1}]]"
%format Q2 = "[[{Q2}]]"
%format Sub t as bs = t "[" as "/" bs "]"
%format alts = "[[alts]]"
%format as = "[[{as}]]"
%format case_1 = "[[case_1]]"
%format case_omega = "[[case_omega]]"
%format e1 = "[[{e1}]]"
%format e2 = "[[{e2}]]"
%format ei = "[[{ei}]]"
%format let_1 = "[[let_1]]"
%format let_omega = "[[let_omega]]"
%format omega = "[[{omega}]]"
%format pi = "[[{pi}]]"
%format pii = "[[{pii}]]"
%format t = "[[{t}]]"
%format t1 = "[[{t1}]]"
%format t2 = "[[{t2}]]"
%format ts = "[[{ts}]]"
%format u = "[[{u}]]"
%format ui = "[[{ui}]]"
%format unpack(x) = "\klet\ \packbox " x
%format urified(x) = "\underline{" x "}"
%format us = "[[{us}]]"
%format xi = "[[{xi}]]"
%format xsi = "[[{xsi}]]"
%format z1 = "[[{z1}]]"
%format z2 = "[[{z2}]]"
%format z2' = "[[{z2}]]''"
%format |- = "[[|-]]"
%format ||- = "[[||-]]"
$$
\left\{\;
\begin{minipage}{0.8\linewidth}
\begin{code}
Ds(z)(Q;G |- x : u[ts/as])  =
    x z
Ds(z)(Q;G |- \x.e : t1 ->> t2) =
  \x. Ds(z)(Q;G, Of pi x t1 |- e : t2)
Ds(z)(Q1*Q2; G1+G2 |- e1 e2 : t) =
  case_1 z of { (z1, z2) ->
    (Ds(z1)(Q1;G1 |- e1 : t1 ->. t)) (Ds(z2)(Q2;G2 |- e2 : t1)) }
Ds(z)(Q1* omega ** Q2; G1+ omega ** G2 |- e1 e2 : t) =
  case_1 z of { (z1, urified(z2)) ->
    (Ds(z1)(Q1;G1 |- e1 : t1 ->>> t)) (Ds(z2)(Q2;G2 |- e2 : t1)) }
Ds(z)(Q * Sub Q1 us as;G |- pack e : exists as. t .<= Q1) =
  case_1 z of { (z', z'') ->
    pack (z'', Ds(z')( Q ; G |- e : Sub t us as))}
Ds(z)(Q1 * Q2;G1 + G2 |- unpack x = e1 in e2 : t) =
  case_1 z of { (z1, z2) ->
    unpack (z',x) = Ds(z1)(Q1;G1 |- e1 : exists as. t1 .<= Q) in
    let_1 z2' = (z2,z') in
    Ds(z2')(Q2 * Q;G2, OneOf x t1 |- e2 : t)}
Ds(z)(Q1 * Q2 ;G1+G2 |- let_1 x = e1 in e2 : t) =
  case_1 z of { (z1, z2) ->
    let_1 x : Ev(Q) ->. t1 = Ds(z1)(Q1*Q;G1 |- e1 : t1)
    in Ds(z2)(Q2;G2, OneOf x t1 |- e2 : t)}
Ds(z)(omega ** Q1 * Q2 ;omega ** G1+G2 |- let_omega x = e1 in e2 : t) =
  case_1 z of { (urified(z1), z2) ->
    let_omega x : Ev(Q) ->. t1 = Ds(z1)(Q1*Q;G1 |- e1 : t1) in
    Ds(z2)(Q2;G2, Of omega x t1 |- e2 : t)}
Ds(z)(Q1 * Q2 ;G1+G2 |- let_1 x : forall as. Q =>. t1 = e1 in e2 : t) =
  case_1 z of { (z1, z2) ->
    let_1 x : forall as. Ev(Q) ->. t1 = Ds(z1)(Q1*Q;G1 |- e1 : t1) in
    Ds(z2)(Q2;G2, OneOf x (forall as. Q =>. t1) |- e2 : t)}
Ds(z)(omega ** Q1 * Q2 ;omega ** G1+G2 |- let_omega x : forall as. Q =>. t1 = e1 in e2 : t) =
  case_1 z of { (urified(z1), z2) ->
    let_omega x : forall as. Ev(Q) ->. t1 = Ds(z1)(Q1*Q;G1 |- e1 : t1) in
    Ds(z2)(Q2;G2, Of omega x t1 |- e2 : t)}
Ds(z)(omega ** Q1*Q2;omega ** G1+G2 |- case_1 e of { alts } : t)  =
  case_1 z of { (urified(z1), z2) ->
    case_1 (Ds(z1)(Q1;G1 |- e : T ts)) of
      { ListOf(K xsi -> Ds(z2)( Q2; G2, ListOf(Of ((pi ** pii)) xi (Sub ui ts as)) |- ei : t))}}
Ds(z)(Q1*Q2;G1+G2 |- case_omega e of { alts } : t)  =
  case_1 z of { (z1, z2) ->
    case_omega (Ds(z1)(Q1;G1 |- e : T ts)) of
      { ListOf(K xsi -> Ds(z2)( Q2; G2, ListOf(Of ((pi**pii)) xi (Sub ui ts as)) |- ei : t))}}
\end{code}
\end{minipage}
\right.
$$

%}

  \caption{Desugaring}
  \label{fig:full:desugaring}
\end{figure}

\section{Proofs}
\label{sec:appendix:proofs-lemmas}

\setcounter{subsection}{4}
\subsection{Lemmas on the qualified type system}
\label{sec:appendix:qual-type-syst}

\begin{proof}[Proof of \cref{lem:q:scaling}]
  Let us prove separately the cases $[[{pi}]]=[[{1}]]$ and
  $[[{pi}]]=[[{omega}]]$.
  \begin{itemize}
  \item When $[[{pi}]]=[[{1}]]$, then $[[{pi.Q}]]=[[{Q}]]$ for all
    $[[{Q}]]$, hence $[[Q1||-Q2]]$ implies $[[pi.Q1 ||- pi.Q2]]$.
  \item For the case $[[{pi}]]=[[{omega}]]$, let us consider a few
    properties. First note that, for any $[[{Q}]]$,
    $[[{omega.Q}]]=[[{omega.Q * omega.Q}]]$. From which it follows,
    using the laws of \cref{def:entailment-relation}, that
    $[[omega.Q ||- Q1 * Q2]]$ if and only if $[[omega.Q ||- Q1]]$ and
    $[[omega.Q ||- Q2]]$.

    This means that to verify that
    $[[omega.Q1 ||- omega.Q2]]$, it is equivalent to prove that $[[omega.Q1
    ||- omega.q2]]$ for each
    $[[{q2}]]∈[[{UCtx}]]$ (letting $[[{omega.Q2}]]=[[{(UCtx,
      emptyset)}]]$). In turn, by \cref{def:entailment-relation} and
    observing that $[[{omega.(omega.Q1)}]] = [[{Q1}]]$, this is
    equivalent to $[[omega.Q1 ||- 1.q2]]$.

    This follows from the fact that $[[Q1 ||- Q2]]$ implies
    $[[omega.Q1 ||- Q2]]$ (\cref{def:entailment-relation}) and the
    property, shown above, that $[[omega.Q1 ||- Q2 * Q2']]$ if and
    only if $[[omega.Q1 ||- Q2]]$ and $[[omega.Q1 ||- Q2']]$.
  \end{itemize}
\end{proof}

\begin{proof}[Proof of \cref{lem:q:scaling-inversion}]
  Let us prove separately the cases $[[{pi}]]=[[{1}]]$ and
  $[[{pi}]]=[[{omega}]]$.
  \begin{itemize}
  \item When $[[{pi}]]=[[{1}]]$, then $[[{pi.Q}]]=[[{Q}]]$ for all
    $[[{Q}]]$, in particular $[[Q1||- 1.Q2]]$ implies that
    $[[{Q1}]]=[[{1.Q1}]]$ with $[[Q1 ||- Q2]]$.
  \item When $[[{pi}]]=[[{omega}]]$, then let us first remark, letting
    $[[{omega.Q2}]]=[[{(UCtx, emptyset)}]]$ that, by a straightforward
    induction on the cardinality of $[[{UCtx}]]$ it is sufficient to
    prove that the result holds for atomic constraints.

    That is, we need to prove that if $[[Q1 ||- omega.q2]]$ then
    there exists $[[{Q'}]]$ such that $[[{Q1}]]=[[{omega.Q'}]]$ and
    $[[Q' ||- rho.q2]]$ (for all $[[{rho}]]$).

    This result, in turns, holds by \cref{def:entailment-relation}.
  \end{itemize}
\end{proof}

\begin{lemma}\label{lem:simples:monoid-action}
  The following equality holds $[[{pi.(rho.Q)}]]=[[{(pi.rho).Q}]]$
\end{lemma}
\begin{proof}
  Immediate by case analysis of $[[{pi}]]$ and $[[{rho}]]$.
\end{proof}

\setcounter{subsection}{5}
\subsection{Lemmas on constraint inference}
\label{sec:appendix:constraint-inference}

\begin{lemma}[$[[{Dup}]]$ discarding]
  \label{lem:dup-weakening}
  The two following, equivalent, properties hold
  \begin{itemize}
  \item if $[[Qdup \in Dup]]$, then $[[Qdup ||- Empty]]$
  \item if $[[Q1 ||- Q2]]$ and $[[Qdup \in Dup]]$, then $[[Q1 * Qdup ||- Q2]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The two properties are equivalent
  \begin{itemize}
  \item using $[[{C1}]]=[[{C2}]]=[[{Empty}]]$, the latter implies the
    former
  \item The former implies the latter by tensoring together
    $[[Q1 ||- Q2]]$ and $[[Qdup ||- Empty]]$ following the rules
    of~\cref{fig:entailment-relation}.
  \end{itemize}
  Let $[[Qdup \in Dup]]$, then for each $[[{1.q}]] \in [[{Qdup}]]$,
  $[[1.q ||- Empty]]$ (per~\cref{fig:entailment-relation}), tensoring
  each of these entailments together and with the $[[{omega.q}]] \in [[{Qdup}]]$, we get $[[Qdup ||- Empty]]$.
\end{proof}

\begin{lemma}[$[[{Dup}]]$ duplication]
  \label{lem:dup-contraction}
  The two following, equivalent, properties hold
  \begin{itemize}
  \item if $[[Qdup \in Dup]]$, then $[[Qdup ||- Qdup * Qdup]]$
  \item if $[[Q1 * Qdup ||- Q2]]$, $[[Qdup * Q1' ||- Q2']]$, and
    $[[Qdup \in Dup]]$, then $[[Q1 * Qdup * Q1'||- Q2 * Q2']]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The proof is similar to that of~\cref{lem:dup-weakening}
\end{proof}

\begin{lemma}[Transitive tensor decomposition]
  \label{lem:transitive-tensor-decomposition}
  if $[[Qdup \in Dup]]$ and $[[Q ||- Q1 * Qdup * Q2]]$, then there
  exists $[[Q1']]$, $[[Qdup']]$, $[[Q2']]$, such that
  \begin{itemize}
  \item $[[Q1' * Qdup' ||- Q1]]$
  \item $[[Qdup' * Q2' ||- Q2]]$
  \item $[[Qdup' ||- Qdup]]$
  % \item $[[{Q}]] = [[{Q1' * Qdup' * Q2'}]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  By the inversion-of-tensor rule from~\cref{fig:entailment-relation},
  we get that ther exists $[[{Q'}]]$, $[[{Qdup'}]]$, and $[[{Q2'}]]$,
  such that
  \begin{itemize}
  \item $[[{Q}]] = [[{Q' * Qdup' * Q2'}]]$
  \item $[[Qdup' * Q2' ||- Q2]]$
  \item $[[Q' * Qdup' ||- Q1 * Qdup]]$. The inversion-of-tensor rule
    applies further to this case: there exists $[[{Q1'}]]$,
    $[[{Qdup''}]]$, and $[[{Q''}]]$ such that
    \begin{itemize}
    \item $[[{Q' * Qdup'}]] = [[{Q1' * Qdup'' * Q''}]]$
    \item $[[Q1' * Qdup'' ||- Q1']]$
    \item $[[Qdup'' * Q'' ||- Qdup']]$
    \end{itemize}
  \end{itemize}
  Observe the following
  \begin{itemize}
  \item $[[Qdup'' * Q'' \in Dup]]$ (because of the requirements
    of~\cref{fig:entailment-relation}). Let's write
    $[[{Qdup'''}]] = [[{Qdup'' * Q''}]]$.
  \item $[[{Q}]] = [[{Q1' * Qdup''' * Q2'}]]$
  \item We have
    \begin{itemize}
    \item $[[Q1' * Qdup''' ||- Q1]]$. Because
      \begin{itemize}
      \item $[[{Q1' * Qdup'''}]] = [[{Q' * Qdup'}]]$
      \item therefore $[[Q1' * Qdup''' ||- Q1 * Qdup]]$
      \item by~\cref{lem:dup-weakening}, and by transitivity of the
        entailment relation (per~\cref{fig:entailment-relation}), we
        can drop $[[{Qdup}]]$ from the conclusion.
      \end{itemize}
    \item $[[Qdup''' ||- Qdup']]$ (by definition of $[[{Qdup'''}]]$)
    \item $[[Qdup''' * Q2' ||- Q2]]$
      \begin{itemize}
      \item By tensoring together, per~\cref{fig:entailment-relation},
        $[[Qdup''' ||- Qdup']]$ and $[[Q2' ||- Q2']]$, we get
        $[[Qdup''' * Q2' ||- Qdup' * Q2']]$
      \item then we get the desired result by transitivity of the
        entailment relation.
      \end{itemize}
    \end{itemize}
  \end{itemize}

  This concludes the proof
\end{proof}


\begin{proof}[Proof of \cref{lem:inversion}]
  The cases $[[Q |- C1 & C2]]$ and $[[Q |- pi.(Q2 => C)]]$ are
  straightforward by induction, so let us prove them first
  \begin{itemize}
  \item Suppose $[[Q |- C1 & C2]]$, then there are two cases
    \begin{itemize}
    \item either it is the conclusion of a \rref*{C-With} rule,
      and the result is immediate.
    \item or it is the result of a \rref*{C-Dom} rule, then, there
      exists $[[{Q'}]]$, such that $[[Q ||- Q']]$ and
      $[[Q' |- C1 & C2]]$.

      By induction $[[Q' |- C2]]$ and $[[Q' |- C2]]$, applying
      \rref*{C-Dom} to both gives $[[Q |- C2]]$ and $[[Q |- C2]]$ as
      required.
    \end{itemize}

  \item Suppose $[[Q |- pi.(Q2 => C)]]$, then there are two cases
    \begin{itemize}
    \item either it is the conclusion of a \rref*{C-Impl} rule,
      and the result is immediate.
    \item or it is the result of a \rref*{C-Dom} rule, then, there
      exists $[[{Q'}]]$, such that $[[Q ||- Q']]$ and
      $[[Q' |- pi.(Q2 => C)]]$.

      By induction, there exists $[[{Q1'}]]$ such that $[[Q1' * Q2 |-
      C]]$ and $[[{Q'}]] = [[{pi.Q1'}]]$,
      by~\cref{fig:entailment-relation}, there exists $[[{Q1}]]$ such
      that $[[{Q}]] = [[{pi.Q1}]]$ and $[[Q1 ||- Q1']]$. Hence $[[Q1 *
      Q2 ||- Q1' * Q2]]$, which lets us conclude with \rref*{C-Dom}.
    \end{itemize}
  \end{itemize}

  For $[[Q |- C1 * C2]]$ we have the following cases:
  \begin{itemize}
  \item either it is the conclusion of a \rref*{C-Tensor} rule, and
    the result is immediate
  \item or it is the result of a \rref*{C-Id} rule, in which case
    $[[{Q}]] = [[{C1 * C2}]]$, which proves the result
  \item or it is the result of a \rref*{C-Dom} rule, in which case
    there is $[[{Q'}]]$ such that $[[Q ||- Q']]$ and $[[Q' |- C1 * C2]]$.

    By induction, there exist $[[{Q1'}]]$, $[[{Qdup'}]]$, and
    $[[{Q2'}]]$, such that $[[Qdup' \in Dup]]$, $[[Q1' * Qdup' |- C1]]$,
    $[[Qdup' * Q2' |- C2]]$, and $[[{Q'}]] = [[{Q1' * Qdup' * Q2'}]]$.

    Then~\cref{lem:transitive-tensor-decomposition}, gives us
    $[[{Q1}]]$, $[[{Qdup}]]$, and $[[{Q2}]]$ such that
    \begin{itemize}
    \item $[[{Q}]] = [[{Q1* Qdup * Q2}]]$
    \item $[[Qdup \in Dup]]$
    \item $[[Q1 * Qdup ||- Q1']]$
    \item $[[Qdup * Q2 ||- Q2']]$
    \item $[[Qdup ||- Qdup']]$
    \end{itemize}
    By~\ref{lem:dup-contraction}, we can further deduce that
    \begin{itemize}
    \item $[[Q1 * Qdup ||- Q1' * Qdup']]$
    \item $[[Qdup * Q2 ||- Qdup' * Q2']]$
    \end{itemize}
    Which concludes the proof, by the \rref*{C-Dom} rule
  \end{itemize}
\end{proof}


\begin{proof}[Proof of \cref{lem:wanted:promote}]
  By induction on the syntax of $[[{C}]]$
  \begin{itemize}
  \item If $[[{C}]]=[[{Q'}]]$, then the result follows
    from \cref{lem:q:scaling}
  \item If $[[{C}]]=[[{C1*C2}]]$, then we can prove the result like we
    proved the corresponding case in \cref{lem:q:scaling},
    using \cref{lem:inversion}.
  \item If $[[{C}]]=[[{C1&C2}]]$, then we the case where $[[{pi}]]=[[{1}]]$ is
    immediate, so we can assume without loss of generality that
    $[[{pi}]]=[[{omega}]]$, and, therefore, that $[[{pi.C}]] = [[pi.C1 *
    pi.C2]]$.
    By \cref{lem:inversion}, we have that $[[Q|-C1]]$ and
    $[[Q|-C2]]$; hence, by induction, $[[omega.Q |- omega.C1]]$ and
    $[[omega.Q |- omega.C1]]$.
    Then, by definition of the entailment relation, we have $[[omega.Q
    * omega.Q |- omega.C1 * omega.C2]]$, which concludes,
    since $[[{omega.Q}]] = [[{omega.Q * omega.Q}]]$.
  \item If $[[{C}]]=[[{rho.(Q1 => C')}]]$, then by
    \cref{lem:inversion}, there is a $[[{Q'}]]$ such that
    $[[{Q}]]=[[{pi.Q'}]]$ and $[[Q'*Q1 |- C']]$. Applying
    rule~\rref*{C-Impl} with $[[{pi.rho}]]$, we get
    $[[(pi.rho).Q' |- (pi.rho).(Q1 => C')]]$.

    In other words: $[[pi.Q |- pi.(rho.(Q=>C))]]$ as expected.
  \end{itemize}
\end{proof}

\begin{proof}[Proof of \cref{lem:wanted:demote}]
  By induction on the syntax of $[[{C}]]$
  \begin{itemize}
  \item If $[[{C}]]=[[{Q'}]]$, then the result follows from
    \cref{lem:q:scaling-inversion}
  \item If $[[{C}]]=[[{C1*C2}]]$, then we can prove the result like we
    proved the corresponding case in
    \cref{lem:q:scaling-inversion} using
    \cref{lem:inversion}.
  \item If $[[{C}]]=[[{C1&C2}]]$, then we the case where $[[{pi}]]=[[{1}]]$ is
    immediate, so we can assume without loss of generality that
    $[[{pi}]]=[[{omega}]]$, and, therefore, that
    $[[{pi.C}]] = [[{pi.C1 * pi.C2}]]$. By \cref{lem:inversion},
    there exist $[[{Q1}]]$ and $[[{Q2}]]$ such that $[[Q1|- omega.C1]]$,
    $[[Q2|- omega.C2]]$ and $[[{Q}]]=[[{Q1 * Q2}]]$. By induction
    hypothesis, we get $[[{Q1}]] = [[{omega.Q1'}]]$ and $[[{Q2}]] = [[{omega.Q2'}]]$
    such that $[[Q1' |- C1]]$ and $[[Q2' |- C2]]$. From which it
    follows that $[[omega.Q1'*omega.Q2' |- C1]]$ and
    $[[omega.Q1'*omega.Q2' |- C1]]$ (by
    \cref{lem:wanteds:weakening}) and, finally,
    $[[{Q}]]=[[{omega.Q}]]$ (by \cref{lem:wanteds:module-action})
    and $[[Q |- C1 & C2]]$.
  \item If $[[{C}]]=[[{rho.(Q1 => C')}]]$, then
    $[[{pi.C}]] = [[{(pi.rho). (Q1 => C')}]]$. The result follows
    immediately by \cref{lem:inversion}.
  \end{itemize}
\end{proof}

\begin{proof}[Proof of \cref{lem:generation-soundness}]
  By induction on $[[G |-> e : t ~> C]]$
  \begin{description}
  \item[\rref*{G-Var}] We have
    \begin{itemize}
    \item $[[G1 = x :_1 forall as. Q =o u]]$
    \item $[[G1 + omega.G2 |-> x : u[ts/as] ~> Q[ts/as] ]]$
    \item $[[Q_g |- Q[ts/as] ]]$
    \end{itemize}
    Therefore, by rules~\rref*{E-Var} and~\rref*{E-Sub}, it follows
    immediately that $[[Q_g ; G1 + omega.G2 |- x : u[ts/as] ]]$
  \item[\rref*{G-Abs}] We have
    \begin{itemize}
    \item $[[G |-> \x. e : t0 ->_pi t ~> C]]$
    \item $[[Q_g |- C]]$
    \item $[[G, x:_pi t0 |-> e : t ~> C]]$
    \end{itemize}
    By induction hypothesis we have
    \begin{itemize}
    \item $[[Q_g; G, x:_pi t0 |- e : t]]$
    \end{itemize}
    From which follows that $[[Q_g; G |- \x. e : t0 ->_pi t]]$.
  \item[\rref*{G-Let}] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> let_pi x = e1 in e2 : t ~> pi.C1 * C2]]$
    \item $[[Q_g |- pi.C1 * C2]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \item $[[G1 |-> e1 : t1 ~> C1]]$
    \end{itemize}
    By \cref{lem:inversion,lem:wanted:demote}, there exist $[[{Q1}]]$,
    $[[{Qdup}]]$ and $[[{Q_2}]]$ such that\info{Here I used,
      implicitly (and without proof), the easy fact that if there
      exists $[[{Q'}]]$ such that $[[{Q}]]=[[{pi.Q'}]]$, then
      $[[{Q}]]=[[{pi.Q}]]$ (because $[[{pi.pi}]] = [[{pi}]]$) and $[[Q
      ||- Q']]$ (identity for $[[{pi}]]=[[{1}]]$ and dereliction for $[[{pi}]]=[[{omega}]]$).}
    \begin{itemize}
    \item $[[Q_1 * Qdup |- C1]]$
    \item $[[Qdup * Q_2 |- C2]]$
    \item $[[{Q_g}]] = [[{pi.Q_1 * Qdup * Q_2}]]$
    \item $[[Qdup \in Dup]]$
    \item $[[{pi.Qdup}]] = [[{Qdup}]]$
    \end{itemize}
    By induction hypothesis we have
    \begin{itemize}
    \item $[[Q_1 * Qdup; G1 |- e1 : t1]]$
    \item $[[Qdup * Q_2; G2, x:_pi  t1 |- e1 : t1]]$
    \end{itemize}
    From which follows that $[[Q_g; pi.G1+G2 |- let_pi x = e1 in e2 :
    t]]$.
  \item[\rref*{G-LetSig}] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> let_pi x : forall as. Q =o t1 = e1 in e2 : t ~>
      C2 * pi.(Q => C1)]]$
    \item $[[Q_g |- C2 * pi.(Q => C1)]]$
    \item $[[G1 |-> e1 : t1 ~> C1]]$
    \item $[[G2, x:_pi forall as. Q =o t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By \cref{lem:inversion,lem:wanted:demote}, there exist $[[{Q1}]]$,
    $[[Qdup]]$, $[[{Q2}]]$ such
    that
    \begin{itemize}
    \item $[[Qdup * Q2 |- C2]]$
    \item $[[Q1*Qdup*Q |- C]]$
    \item $[[{Q_g}]] = [[{pi.Q_1 * Qdup * Q_2}]]$
    \item $[[Qdup \in Dup]]$
    \item $[[{pi.Qdup}]] = [[{Qdup}]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q1*Qdup*Q;G1 |- e1 : t1]]$
    \item $[[Qdup*Q2; G2, x:_pi forall as. Q =o t1 |- e2 : t]]$
    \end{itemize}
    Hence $[[Q_g; pi.G1+G2 |- let_pi x : forall as. Q =o t1 = e1 in e2 : t]]$
  \item[\rref*{G-App}] \info{Most of the linearity problems are in the App
      rule. Unpack is also relevant.}
    We have
    \begin{itemize}
    \item $[[G1+pi.G2 |-> e1 e2 : t ~> C1 * pi.C2]]$
    \item $[[Q_g |- C1 * pi.C2]]$
    \item $[[G1 |-> e1 : t2 ->_pi t ~> C1]]$
    \item $[[G2 |-> e2 : t2 ~> C2]]$
    \end{itemize}
    By \cref{lem:inversion,lem:wanted:demote}, there exist
    $[[{Q1}]]$, $[[{Qdup}]]$, $[[{Q2}]]$ such that
    \begin{itemize}
    \item $[[Q1*Qdup |- C1]]$
    \item $[[Qdup*Q2 |- C2]]$
    \item $[[{Q_g}]] = [[{Q1 * Qdup * pi.Q2}]]$
    \item $[[Qdup \in Dup]]$
    \item $[[{pi.Qdup}]] = [[{Qdup}]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q1*Qdup; G1 |- e1 : t2 ->_pi t]]$
    \item $[[Qdup* Q2; G2 |- e2 : t2]]$
    \end{itemize}
    Hence $[[Q_g; G1+pi.G2 |- e1 e2 : t]]$.
  \item[\rref*{G-Pack}] We have
    \begin{itemize}
    \item $[[G |-> pack e : exists as. t o= Q ~> C * Q[us/as] ]]$
    \item $[[Q_g |- C * Q[us/as] ]]$
    \item $[[G |-> e : t[us/as] ~> C]]$
    \end{itemize}
    By \cref{lem:inversion}, there exist $[[{Q_1}]]$, $[[{Qdup}]]$, $[[{Q_2}]]$
    such that
    \begin{itemize}
    \item $[[Q_1 * Qdup |- C]]$
    \item $[[Qdup * Q_2 |- Q[us/as] ]]$
    \item $[[{Q_g}]] = [[{Q_1*Qdup*Q_2}]]$
    \item $[[Qdup \in Dup]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q_1 * Qdup; G |- e : t[us/as] ]]$
    \end{itemize}
    So we have $[[Q_1 * Qdup * Q[us/as] ; G |- pack e : exists as. t o=
    Q]]$. By~\cref{lem:dup-contraction} rule~\rref*{E-Sub}, we conclude
    $[[Q_g ; omega.G |- pack e : exists as. t o= Q]]$.
  \item[\rref*{G-Unpack}] We have
    \begin{itemize}
    \item $[[G1+G2 |-> unpack x = e1 in e2 : t ~> C1 * 1.(Q' => C2)]]$
    \item $[[Q_g |- C1 * 1.(Q' => C2)]]$
    \item $[[G1 |-> e1 : exists as. t1 o= Q' ~> C1]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By \cref{lem:inversion}, there exist $[[{Q_1}]]$, $[[{Qdup}]]$, $[[{Q_2}]]$
    such that
    \begin{itemize}
    \item $[[Q_1 * Qdup |- C1]]$
    \item $[[Qdup * Q_2 * Q' |- C2]]$
    \item $[[{Q_g}]] = [[{Q1 * Qdup * Q2}]]$
    \item $[[Qdup \in Dup]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q_1*Qdup; G1 |- e1 : exists as. t1 o= Q']]$
    \item $[[Qdup*Q_2*Q ; G2 |- e2 : t]]$
    \end{itemize}
    Therefore $[[Q_g ; G1 + G2 |- unpack x = e1 in e2 : t]]$.
  \item[\rref*{G-Case}] We have
    \begin{itemize}
    \item $[[pi.G + D |-> case_pi e of {alts} : t ~> pi.C * && Ci]]$
    \item $[[Q_g |- pi.C * && Ci]]$
    \item $[[G |-> e : T ss ~> C]]$
    \item For each $i$, $[[D, <xi:_(pi.pii) ui[ss/as]> |-> ei : t ~> Ci]]$
    \end{itemize}
    By repeated uses of \cref{lem:inversion} as well as \cref{lem:wanted:demote}, there exist
    $[[{Q}]]$, $[[{Qdup}]]$, $[[{Q'}]]$ such that
    \begin{itemize}
    \item $[[Q * Qdup |- C]]$
    \item For each $i$, $[[Qdup * Q' |- Ci]]$
    \item $[[{Q_g}]] = [[{pi.Q * Qdup * Q'}]]$
    \item $[[Qdup \in Dup]]$
    \item $[[{pi.Qdup}]] = [[{Qdup}]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q*Qdup; G |- e : T ss]]$
    \item For each $i$, $[[Qdup*Q';D, <xi:_(pi.pii) ui[ss/as]> |- ei : t]]$
    \end{itemize}
    Therefore $[[Q_g ; pi.G + D |- case_pi e of {alts} : t]]$.
  \end{description}
\end{proof}

\begin{proof}[Proof of \cref{lem:solver-soundness}]
  By induction on $[[UCtx; DCtx; LCtx_i |-s C ~> LCtx_o]]$
  \begin{description}
  \item[\rref*{S-Atom}] We have
  \begin{itemize}
          \item $[[UCtx ; DCtx ; LCtx_i |-s pi.q ~> LCtx_o]]$
          \item $[[UCtx ; DCtx ; LCtx_i |-simp pi.q ~> LCtx_o]]$
  \end{itemize}
  By \cref{prop:atomic-solver-soundness} we have
  \begin{enumerate}
  \item $[[{LCtx_o}]]\subseteq [[{LCtx_i}]]$
  \item $[[(UCtx, DCtx \u LCtx_i) ||- pi.q * (emptyset, LCtx_o)]]$
  \end{enumerate}
  Then by \rref*{C-Dom} we have $[[(UCtx, LCtx_i) |- pi.q * (emptyset, LCtx_o)]]$.
  \item[\rref*{S-Add}] We have
  \begin{itemize}
          \item $[[UCtx ; DCtx ; LCtx_i |-s C1 & C2 ~> LCtx_o]]$
          \item $[[UCtx ; DCtx ; LCtx_i |-s C1 ~> LCtx_o]]$
          \item $[[UCtx ; DCtx ; LCtx_i |-s C2 ~> LCtx_o]]$
  \end{itemize}
  By induction hypothesis we have
  \begin{itemize}
          \item $[[{LCtx_o}]]\subseteq [[{LCtx_i}]]$
          \item $[[(UCtx, DCtx \u LCtx_i) |- C1 * (emptyset, LCtx_o)]]$
          \item $[[(UCtx, DCtx \u LCtx_i) |- C2 * (emptyset, LCtx_o)]]$
  \end{itemize}
  Then by \rref*{C-With} we have $[[(UCtx, DCtx \u LCtx_i) |- C1 & C2 * (emptyset, LCtx_o)]]$.
  \item[\rref*{S-Mult}] We have
  \begin{itemize}
          \item $[[UCtx ; DCtx ; LCtx_i |-s C1 * C2 ~> LCtx_o]]$
          \item $[[UCtx ; DCtx ; LCtx_i |-s C1 ~> LCtx_o']]$
          \item $[[UCtx ; DCtx ; LCtx_o' |-s C2 ~> LCtx_o]]$
  \end{itemize}
  By induction hypothesis we have
  \begin{itemize}
          \item $[[{LCtx_o}]]\subseteq [[{LCtx_o'}]]$
          \item $[[{LCtx_o'}]]\subseteq [[{LCtx_i}]]$
          \item $[[(UCtx, DCtx \u LCtx_i) |- C1 * (emptyset, LCtx_o')]]$
          \item $[[(UCtx, DCtx \u LCtx_o') |- C2 * (emptyset, LCtx_o)]]$
  \end{itemize}
  Then
  \begin{itemize}
  \item by transitivity of $\subseteq$ we have
    $[[{LCtx_o}]]\subseteq [[{LCtx_i}]]$, and by \rref*{C-Tensor} we
    have
    $[[(UCtx, DCtx \u LCtx_i) * (UCtx , DCtx \u LCtx_o') |- C1 * C2 *
    (emptyset, LCtx_o') * (emptyset, LCtx_o)]]$
  \item by~\ref{lem:dup-contraction} and the definition of tensor on
    unrestricted constraints, we have
    $[[(UCtx, DCtx \u LCtx_i) * (emptyset , LCtx_o') |- C1 * C2 *
    (emptyset, LCtx_o') * (emptyset, LCtx_o)]]$
  \item by~\cref{lem:inversion} we have
    $[[(UCtx, LCtx_i) |- C1 * C2 * (emptyset, LCtx_o)]]$.
  \end{itemize}
  \item[\rref*{S-ImplOne}] We have
  \begin{itemize}
          \item $[[UCtx ; DCtx ; LCtx_i |-s 1.((UCtx0, LCtx0) => C) ~> LCtx_o]]$
          \item $[[UCtx \u UCtx0 ; DCtx \u (LCtx0 \n Dup) ; LCtx_i \u
            (LCtx0 \m Dup) |-s C ~> LCtx_o]]$
          \item $[[LCtx_o \subseteq LCtx_i]]$
  \end{itemize}
  By induction hypothesis we have
  \begin{itemize}
          \item $[[(UCtx \u UCtx0, DCtx \u LCtx_i \u LCtx0) |- C * (emptyset, LCtx_o)]]$
          \item $[[LCtx_o \subseteq LCtx_i \u LCtx0]]$
  \end{itemize}
  Then we know that
  $[[{(emptyset, LCtx_i)}]] = [[{(emptyset, LCtx_o) * (emptyset, LCtx_i')}]]$ for
  some $[[{LCtx_i'}]]$.
  Then by \cref{lem:inversion} we know that $[[(UCtx \u UCtx0, DCtx \u
  LCtx_i' \u LCtx0) |- C]]$ and by
  \rref*{C-Impl} we have $[[(UCtx, LCtx_i') |- 1.((UCtx0, LCtx0) => C)]]$.
  Finally, by \rref*{C-Tensor} we conclude that $[[(UCtx, LCtx_i) |- 1.((UCtx0, LCtx0) => C) * (emptyset, LCtx_o)]]$
  \item[\rref*{S-ImplMany}] We have
  \begin{itemize}
          \item $[[UCtx ; DCtx ; LCtx_i |-s omega.((UCtx0, LCtx0) => C) ~> LCtx_i]]$
          \item $[[UCtx \u UCtx0 ; LCtx0 \n Dup ; LCtx0 \m Dup |-s C ~> emptyset]]$
  \end{itemize}
  By induction hypothesis we have
  \begin{itemize}
          \item $[[(UCtx \u UCtx0, LCtx0) |- C]]$
  \end{itemize}
  Then by
  \rref*{C-Impl} $[[(UCtx, emptyset) |- omega.((UCtx0, LCtx0) => C)]]$ and finally by
  \rref{C-Tensor} we have $[[(UCtx, LCtx_i) |- omega.((UCtx0, LCtx0) => C) * (emptyset, LCtx_i)]]$.
  $[[LCtx_i \subseteq LCtx_i]]$ holds trivially.
  \end{description}
\end{proof}

\begin{lemma}[Weakening of wanteds]\label{lem:wanteds:weakening}
  If $[[Q |- C]]$, then $[[omega.Q'*Q |- C]]$
\end{lemma}
\begin{proof}
  This is proved by a straightforward induction on the derivation of
  $[[Q |- C]]$, using the corresponding property on the
  simple-constraint entailment relation from
  \cref{def:entailment-relation}, for the \rref*{C-Dom} case.
\end{proof}

\begin{lemma}\label{lem:wanteds:module-action}
  The following equality holds: $[[{pi.(rho.C)}]]=[[{(pi.rho).C}]]$.
\end{lemma}
\begin{proof}
  This is proved by a straightforward induction on the structure of
  $[[{C}]]$, using \cref{lem:simples:monoid-action} for the case
  $[[{C}]]=[[{Q}]]$.
\end{proof}
\end{document}

% Local Variables:
% ispell-dictionary: "british"
% End:


% LocalWords:  sequent typechecker idempotence polymorphism desugar subarray
% LocalWords:  desugaring ghc OutsideIn quotiented gadt typeable disjunction
% LocalWords:  combinator sigils equalities wanteds intuitionistic
% LocalWords:  sequents implicational deallocate deallocating monadic
% LocalWords:  deallocated instantiations desugars unioned
% LocalWords:  deterministically unrestrictedly subexponentials
