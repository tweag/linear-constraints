% -*- latex -*-

%if style == newcode
module LinearConstraints where

\begin{code}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE ConstraintKinds #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeOperators #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE MultiParamTypeClasses #-}

import Data.Kind (Constraint)
--import GHC.IO.Unsafe
import GHC.Base
\end{code}
%endif

\documentclass[acmsmall,review,natbib=false]{acmart}

\usepackage[backend=biber,citestyle=authoryear,style=alphabetic]{biblatex}
\bibliography{bibliography}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
  }
\usepackage[plain]{fancyref}
\usepackage{mathpartir}
\usepackage{newunicodechar}
\input{newunicodedefs}

%%%%%%%%%%%%%%%%% ott %%%%%%%%%%%%%%%%%

\usepackage[supertabular,implicitLineBreakHack]{ottalt}
\inputott{ott.tex}

%%%%%%%%%%%%%%%%% /ott %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% Workaround %%%%%%%%%%%%%%%%%

% This should be handled by the acmclass article, there are a couple
% of issues about
% this. https://github.com/borisveytsman/acmart/issues/271,
% https://github.com/borisveytsman/acmart/issues/327 . Both have been
% merged long ago, and the version of acmart in the shell.nix is from
% 2020.

%% \usepackage{fontspec}
%% \setmainfont{Linux Libertine O}
%% \setsansfont{Linux Biolinum O}
%% \setmonofont{inconsolata}

%%%%%%%%%%%%%%%%% /Workaround %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% lhs2tex %%%%%%%%%%%%%%%%%

\let\Bbbk\undefined    % see https://github.com/kosmikus/lhs2tex/issues/82
%include polycode.fmt
%if style == poly
%format ->. = "⊸"
%format =>. = "\Lolly"
%format .<= = "\RLolly"
%format IOL = "IO_L"
%format . = "."
%format exists = "\exists"
%format forall = "\forall"
%format pack = "\kpack"
%
%format a1
%format a_n
%format an = a_n
%endif

%%%%%%%%%%%%%%%%% /lhs2tex %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      \setlength{\marginparwidth}{1.2cm} % A size that matches the new PACMPL format
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{{\color{blue}{#1}}}
      \newcommand{\note}[1]{{\color{blue}{\begin{itemize} \item {#1} \end{itemize}}}}
      \newenvironment{alt}{\color{red}}{}

      \newcommandx{\jp}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommandx{\csongor}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=purple,#1]{#2}}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
  \else
  %    \newcommand{\Red}[1]{#1}
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{#1}
      \newcommand{\note}[1]{}
      \newenvironment{alt}{}{}
  %    \renewcommand\todo[2]{}
      \newcommand{\unsure}[2]{}
      \newcommand{\info}[2]{}
      \newcommand{\change}[2]{}
      \newcommand{\inconsistent}[2]{}
      \newcommand{\critical}[2]{}
      \newcommand{\improvement}[1]{}
      \newcommand{\resolved}[2]{}
  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Domain-specific macros %%%%%%%%%%%%%%%%%

  \newcommand{\cscheme}[1]{\mathcal{#1}}
  \newcommand{\aand}{\mathop{\&}}
  \DeclareMathOperator*{\bigaand}{\vcenter{\hbox{\Large\&}}}
  \newcommand{\lollycirc}{\raisebox{-0.2ex}{\scalebox{1.4}{$\circ$}}}
  \newcommand{\Lolly}{\mathop{=\!\!\!{\lollycirc}}}
  \newcommand{\RLolly}{\mathop{\lollycirc\!\!\!=}}
  \newcommand{\rlolly}{\mathop{\reflectbox{$\multimap$}}}
  \newcommand{\subst}[2]{[#1]#2}
  \newcommand{\sby}[2]{#1 ↦ #2}
  \newcommand{\vdashi}{⊢_{\mathsf{i}}}
  \newcommand{\vdashs}{⊢_{\mathsf{s}}}

  % language keywords
  \newcommand{\keyword}[1]{\mathbf{#1}}
  \newcommand{\klet}{\keyword{let}}
  \newcommand{\kcase}{\keyword{case}}
  \newcommand{\kwith}{\keyword{with}}
  \newcommand{\kpack}{\keyword{pack}}
  \newcommand{\kunpack}{\keyword{unpack}}
  \newcommand{\kin}{\keyword{in}}
  \newcommand{\kof}{\keyword{of}}

  % defining grammars
  \newcommand{\bnfeq}{\mathrel{{:}{:}{=}}}
  \newcommand{\bnfor}{\mathrel{\mid}}

%%%%%%%%%%%%%%%%% /Domain-specific macros %%%%%%%%%%%%%%%%%

\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  Paso, Texas USA} 
\acmYear{1997}
\copyrightyear{2016}

\acmPrice{15.00}

\begin{document}

\title{Linear Constraints}

\author{Jean-Philippe Bernardy}
\affiliation{
  \institution{University of Gothenburg}
  \city{Gothenburg}
  \country{Sweden}
}
\email{jean-philippe.bernardy@@gu.se}
\author{Richard Eisenberg}
\affiliation{
  \institution{Tweag}
  \city{Paris}
  \country{France}
}
\email{richard.eisenberg@@tweag.io}
\author{Csongor Kiss}
\affiliation{
  \institution{Imperial College London}
  \city{London}
  \country{United Kingdom}
}
\email{csongor.kiss14@@imperial.ac.uk}
\author{Arnaud Spiwack}
\affiliation{
  \institution{Tweag}
  \city{Paris}
  \country{France}
}
\email{arnaud.spiwack@@tweag.io}

\begin{abstract}
This paper presents \emph{linear constraints}, a language feature that improves
the ergonomics of using linear types by freeing programmers from having to
manually pass around linear resource tokens. The resulting code retains the
safety of the linear version while also keeping the simplicity of the
traditional version. We present a qualified type system with linear constraints,
and a typechecking algorithm. We prove the soundness of the algorithm with
respect to the type system, and show how our changes can be integrated into
|OutsideIn|, GHC's existing constraint solver algorithm.
\end{abstract}

\maketitle

\renewcommand{\shortauthors}{Bernardy, Eisenberg, Kiss, and Spiwack}

\section{Introduction}
\label{sec:introduction}
\info{There  is an Appendix section with unorganised thoughts and
  examples.}

Linear type systems have seen somewhat of a renaissance in recent years in
various mainstream programming communities. Rust's ownership system guarantees
memory safety for systems programmers, Haskell's linear types give functional
programmers safe APIs for low-level mutable data structures, and even
dependently typed programmers can now use linear types with Idris 2.

\csongor{Say something about ergonomics to set up the next part}

The essence of linear types is careful tracking of the usage of resources. To
get a sense of their power, consider the following example from
the Linear Haskell article~\cite{LinearHaskell}\footnote{|IOL| is the linear IO
monad}:
\begin{code}
firstLine :: FilePath -> IOL String
firstLine fp =
  do  {  f <- openFile fp
      ;  (f, Ur xs) <- readLine f
      ;  closeFile f
      ;  return xs }
\end{code}

This simple function opens a file, reads its first line, then closes
it. Linearity ensures that the file handle |f| is consumed at the end.
Forgetting to call |closeFile f| would result in a type error since |f| would
remain unused at the end of the function. Notice that |readLine| consumes the
file handle, and returns a fresh |f| that shadows the previous version, to be
used in further interactions with the file. The line's content is a string
|xs| that is returned in an |Ur| wrapper (pronounced ``unrestricted'') to
signify that it can be used arbitrary many times.

% We see that linear types introduce some noise on the |readLine| line:
% we need to destruct an extra pair, and an extra |Ur| (called
% |Unrestricted| in~\cite{LinearHaskell}), compared to the
% traditional (albeit less safe)\unsure{It only gets worse in larger
%   program. This makes the extra safety afforded by linear types too
%   rarely worth it.}

Compare this function with the traditional non-linear version:
\begin{code}
firstLine :: FilePath -> IO String
firstLine fp =
  do  {  f <- openFile fp
      ;  xs <- readLine f
      ;  closeFile f
      ;  return xs }
\end{code}

This version is less safe, because the type system does not keep track of the
file handle, so the programmer must be careful to do this. But it is also
simpler: apparently, in the linear version, we traded clarity for safety. Since
the file handle is now an expendable resource, the type system must know at all
times where it is being consumed, so the file handle must be passed around
manually, culminating in extra noise. Worse, the larger the program gets, the
more additional bookkeeping this requires.

But reading the non-linear version, it is perfectly clear where the
handle is used, and ultimately, consumed. Could the compiler not figure this out
without extra help?

In this paper, we answer this question affirmatively, and introduce \emph{linear
  constraints}, a feature for tracking implicit arguments linearly.
Whe show how linear constraints can be implemented as an extension of Haskell's
type class mechanism.  This way, resource consumption is tracked without
explicitly having to thread the tokens through the program.
%if True
With this extension, the final version of |firstLine| is almost the same as the
traditional version above, with a few minor modifications:
\begin{code}
firstLine :: FilePath -> IOL String
firstLine fp =
  do  {  pack f <- openFile fp
      ;  pack xs <- readLine f
      ;  closeFile f
      ;  return xs }
\end{code}
The only changes from the unsafe version are that this version runs in the linear IO monad,
and explicit |pack| annotations are used to indicate the variables that require
special treatment.
\unsure{We should decide what to do with |pack|.}
In fact, with the right preamble, even the |pack| annotations can be dropped.
%else
With this extension, the final version
of |firstLine| is exactly the same as the traditional version above,
except that the type |IOL| is used instead of |IO| indicating that this
is working within the linear IO monad.
%endif

\paragraph{Our contributions are as follows}

\begin{itemize}
\item A system of qualified types that allows a constraint assumption
  to be given a multiplicity. Linear assumptions are used precisely
  once in the body of a definition.
\item This system supports examples that have motivated the design of
  several resource-aware systems, such as ownership à la Rust, or
  capabilities in the style of Mezzo~\cite{mezzo-permissions}
  or \textsc{ats}~\cite{AtsLinearViews}; accordingly, our system
  may serve as a way to unify these lines of research.\unsure{Speak of
  the Pony language? On the one hand Pony is a pretty cool piece of
  tech, on the other hand, I don't know enough to say something
  smart about it.}\unsure{Should we speak of typestate here?}
\item A typechecking algorithm, based on a combination
  of~\cite{OutsideIn}
  and~\cite{resource-management-for-ll-proof-search}, that respects
  the multiplicity of assumptions. We prove that this algorithm is
  sound and complete with respect to our type system.\unsure{Can we
    have a concrete completeness result?}
\item Our algorithm additionally desugars expressions in our qualified
  type system into a core language (directly inspired
  by Linear Haskell~\cite{LinearHaskell}) that supports linear functions. We
  prove that the output of desugaring is well-typed in the core
  language.
\end{itemize}

\newpage

\section{Motivation}

The goal of this paper is to introduce linear constraints as a mechanism for
ergonomically using linear types in Haskell.  Of course, in order to appreciate
this work, it helps to understand how linear types work.  In this section, we
will sketch out some of the basics of how linear types work in Haskell, and then
give a number of examples that motivate our extension into linear constraints.

% This extra noise is the consequence of the fact that, as far as a
% linear type system is concerned, |f| is expended after |readLine
% f|. But, of course, we typically want to do more with a file that
% reading just one line of it, so the linear |readLine| is given the type.

\subsection{Linear Types}
\label{sec:linear-types}

\begin{figure}%
  \centering
  \begin{subfigure}{.3\linewidth}%
    \noindent%
\begin{code}
openFile   :: FilePath -> IOL Handle
readLine   :: Handle ⊸ IOL (Handle, String)
closeFile  :: Handle ⊸ IOL ()
\end{code}
\caption{Linear Types}
\label{fig:linear-interface}
  \end{subfigure}
  \hfill
  \begin{subfigure}{.52\linewidth}
\begin{code}
openFile   :: FilePath -> IOL (exists h. Handle h .<= Open h)
readLine   :: Open h =>. Handle h -> IOL (String .<= Open h)
closeFile  :: Open h =>. Handle h -> IOL ()
\end{code}
\caption{Linear Constraints}
\label{fig:constraints-interface}
  \end{subfigure}
\caption{Interfaces for file manipulation}
\end{figure}

Linear Haskell~\cite{LinearHaskell} adds a new type of functions,
dubbed linear functions and written |a ⊸ b|, to Haskell\footnote{The linear function
  type and its notation come from linear
  logic~\cite{girard-linear-logic}, to which the phrase \emph{linear
    types} refers. All the various design of linear typing in the
  literature amount to adding such a linear function type, but details
  can vary wildly. See~\cite[Section 6]{LinearHaskell} for an analysis
  of alternative approaches.}. A linear function consumes its
  argument exactly once, more precisely:

\begin{quote}
\emph{Meaning of the linear arrow}:
|f :: s ⊸ t| guarantees that if |(f u)| is consumed exactly once,
then the argument |u| is consumed exactly once.
\end{quote}
To make sense of this statement we need to know what ``consumed exactly once'' means.
Our definition is based on the type of the value concerned:
\begin{definition}[Consume exactly once]~ \label{def:consume}
\begin{itemize}
\item To consume a value of atomic base type (like |Int| or |Handle|) exactly once, just evaluate it.
\item To consume a function value exactly once, apply it to one argument, and consume its result exactly once.
\item To consume a pair exactly once, pattern-match on it, and consume each component exactly once.
\item In general, to consume a value of an algebraic datatype exactly once, pattern-match on it,
  and consume all its linear components exactly once.
\end{itemize}
\end{definition}
\noindent
This definition is enough to allow programmers to reason about the
typing of their functions.
%
Note that a linear arrow specifies \emph{how the function uses its argument}. It does not
restrict \emph{the arguments to which the function can be applied}.
In particular, a linear function cannot assume that it is given the
unique pointer to its argument.  For example, if |f :: s ⊸ t|, then\
this is fine:
\begin{code}
g :: s -> t
g x = f x
\end{code}
The type of |g| makes no particular guarantees about the way in which it uses |x|;
in particular, |g| can pass that argument to |f|.

The example in the previous section made use of |readLine|, whose type is given in \autoref{fig:linear-interface}.
This appears to return a new file, but really, it returns a new name for
the same file. The trick is that there is only ever one of
these names in scope at any given time, and this one name must be
consumed exactly once. In other words, the name is a linear
variable. It can, therefore, only be consumed by linear
functions. This is why the type of |readLine| is a linear function;
and it is also why it must return a new name for the file: passing the
name to |readLine| consumes the name and we don't want |readLine|
to close the file. Ultimately, we will have to call |closeFile| to
consume the name without creating a new one (remember: we need to consume
the name \emph{exactly} once, not at most once). The type system
ensures that we do so exactly once.

From the perspective of the programmer, this is unwanted boilerplate.
Why do we have to manage a bunch of names to help a compiler count? Surely this
can be handled by the typechecker automatically. And, indeed, compilers with \emph{ad hoc}
specialised logic allow us to write essentially the traditional program but
with the guarantee that if we forget to |closeFile|, then we will
get a type error.
This is most notably the case of the
\textsc{ats}~\cite{AtsLinearViews}, and Mezzo~\cite{mezzo-permissions}
languages.\unsure{Both \textsc{ats} and Mezzo
  are specialised in handling pointers-and-mutations, rather than
  file. So the sentence above is a little bit of a lie. Either
  rephrase to say that we can write programs of \emph{this type}, or
  use an array example instead of a file example. Though I think that
  the file example is a better introduction.}

\unsure{Maybe we want to hammer in the fact that, in Linear Haskell,
  there is no use case natively understood by the compiler. Every
  abstraction is built user-side. \textsc{Ats}'s views are closest to
  what we are doing, though seems to only be geared towards pointers.}
In this article we introduce a generic extension to Linear Haskell,
which lets the typechecker handle the counting


There is a bit of boilerplate left, but it doesn't involve managing
names to please the compiler. This considerably lowers the cost of
using a linear-type based abstraction.\unsure{I'm trying to get at the
  cost/benefit analysis thing and how it matters a lot, but I haven't
  found a convincing way to do so without ranting for a page or so,
  I'll get back to this when the rest of the paper is written and I
  revisit the introduction.}


\subsection{Working With Linear Constraints}
\label{sec:what-it-looks-like}


Consider the Haskell function |show|:
\begin{code}
show :: Show a => a -> String
\end{code}
In addition to the function arrow |->|, common to all functional
programming languages, the type of this function features a fat arrow |=>|.
Everything to the
left of a fat arrow is called a \emph{constraint}. Here |Show a| is a
type-class constraint, but there are other kinds of constraints such
as equality constraints or implicit parameter constraints.

What is crucial, for our purpose, is that constraints are handled implicitly by
the typechecker. That is, if we want to |show| an integer we would write |show
42|, and the typechecker would handle proving that |Show Int| without
intervention from the programmer.
Thus, constraints are a convenient mechanism that allow the compiler
to automatically fill in implicit arguments.

In order to manage linearity implicitly, this article introduces a
linear fat arrow |=>.|, much like Linear Haskell introduced a linear
function arrow |->.|. We dub constraints to the left of a linear fat
arrow \emph{linear constraints}.  \unsure{I'm jumping to
  conclusions a little fast. I need to explain what it entails for a
  constraint to be linear. Then I need to re-read (and
  presumably re-write) the paragraphs below, they will probably flow a
  little bit better once the right principles are firmly established.}

In the introduction we wanted to use linearity to make sure that
once a file is closed it can no longer be used.
That is, we need to track in types
whether the file open or not. We can use a linear constraint |Open f|
to represent that a file is, indeed, open. We can write the type of
|closeFile|:

\begin{code}
closeFile :: Open h =>. Handle h -> IOL ()
\end{code}

There are a few things to notice
\begin{itemize}
\item First, there is this type variable |f| which did not exist in
  previous representation. In the representation of the Linear Haskell
  paper, for instance, |closeFile| had type |closeFile :: File ->. IOL
  ()|. This |f| is a type-level name for the file which we are
  closing.
  Giving a name to function argument is the bread and butter of more
  dependently typed languages such as \textsc{ats}~\cite{ats-lang} or Liquid
  Haskell~\cite{liquid-haskell-abstract-refinement-types}. But Haskell doesn't have such a
  naming mechanism built in, so we have to make argument names
  explicit in types.
\item Second, assuming that we have a single, linear, |Open f|
  available, then after |closeFile| there will not be any |Open f|
  left to use, thus preventing the file from being closed
  twice. This is precisely what we were trying to achieve.
\end{itemize}

This still leaves questions open: where does |f| come from? where does
|Open f| come from? what are the types of |openFile| and |readLine|?
The answers to these three questions rely on the same device: we
introduce a type construction |exists a1 ... an. t .<= Q|, where |Q| is some (linear)
constraint.

The fact that existential quantification generate new type-level names
is a folklore observation. It's used crucially in the interface of the
|ST| monad~\cite{st-monad} and of type-class
reflection~\cite{type-class-reflection} (in both of these cases, existential
quantification is encoded as a rank-2 universal quantification). We
shall use it exactly this way: |openFile| uses an existential
quantifier to generate the type-level name of the file
handle. Existentially quantified types are paired with constraint |Q|
which we understand as being returned by functions. We will freely
omit the |exists a1 ... an.| or |.<= Q| parts when they are
empty. This lets us give the following \textsc{api} to files:


Haskell doesn't have such existential quantification, however each
instance of such existential quantification can be encoded as a
\textsc{gadt}. For instance |exists h. Handle h .<= Open h| can be
implemented as
\unsure{We could use a |Proxy| instead. |Pack :: c a =>. Proxy a -> Pack c|, where |c :: * -> Constraint|}
\begin{code}
data PackHandle where
  Pack :: Open h =>. Handle h -> PackHandle
\end{code}
Therefore, the existential types of this article are really a
convenience for the sake of exposition\unsure{Though, see the
  existential type paper}. Correspondingly, existential types are
introduced by a data constructor, which we write |pack|.

When pattern-matching on a |pack| all the existentially quantified
names are introduced in scope and all the returned constraints are
made available. With all these ingredients we can indeed write
the example given in the introduction.

\unsure {Explain that existentially quantified type always have an
  implicit unrestricted at their core.}

\unsure{Link to a typestate paper + mention how much closer this is
  to the idea of typestate than the pedestrian encoding in regular
  linear types.}

\unsure{Explain why the following is unsound:}
\begin{spec}
openFile  :: FilePath -> IOL (Handle h .<= Open h)
\end{spec}


Another example to consider:
\begin{spec}
readTwoLines path = do
  h0 <- openFile path
  (h1, line1) <- readLine h0
  (h2, line2) <- readLine h1
  close h2
\end{spec}
With linear constraints, API:

The example become (remark: not the do-notation for the |IO| monad):
\begin{spec}
readTwoLines path = do
  h <- openFile path
  line1 <- readLine h
  line2 <- readLine h
  close h
\end{spec}

It looks exactly the same as without linear types. But you still get
an error for double-free and use-after-free usages.








\subsection{Motivating Examples}
\label{sec:examples}

To get a sense of how the features we introduce should behave, let's look at
some simple examples. Treating constraints as expendable resources allows use to
reject certain classes of ill-behaved programs. Thus, the following examples show
the different reasons a program might be rejected.

In what follows, we will be using a class |C| that is consumed by the |useC|
function.
\begin{code}
class C

useC :: C =>. Int
\end{code}
The type of |useC| indicates that it consumes its linear resource |C| exactly once.

\subsubsection{Dithering}

Now consider the following program, which we reject:
\begin{code}
dithering :: C =>. Bool -> Int
dithering x = if x then useC else 10
\end{code}
The problem with |dithering| is that it does not commit properly to how much
resource it requires: the branch where |x| holds will use the resource in |C|
since it evaluates to |useC| whereas the other does not.

\subsubsection{Neglecting}

Now consider the type of the linear version of |const|:
\begin{spec}
const :: a ->. b -> a
\end{spec}
This function uses its first argument linearly, and ignores the second.

One way to improperly use the linear |const| is by neglecting a linear variable:
\begin{code}
neglecting :: C =>. Int
neglecting = const 10 useC
\end{code}
The problem with |neglecting| is that although |useC| is mentioned in this program,
it is never evaluated because |const| does not use its second argument.
The constraint |C| is never consumed so this program ought to be rejected.

The rule is that a linear constraint is only consumed in a linear context. For
example,
\begin{code}
notNeglecting :: C =>. Int
notNeglecting = const useC 10
\end{code}
is accepted, because the |C| constraint is passed on to |useC| which itself
appears as an argument to a linear function (whose result is consumed linearly).

\subsubsection{Overusing}

Finally, consider the following program:
\begin{code}
overusing :: C =>. (Int, Int)
overusing = (useC, useC)
\end{code}
Naturally, this is program is rejected as it uses |C| twice. However, the
following version is accepted:
\begin{code}
notOverusing :: (C, C) =>. (Int, Int)
notOverusing = (useC, useC)
\end{code}
That is, it is possible to have multiple copies of a given constraint. The order
of resolution is non-deterministic, and it is up to the creator of the API to
ensure that the runtime behaviour is confluent irrespective of the order of
constraint resolution.
\unsure{Linear constraints have no runtime payload, or even if they did, they
would not be observable (safely) as dictionary methods use the dictionary in an
unrestricted way.}

\subsection{Linear IO}
\label{sec:linear-io}

The file handling example discussed in Sections~\ref{sec:linear-types}
and~\ref{sec:what-it-looks-like} uses a linear version of the |IO| monad, |IOL|.
There are two main modifications compared to the traditional |IO|. Firstly, the
type of the monadic operations |>>=| and |return| are changed so that they
consume their arguments linearly. In the case of |>>=|, its argument also must
be a linear function:

\begin{code}
(>>=) :: IOL a ->. (a ->. IOL b) ->. IOL b
return :: a ->. IOL a
\end{code}

The reason bind needs to be linear is that, as explained in the previous
section, a linear constraint can only be used in a linear context. For the following
program to typecheck, bind must be linear:
\begin{code}
readTwo ::  Open h =>. Handle h -> IOL ((String, String) .<= Open h)
readTwo h =
  readLine h >>= \case pack xs ->
  readLine h >>= \case pack ys ->
  return (pack (xs, ys))
\end{code}
If it were not linear, the first argument |readLine h| of the first bind would
not be able to consume the |Open h| constraint.

The astute reader will notice that since |>>=|'s function argument is a linear
function, all the values bound must be used exactly once. But our intention is
to treat only the constraints linearly, but use the values in an unrestricted
fashion. To this end, |pack| is actually unrestricted in the value it holds, and
only linear in the constraints. This means that in |readTwo|, we could decide to
read an additional line, but maybe not return the result from the function.

\newpage

\section{A qualified type system}

\unsure{Some transition from example into the technique needed here.}

The description of the type system in this section, as well as the
constraint inference algorithm of Section~\ref{sec:type-inference}, are
strongly inspired by the presentation of
OutsideIn~\cite{OutsideIn}. OutsideIn is a foundation of the type
inference algorithm of \textsc{ghc}, the most popular Haskell
compiler, as such we decided to frame this presentation as an
extension of OutsideIn. We have chosen, for the sake of clarity of the
exposition, to omit details of OutsideIn which do not interact with
linear constraints. We shall point out such simplifications where they
arise.

\subsection{Multiplicities}
\label{sec:multiplicities}

Like in Linear Haskell~\cite{LinearHaskell} we shall make use of a
system of \emph{multiplicities}, which describe how linear functions
can be. Linear Haskell is parametric in the system of
multiplicities. For the sake of this article, however, we will use
only the simplest system of multiplicity: that composed of only
$[[1]]$ (representing linear functions) and $[[omega]]$ (representing
regular Haskell functions).

$$
\begin{array}{lcll}
  [[pi]], [[rho]] & \bnfeq & [[1]] \bnfor [[omega]] & \text{Multiplicities}
\end{array}
$$

We will need to add and multiply constraints. Here are the definitions
of these operations.

$$
\left\{
  \begin{array}{lcl}
    [[pi + rho]] & = & [[omega]]
  \end{array}
\right.
$$

$$
\left\{
  \begin{array}{lcl}
    [[1 . pi]] & = & [[pi]] \\
    [[pi . 1]] & = & [[pi]] \\
    [[omega . omega]] & = & [[omega]]
  \end{array}
\right.
$$

\subsection{Simple constraints}
\label{sec:constraint-domain}

\info{See Fig 3, p14 of OutsideIn\cite{OutsideIn}.}

Like OutsideIn (see~\cite[Section 3.2, in particular Figure
3]{OutsideIn}), we parameterise the entire type system by a constraint
domain\,--\,the $X$ in OutsideIn($X$). This domain is characterised by
a set of \emph{atomic constraints} written $[[q]]$ and an entailment
relation $[[Q1 ||- Q2]]$. These constraints are called \emph{simple
  constraints} to distinguish them from the richer constraints of
Section~\ref{sec:wanteds}. This is also the terminology used in
\textsc{ghc}.

$$
\begin{array}{lcll}
  [[Q]] & \bnfeq & [[pi.q]] \bnfor [[Q1*Q2]] \bnfor [[Empty]] &
                                                                \text{Simple constraints}
\end{array}
$$

The multiplicity in front of atomic constraints is the \emph{scaling
  factor}. It indicates whether the constraint is to be used linearly
($[[1]]$) or without restriction ($[[omega]]$).

Simple constraints are treated completely abstractly by the system; for
inference we will need a domain-specific solver, of which
we only require that it adheres to the interface given in
Section~\ref{sec:constraint-solver}. For instance, in \textsc{ghc},
the domain includes type classes the entailment relation describes
instance resolution.
For the sake of the examples of Section~\ref{sec:examples}, simple constraints need
only be the simplest possible, whereby atomic constraints are treated
as uninterpreted symbols. Being parameterised by the domain therefore
only serves to support the rest of Haskell, or any future extension.

OutsideIn introduces, as part of the constraint domain, a generalised
kind of constraint $\mathcal{Q}$, which include toplevel axioms, such
as type-class instance declarations. Such toplevel axioms
are never linear\,--\,just like how toplevel definitions are never linear in
Linear Haskell~\cite{LinearHaskell}\,--\,as such they don't have
interesting interaction with the rest of the system, and we choose to
omit them for simplicity.

We consider simple constraints equal up to associativity and commutativity of
tensor products, as well as idempotence of the unrestricted
constraints. That is
$$
\begin{array}{rcl}
  [[Q1 * Q2]] & = & [[Q2 * Q1]] \\
  [[(Q1*Q2)*Q3]] & = & [[Q1*(Q2*Q3)]] \\
  [[omega.q * omega.q]] & = & [[omega.q]]
\end{array}
$$

Scaling is extended to all constraints:

$$
\left\{
  \begin{array}{lcl}
    [[pi.(Q1 * Q2)]] & = & [[pi.Q1 * pi.Q2]] \\
    [[pi.(rho. Q)]]  & = & [[(pi.rho) . Q]]
  \end{array}
\right.
$$
\unsure{Rendering}
\unsure{Explain that the commutation of scaling and tensor product is
  an exotic feature of Linear Haskell. It does simplify the
  presentation a bit here.}

Note that $[[1.Q]] = [[Q]]$ and that
$[[omega.Q * omega.Q]] = [[omega.Q]]$.

We will often omit the scaling factor for linear atomic constraints
and write $[[q]]$ for $[[1.q]]$. Note that there is no ambiguity as,
if $[[pi.q]]$ is read as $[[pi.(1.q)]]$, then it does, indeed, equal
$[[pi.q]]$.

The constraint entailment relation must satisfy the following
properties:

\begin{displaymath}
  \begin{array}{l}
    [[Q ||- Q]] \\
    [[Q * Empty ||- Q]] \text{ and } [[Q ||- Q*Empty ]] \\
    \text{if } [[Q1 ||- Q2]] \text{ and } [[Q * Q2 ||- Q3]] \text{ then } [[Q * Q1 ||- Q3]] \\
    \text{if } [[Q ||- Q1 * Q2]] \text{ then there exists } [[Q']] \text{ and } [[Q'']]
    \text{ such that } [[Q]]=[[Q' * Q'']] \text{, } [[Q' ||- Q1]] \text{ and } [[Q'' ||- Q2]] \\
    \text{if } [[Q1 ||- Q1]] \text{ and } [[Q2 ||- Q2]] \text{ then } [[Q1 * Q2 ||- Q1 * Q2]] \\
    \text{if } [[Q ||- rho. q]] \text{ then } [[pi . Q ||- (pi.rho). q]] \\
    \text{if } [[Q ||- (pi.rho) . q]] \text{ then there exists } [[Q']] \text{ such
    that } [[Q]] = [[pi. Q']] \text{ and } [[Q' ||- rho . q]]
  \end{array}
\end{displaymath}

Another difference with OutsideIn is that we don't require the
presence of equality constraints. We come back to the motivation for
this simplification in Section~\ref{sec:constraint-generation}.

\begin{lemma}
  \label{lem:q:promotion}
  If $[[Q1 ||- Q2]]$, then $[[pi.Q1 ||- pi.Q2]]$.
\end{lemma}
\begin{proof}
  By induction on the syntax of $[[Q2]]$:
  \begin{itemize}
  \item If $[[Q2]] = [[rho.q]]$, then $[[pi.Q1 ||- (pi.rho).q]]$ holds by
    hypothesis.
  \item If $[[Q2]] = [[Q2' * Q2'']]$, then, by hypothesis, we know that
    $[[Q1]] = [[Q1' * Q1'']]$ for some $[[Q1']]$ and $[[Q1'']]$, and
    that
    $[[Q1' ||- Q2']]$ and $[[Q1'' ||- Q2'']]$. By induction hypothesis,
    we have
    $[[pi.Q1' ||- pi.Q2']]$ and $[[pi.Q1'' ||- pi.Q2'']]$. From which it
    follows that
    $[[pi.Q1 ||- pi.Q2]]$.
  \end{itemize}
\end{proof}

\begin{lemma}
  \label{lem:q:scaling-inversion}
  If $[[Q1 ||- pi.Q2]]$, then there exists $[[Q1']]$ such that
  $[[Q1]]=[[pi.Q1']]$ and $[[Q1' ||- Q2]]$
\end{lemma}
\begin{proof}
  By induction on the syntax of $[[Q2]]$
  \begin{itemize}
  \item If $[[Q2]] = [[rho.q]]$, then, by hypothesis, there exists
    $[[Q1']]$ such that $[[Q1]]=[[pi.Q1']]$ and $[[Q1' ||- rho.q]]$.
  \item If $[[Q2]] = [[Q2' * Q2'']]$, then, by hypothesis, we know
    that
    $[[Q1]] = [[Q1' * Q1'']]$ for some $[[Q1']]$ and $[[Q1'']]$, and
    that
    $[[Q1' ||- pi.Q2']]$ and $[[Q1'' ||- pi.Q2'']]$ (remember that, by
    definition, $[[pi.Q2]] = [[pi.Q2' * pi.Q2'']]$). By induction hypothesis,
    we have
    constraints $[[Q']]$ and $[[Q'']]$, such that $[[Q1']] =
    [[pi.Q']]$ and $[[Q1'']] = [[pi.Q'']]$, and $[[Q' ||- Q2']]$ and
    $[[Q'' ||- Q2'']]$.
    It follows that $[[Q1]] = [[pi.(Q' * Q'')]]$ and
    $[[Q' * Q'' ||- Q2]]$.
  \end{itemize}
\end{proof}

\newpage

\subsection{Typing rules}
\label{sec:typing-rules}

Like in OutsideIn~\cite[Section 4]{OutsideIn}, the type system (Figure~\ref{fig:declarative:grammar}) is
presented as a \emph{qualified type system} in the style first introduced
by~\cite{QualifiedTypes}. Such a qualified type system introduces a
judgement of the form $[[Q;G |- e : t]]$, where $[[G]]$ is a standard
type context, and $[[Q]]$ is a constraint from the domain of
Section~\ref{sec:constraint-domain}. For the most part $[[Q]]$ behaves
much like with $[[G]]$, which will be instrumental for
desugaring in Section~\ref{sec:desugaring}; the main difference is
that $[[G]]$ is referred to explicitly with variables, whereas $[[Q]]$
is used implicitly in \rref{E-Var}.

\begin{figure}
  \centering
  $$
  \begin{array}{lcll}
    [[a]], [[b]] & \bnfeq & \ldots & \text{Type variables} \\
    [[x]], [[y]] & \bnfeq & \ldots & \text{Expression variables} \\
    [[K]] & \bnfeq & \ldots & \text{Data constructors} \\
    [[s]] & \bnfeq & [[forall as. Q =o t]] & \text{Type schemes} \\
    [[t]], [[u]] & \bnfeq & [[a]] \bnfor [[exists as. t o= Q]] \bnfor [[t1 ->_pi t2]]
                            \bnfor [[T ts]] & \text{Types} \\
    [[G]], [[D]] & \bnfeq & [[empty]] \bnfor [[G, x:_pi s]] &
                                                              \text{Contexts} \\
    [[e]] & \bnfeq & [[x]] \bnfor [[K]] \bnfor [[\x. e]] \bnfor [[e1
                     e2]] \bnfor [[pack e]] & \text{Expressions}\\
                 &\bnfor & [[unpack x=e1 in
                     e2]] \bnfor [[case e of { alts }]] &\\
                 &\bnfor & [[let
                     x=e1 in e2]] \bnfor [[let x : s = e1 in e2]] &
  \end{array}
  $$
  \caption{Grammar of the qualified type system}
  \label{fig:declarative:grammar}
\end{figure}

\unsure{Todo: explain what $[[x :_1 forall as. Q =o u \in G]]$ means}
\unsure{Explain what summing contexts means}
%
\jp{It's very important to explain in detail that linear constraints
  (as linear values) can never escape to omega contexts.
}

%
\info{See Fig 10, p25 of OutsideIn\cite{OutsideIn}.}

See Figure~\ref{fig:typing-rules}.\unsure{I [Arnaud] think that either
  the subsumption should be removed from the Var rule (using the Sub
  rule explicitly when needed), or, I should remove the Sub rule and
  use subsumption wherever relevant (in particular the Pack
  rule). Let's revisit this when the proofs are done.}

Main differences:
\begin{itemize}
\item Linearity as in the Linear Haskell paper
\item $\kcase$ doesn't have \textsc{gadt}s
\item Existential packs are our only \textsc{gadt}. They have a single
  constructor, pattern-matched over by $\kunpack$.

  (Consequently, we encode linear constraints inside data types as
  existential pack type.)\unsure{We may need a comment on the fact
    that $\kunpack$ doesn't have a $\pi$ index. There would be nothing
    wrong with it, I imagine, it's just a little bit useless.}
\item Explicit subsumption rule \rref*{E-Sub}
\end{itemize}
\improvement{We also want let with a signature. For the sake of completeness}

\begin{figure}
  \centering
  \drules[E]{$[[Q;G |- e : t]]$}{Expression
    typing}{Var,Abs,App,Pack,Unpack,Let,LetSig,Case,Sub}
  \caption{Qualified type system}
  \label{fig:typing-rules}
\end{figure}

\info{No substitution on $[[Q1]]$ in the $\kunpack$ rule, because there is
  only existential quantification.}


\newpage

\section{Constraint inference}
\label{sec:type-inference}

\unsure{Todo: transition}

\subsection{Wanted constraints}
\label{sec:wanteds}

The constraint generated in Section~\ref{sec:constraint-generation}
have a richer logical structure than the simple constraints. Let us
follow \textsc{ghc}'s terminology and call these \emph{wanted
  constraints}: these are constraints which we \emph{want} to hold.

$$
\begin{array}{lcll}
  [[C]] & \bnfeq & [[Q]] \bnfor [[C1*C2]] \bnfor [[C1&C2]] \bnfor [[pi.(Q=>C)]]&
                                                                \text{Wanted constraints}
\end{array}
$$

\unsure{explanation about the scaling factor on implication constraints?}
\drules[C]{$[[Q |- C]]$}
  {Generalised constraint entailment}
  {Dom,Tensor,With,Impl}

Scaling is extended to all wanted constraints:

$$
\left\{
  \begin{array}{lcl}
    [[pi.(C1 * C2)]] & = & [[pi.C1 * pi.C2]] \\
    [[omega.(C1 & C2)]] & = & [[omega.C1 * omega.C2]] \\
    [[1.(C1 & C2)]] & = & [[C1 & C2]] \\
    [[pi.(rho.(Q => C))]] & = & [[(pi.rho).(Q => C)]]
  \end{array}
\right.
$$

Like in Section~\ref{sec:constraint-domain}, we will typically drop
the scaling factor for implication when it is $[[1]]$ and write $[[Q
=> C]]$ for $[[1.(Q=>C)]]$.

\begin{lemma}
  \label{lem:inversion}
  \begin{itemize}
  \item If $[[Q |- C1*C2]]$, then there exists $[[Q1]]$ and
    $[[Q2]]$ such that
    \begin{itemize}
    \item $[[Q1 |- C1]]$
    \item $[[Q2 |- C2]]$
    \item $[[Q]] = [[Q1 * Q2]]$
    \end{itemize}
  \item If $[[Q |- C1 & C2]]$, then $[[Q |- C1]]$ and $[[Q |- C2]]$.
  \item If $[[Q |- pi.(Q2 => C)]]$, then there exists $[[Q1]]$ such
    that
    \begin{itemize}
    \item $[[Q1 * Q2 |- C]]$
    \item $[[Q]] = [[pi.Q1]]$
    \end{itemize}
  \end{itemize}
\end{lemma}
\begin{proof}
  The cases $[[Q |- C1 & C2]]$ and $[[Q |- pi.(Q2 => C)]]$ are
  immediate, since there is only one rule (\rref*{C-With} and
  \rref*{C-Impl} respectively) which can have them as their
  conclusion.

  For $[[Q |- C1 * C2]]$ we have two cases:
  \begin{itemize}
  \item either it is the conclusion of a \rref*{C-Tensor} rule, and
    the result is immediate.
  \item or it is the result of a \rref*{C-Dom} rule, in which case we
    have $[[C1]]=[[Q1]]$, $[[C2]]=[[Q2]]$, and the result follows from
    the definition of the entailment relation.
  \end{itemize}

  This proof may look very fragile. After all in a system with
  quantified constraints~\cite{quantified-constraints}, such as the
  current implementation of \textsc{ghc}, there are rules with
  non-atomic conclusions which do not introduce a connective.

  Proofs where each non-atomic goal is the conclusion of a
  corresponding introduction rule has been called \emph{uniform}
  in~\cite{hh-ll}. They prove for a fragment of linear logic which
  includes quantified constraints and linear generalisations thereof,
  that all provable sequent can be proved by a uniform proof. So this
  lemma, is, in fact, quite robust.
\end{proof}

\begin{lemma}
  \label{lem:wanted:promote}
  If $[[Q |- C]]$, then $[[pi.Q |- pi.C]]$
\end{lemma}
\begin{proof}
  By induction on the syntax of $[[C]]$
  \begin{itemize}
  \item If $[[C]]=[[Q]]$, then the result follows
    from Lemma~\ref{lem:q:promotion}
  \item If $[[C]]=[[C1*C2]]$, then we can prove the result like we
    proved the corresponding case in Lemma~\ref{lem:q:promotion},
    using Lemma~\ref{lem:inversion}.
  \item If $[[C]]=[[C1&C2]]$, then we the case where $[[pi]]=[[1]]$ is
    immediate, so we can assume without loss of generality that
    $[[pi]]=[[omega]]$, and, therefore, that $[[pi.C]] = [[pi.C1 *
    pi.C2]]$.
    By Lemma~\ref{lem:inversion}, we have that $[[Q|-C1]]$ and
    $[[Q|-C2]]$; hence, by induction, $[[omega.Q |- omega.C1]]$ and
    $[[omega.Q |- omega.C1]]$.
    Then, by definition of the entailment relation, we have $[[omega.Q
    * omega.Q |- omega.C1 * omega.C2]]$, which concludes,
    since $[[omega.Q]] = [[omega.Q * omega.Q]]$.
  \item If $[[C]]=[[rho.(Q1 => C)]]$, then by
    Lemma~\ref{lem:inversion}, there is a $[[Q']]$ such that
    $[[Q]]=[[pi.Q']]$ and $[[Q'*Q1 |- C]]$. Applying
    rule~\rref*{C-Impl} with $[[pi.rho]]$, we get
    $[[(pi.rho).Q' |- (pi.rho).(Q1 => C)]]$.

    In other words: $[[pi.Q |- pi.(rho.(Q=>C))]]$ as expected.
  \end{itemize}
\end{proof}

\begin{lemma}
  \label{lem:wanted:demote}
  If $[[Q |- pi.C]]$ then there exists $[[Q']]$ such that
  \begin{itemize}
  \item $[[Q' |- C]]$
  \item $[[Q]] = [[pi.Q']]$
  \end{itemize}
\end{lemma}

\newpage


\subsection{Constraint generation}
\label{sec:constraint-generation}

See Fig.13, p39 of OutsideIn~\cite{OutsideIn} \unsure{Todo: syntax to
  select the $\pi$ in case and let rules}

The main workhorse of GHC's typechecker is its constraints solver, based on the
OutsedIn~\cite{OutsideIn} algorithm. In order to support the wide range of
features modern Haskell boasts, the constraint solver is responsible not only
for type class constraint resolution, but also for type inference in the more
traditional sense. That is, the constraint solver deals with equality
constraints and does unification. Doing so allows seamless integration of e.g.
GADTs with their local equality assumptions and type families with their
top-level equality axioms.

Our current focus is much more narrow than a general typechecking algorithm for
all of GHC's features. Firstly, our system doesn't have equality
constraints, and even when integrated into GHC, we do not allow equality
constraints to be assumed linearly. This is because traditional unification
algorithms are unsound for linear equalities as they will gladly reuse the same
equality many times (or none at all). (For a system that takes linear equality
seriously, see e.g.~\cite{shulman2018linear})
Secondly, we do not support multiplicity polymorphism in constraint arrows. That
is, the multiplicity of a constraint is always known to be either linear or
unrestricted in the empty context. This way, no equality constraints can interfere
with constraint resolution.

As a consequence of these two restrictions (no linear equalities and no
multiplicity polymorphic constraints), type inference and (linear) class
constraint resolution are completely orthogonal. Therefore, the syntax-directed
constraint generation system presented in this section can legitimately assume
that type inference is solved elsewhere, greatly simplifying the presentation.

\unsure{Todo: the rule for a constraint-generalising signatureless
  let}
\improvement{We also want let with a signature. There are two rules in
  OutsideIn: when the signature is monomorphic, and when it's
  polymorphic. Maybe we don't care about this distinction all that
  much.}
\unsure{The case rule, for an empty case, implies the existence of the
  typically annoying $⊤$. We will have to confront this.}
\unsure{We probably want the freshness condition on the $\kunpack$
  rule, though these variables are universal variables, not
  existentials.}
\info{Not caring about inferences simplifies $\kpack$ quite a bit, we
  are using the pseudo-inferred type to generate constraint. In a real
  system, we would need $\kpack$ to know its type (\emph{e.g.} using
  bidirectional type checking).}
\drules[G]{$[[G |-> e : t ~> C]]$}{Constraint generation}{Var, Abs,
  App, Case, Unpack, Pack, Let, LetSig}

\newpage

\subsubsection{Soundness of constraint generation}
\label{sec:constraint-generation-soundness}

Let us now prove that every term whose generated wanted constraints
are solvable can indeed be typed in the declarative type system.

\begin{lemma}
  For all $[[Q_g]]$ if
  \begin{itemize}
  \item $[[G |-> e : t ~> C]]$
  \item $[[Q_g |- C]]$
  \end{itemize}
  then
  $[[Q_g; G |- e : t]]$
\end{lemma}
\begin{proof}
  By induction on $[[G |-> e : t ~> C]]$
  \begin{description}
  \item[Var] We have
    \begin{itemize}
    \item $[[x :_1 forall as. Q =o u \in G]]$
    \item $[[G |-> x : u[ts/as] ~> Q[ts/as] ]]$
    \item $[[Q_g |- Q[ts/as] ]]$
    \end{itemize}
    Therefore, by rule~\rref*{E-Var}\unsure{and E-Sub if we
      remove subsumption from the Var rule}, it follows
    immediately that $[[Q_g ; G |- x : u[ts/as] ]]$
  \item[Abs] We have
    \begin{itemize}
    \item $[[G |-> \x. e : t0 ->_pi t ~> C]]$
    \item $[[Q_g |- C]]$
    \item $[[G, x:_pi t0 |-> e : t ~> C]]$
    \end{itemize}
    By induction hypothesis we have
    \begin{itemize}
    \item $[[Q_g; G, x:_pi t0 |- e : t]]$
    \end{itemize}
    From which follows that $[[Q_g; G |- \x. e : t0 ->_pi t]]$.
  \item[Let] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> let x = e1 in e2 : t ~> pi.C1 * C2]]$
    \item $[[Q_g |- pi.C1 * C2]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \item $[[G1 |-> e1 : t1 ~> C1]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q1]]$ and $[[Q_2]]$ such that
    \begin{itemize}
    \item $[[Q_1 |- C1]]$
    \item $[[Q_2 |- C2]]$
    \item $[[Q_g]] = [[pi.Q_1 * Q_2]]$
    \end{itemize}
    By induction hypothesis we have
    \begin{itemize}
    \item $[[Q_1 ; G1 |- e1 : t1]]$
    \item $[[Q_2; G2, x:_pi  t1 |- e1 : t1]]$
    \end{itemize}
    From which follows that $[[Q_g; pi.G1+G2 |- let x = e1 in e2 :
    t]]$.
  \item[LetSig] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> let x : forall as. Q =o t1 = e1 in e2 : t ~>
      C2 * pi.(Q => C1)]]$
    \item $[[Q_g |- C2 * pi.(Q => C1)]]$
    \item $[[G1 |-> e1 : t1 ~> C1]]$
    \item $[[G2, x:_pi forall as. Q =o t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q1]]$, $[[Q2]]$ such
    that
    \begin{itemize}
    \item $[[Q2 |- C2]]$
    \item $[[Q1*Q |- C]]$
    \item $[[Q_g]] = [[pi.Q1*Q2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q1*Q;G1 |- e1 : t1]]$
    \item $[[Q2; G2, x:_pi forall as. Q =o t1 |- e2 : t]]$
    \end{itemize}
    Hence $[[Q_g; pi.G1+G2 |- let x : forall as. Q =o t1 = e1 in e2 : t]]$
  \item[App] \info{Most of the linearity problems are in the App
      rule. Unpack is also relevant.}
    We have
    \begin{itemize}
    \item $[[G1+pi.G2 |-> e1 e2 : t ~> C1 * pi.C2]]$
    \item $[[Q_g |- C1 * pi.C2]]$
    \item $[[G1 |-> e1 : t2 ->_pi t ~> C1]]$
    \item $[[G2 |-> e2 : t2 ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q1]]$, $[[Q2]]$ such that
    \begin{itemize}
    \item $[[Q1 |- C1]]$
    \item $[[Q2 |- C2]]$
    \item $[[Q_g]] = [[Q1 * pi.Q2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q1; G1 |- e1 : t2 ->_pi t]]$
    \item $[[Q2; G2 |- e2 : t2]]$
    \end{itemize}
    Hence $[[Q_g; G1+pi.G2 |- e1 e2 : t]]$.
  \item[Pack] We have
    \begin{itemize}
    \item $[[omega.G |-> pack e : exists as. t o= Q ~> omega.C * Q[ts/as] ]]$
    \item $[[Q_g |- C * Q[us/as] ]]$
    \item $[[G |-> e : t[us/as] ~> C]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q_1]]$, $[[Q_2]]$
    such that
    \begin{itemize}
    \item $[[Q_1 |- C]]$
    \item $[[Q_2 |- Q[us/as] ]]$
    \item $[[Q_g]] = [[omega.Q_1*Q_2]]$
    \end{itemize}
    Bu induction hypothesis
    \begin{itemize}
    \item $[[Q_1 ; G |- e : t[us/as] ]]$
    \end{itemize}
    So we have $[[Q_1 * Q[us/as] ; omega.G |- pack e : exists as. t o=
    Q]]$. By rule~\rref*{E-Sub}, we conclude
    $[[Q_g ; omega.G |- pack e : exists as. t o= Q]]$.
  \item[Unpack] We have
    \begin{itemize}
    \item $[[G1+G2 |-> unpack x = e1 in e2 : t ~> C1 * Q' => C2]]$
    \item $[[Q_g |- C1 * Q' => C2]]$
    \item $[[G1 |-> e1 : exists as. t1 o= Q' ~> C1]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q_1]]$, $[[Q_2]]$
    such that
    \begin{itemize}
    \item $[[Q_1 |- C1]]$
    \item $[[Q_2 * Q' |- C2]]$
    \item $[[Q_g]] = [[Q1 * Q2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q_1; G1 |- e1 : exists as. t1 o= Q']]$
    \item $[[Q_2*Q ; G2 |- e2 : t]]$
    \end{itemize}
    Therefore $[[Q_g ; G1 + G2 |- unpack x = e1 in e2 : t]]$.
  \item[Case] We have
    \begin{itemize}
    \item $[[pi.G + D |-> case e of {alts} : t ~> pi.C * && Ci]]$
    \item $[[Q_g |- pi.C * && Ci]]$
    \item $[[G |-> e : T ss ~> C]]$
    \item For each $i$, $[[D, <xi:_(pi.pii) ui[ss/as]> |-> ei : t ~> Ci]]$
    \end{itemize}
    By repeated uses of Lemma~\ref{lem:inversion}, there exist
    $[[Q]]$, $[[Q']]$ such that
    \begin{itemize}
    \item $[[Q |- C]]$
    \item For each $i$, $[[Q' |- Ci]]$
    \item $[[Q_g]] = [[pi.Q * Q']]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q; G |- e : T ss]]$
    \item For each $i$, $[[Q';D, <xi:_(pi.pii) ui[ss/as]> |- ei : t]]$
    \end{itemize}
    Therefore $[[Q_g ; pi.G + D |- case e of {alts} : t]]$.
  \end{description}
\end{proof}

\newpage

\subsection{Constraint solver}
\label{sec:constraint-solver}

Haskell's constraint language can be thought of as a logic programming language.
Type classes encode predicates and type class instances add clauses to the
predicates. These predicates arise from user programs, and the constraint solver
attempts to solve them. At its essence, OutsideIn's constraint solver is a
procedure that takes a set of \emph{given} constraints (the logical
assumptions), and generates a proof of some \emph{wanted} constraint using the
\emph{given}s.

Adding linearity requires treating constraints as consumable resources, and this
points at the key change we need to make to OutsideIn's solver judgement. In
addition to returning a set of unsolved constraints, our solver returns a set of
\emph{output} constraints: these are the constraints that were not consumed in
the solution of the wanted, and can be thought of as the output set of
constraints. The solver judgement thus takes the following form:

$[[Q_g |-s C ~> Q_o]]$

\csongor{Gah. It will be more convenient to track the linear context separately
from the unrestricted context. That, or I define a function on contexts that
removes an element, and do cases on the multiplicities (actually this is how the
implementation works). But it would be cleaner to simply have two contexts. I'm not sure
how to convince ott that this is a good idea. Will try again tomorrow.}

There are three simplifications compared to OutsideIn's solver. Firstly, as
explained in Section~\ref{sec:constraint-generation}, our solver does not need
to do unification, so we do not return a substitution in the solver judgement.
Secondly, we do not handle top-level assumptions, as the meaning of a linear
constraint in the global set of givens is unclear.  Finally, in case the wanteds
can not be solved completely, OutsideIn also returns a set of \emph{residual}
constraints: these are the remaining subproblems to solve. This set of residual
constraints is simply quantified over in the type of top-level function
definitions that don't have signatures. The residuals are essentially all of the
wanteds that arise from the program that couldn't be solved from the global
givens. In our solver we omit these residual constraints, because we do not do
inference and assume that all top-level functions will have signatures. Even if
we did do inference, since there are no global linear constraints, the residual
set would be identical to the wanted (modulo rewriting rules from the constraint
domain).

It is important to reiterate this distinction: OutsideIn's residual constraints
are the ones that remain to be solved from the goal, while our output
constraints here are the ones that have not been consumed during solving.

\begin{definition}
\label{def:solver-soundness}
$[[Q_o]]$ is a sound solution for $[[C]]$ under some given
constraint $[[Q_g]]$ when $[[Q_g  |- C * Q_o]]$.
\end{definition}
Note that $[[Q_o]]⊆[[Q_g]]$ is not necessarily true as the entailment relation
$[[||-]]$ of the constraint domain potentially admits additional rewriting rules
that the solver uses to transform constraints as it proceeds (which is indeed
the case with e.g. type families).

A major simplifying design feature of OutsideIn compared to more general proof
search algorithms is that it always produces a \emph{guess-free} solution, which
amounts to not doing backtracking during search.  \unsure{refer to
ambiguity section, which I'm about to write.}

Following this exposition of the constraint language, we use a linear proof
search algorithm based on the recipe given
by~\textcite{resource-management-for-ll-proof-search}.  This recipe is phrased
in a way which implies goal oriented proof search, but it can be adapted
\emph{mutatis mutandis} to GHC's backtrackingless rewrite-based search.

% \info{The first presentation of returning output context that I could
%   find is~\cite{hh-ll}, but I
%   find~\cite{resource-management-for-ll-proof-search} more
%   informative.}

The key points are
\begin{itemize}
\item Each rule returns the remaining, unused (linear) hypotheses: the
  \emph{leftovers}.
\item To deal with $⊤$, remember that you've encountered a $⊤$ in a
  different branch. And let you spend any leftover back into a
  previous $⊤$
\item In~\cite{resource-management-for-ll-proof-search}, there is a
  third input context ($Ξ$), which represents a context which needs to be used,
  and cannot be returned as leftovers. However, this is used to fail earlier in
  backtracking branches that are doomed to fail. This does not apply to our
  setting since we have no backtracking.\unsure{[Arnaud]: I think.}
\end{itemize}

\begin{figure}
  \centering
  \drules[S]{$[[Q_g |-s C_w ~> Q_o ]]$}{Constraint solving typing}{Mult, Add}
  \caption{Constraint solver}
  \label{fig:constraint-solver}
\end{figure}

% We can do pretty much like in OutsideIn: split the constraint between
% simple constraints and non-simple wanted constraints if we wish (but, this time,
% non-simple constraint include $\aand$! so there will be significantly
% more of them). Apply synchronous rules on non-simple constraints to retrieve simple
% constraints, call the simplifier on them.

% To be honest, we can even do one atomic constraint at a time, given
% that we have no equality, hence our wanted can't interact (I [Arnaud]
% think) but the details don't matter terribly.

\newpage

\section{Desugaring}
\label{sec:desugaring}

\info{
  On unicity of tokens:

  A constraint like ``Open'' (no argument), does not make much sense
  to use as a linear constraint. Because if we can make it once, then
  we can make it omega times, and it's useless (it's similar to linear
  constants in linear haskell. They were not supported.)

  So, we're using something like ``Open f'' instead. Together with a
  an existential variable f. Then the API can ensure that there is a
  single token for this constraint at any given point. The API can
  however create several copies --- but then it's up to the API to
  make sure that the order of picking the constraints is
  computationally irrelevant. (Label constraints as computationally
  relevant? Then GHC could issue errors if there is computational
  relevance and it ends up making a choice.)

  [arnaud] maybe reject all programs which force the constraint solver
  to make an ordering choice
  
  [jp] still worried about the order of treating arguments: if we have
  writeFile f x >> writeFile f y then the arguments of could be
  handled in any order (for constraints!), and it's a shame to reject
  this.

  [arnaud] I don't think so, because in this case, writeFile f y is
  forced to use the most nested evidence, which is that given by
  writeFile f x
  
}

The semantics of our language is given by desugaring it into
a simpler core language: a mild variant of the $λ^q$
calculus from the Linear Haskell article~\cite{LinearHaskell}.

\subsection{The core calculus}
\label{sec:core-calculus}

Our Core calculus is described in Figure~\ref{fig:core-grammar}
(grammar) and Figure~\ref{fig:core-typing-rules} (typing rules).

\begin{figure}
  \centering
  $$
  \begin{array}{lcll}
    [[a]], [[b]] & \bnfeq & \ldots & \text{Type variables} \\
    [[x]], [[y]] & \bnfeq & \ldots & \text{Expression variables} \\
    [[K]] & \bnfeq & \ldots & \text{Data constructors} \\
    [[s]] & \bnfeq & [[forall as. t]] & \text{Type schemes} \\
    [[t]], [[u]] & \bnfeq & [[a]] \bnfor [[exists as. t o- u]] \bnfor [[t1 ->_pi t2]]
                            \bnfor [[T ts]] & \text{Types} \\
    [[G]], [[D]] & \bnfeq & [[empty]] \bnfor [[G, x:_pi s]] &
                                                              \text{Contexts} \\
    [[e]] & \bnfeq & [[x]] \bnfor [[K]] \bnfor [[\x. e]] \bnfor [[e1
                     e2]] \bnfor [[pack (e1, e2)]] & \text{Expressions}\\
                 &\bnfor & [[unpack (y,x)=e1 in
                           e2]] \bnfor [[case e of { alts }]] &\\
                 &\bnfor & [[let
                           x=e1 in e2]] \bnfor [[let x : s = e1 in e2]] &
  \end{array}
  $$
  \caption{Grammar of the core calculus}
  \label{fig:core-grammar}
\end{figure}

\begin{figure}
  \centering
  \drules[L]{$[[G |- e : t]]$}{Core language
    typing}{Var,Abs,App,Pack,Unpack,Let,Case}
  \caption{Core calculus type system}
  \label{fig:core-typing-rules}
\end{figure}

The differences between Figure~\ref{fig:core-typing-rules} and $λ^q$
from the Linear Haskell article~\cite{LinearHaskell}
are as follows
\begin{itemize}
\item We don't have multiplicity polymorphism.
\item We need, on the other hand, type polymorphism.
\item Polymorphism is implicit rather than explicit. This is not an
  essential difference but it simplifies the presentation.
\item We a $\kpack$ and $\kunpack$ pair of constructions, which
  introduce existentially quantified types. Specifically type of the
  form $[[exists as. t2 o- t1]]$: a pair of an unrestricted $[[t2]]$
  and a linear $[[t1]]$. As the $\kpack$ and $\kunpack$ of
  Section~\ref{sec:typing-rules}, these can be realised in regular
  Haskell as a family of \textsc{gadt}s.
\end{itemize}

In addition, we shall assume the existence of data types
\begin{itemize}
\item $[[t1 * t2]]$ with sole constructor
  $[[ (,) : forall a b. a ->_1 b ->_1 a * b ]]$. We will write $[[(e1,
  e2)]]$ for $[[(,) e1 e2]]$.
\item $[[unit]]$ with sole constructor $[[() : unit]]$.
\item $[[Ur t]]$ with sole constructor $[[ Ur : forall a. a ->_omega
  Ur a]]$
\end{itemize}
\unsure{As I'm writing this I realise that there is no mention that
  data constructors are treated as variables. It should probably be
  somewhere in English, as well as in the definition of
  $[[x :_1 forall as. u \in G]]$}

These are regular data types and constructors of the language, they
are consumed with $\kcase$.

In addition, for the sake of concision, when writing expressions in
the core calculus, we will allow ourselves to write nested
patterns in case expressions. Desugaring nested patterns into atomic
case expression is routine.

\subsection{Inferred constraints}
\label{sec:ds:inferred-constraints}

Using Lemma~\ref{sec:constraint-generation-soundness} together with
Definition~\ref{def:solver-soundness} we know that if
$[[G |-> e : t ~> C]]$ and $[[Q_g |-s C~> Empty ]]$, then
$[[Q_g ; G |- e : t]]$.

It only remains to desugar derivations of $[[Q;G|-e : t]]$ into the
Core Calculus. Let us dedicate the rest of this section to describe
this last step.

\subsection{From qualified to core}
\label{sec:ds:from-qualified-core}

In order to desugar derivations of the qualified system to the core
calculus, we will use the classic technique known as evidence-passing
style\footnote{This technique is also often called dictionary-passing
  style because, in the case of type classes, evidences are
  dictionaries, and because type classes were the original form of
  constraints in Haskell.}

To do so, we shall require some more material from
constraints. Namely, we will assume a type $[[Ev(q)]]$ for each atomic
constraint. It is extended to all simple constraints

$$
\left\{
  \begin{array}{lcl}
    [[Ev(1.q)]] & = & [[Ev(q)]] \\
    [[Ev(omega.q)]] & = & [[Ur (Ev(q))]] \\
    [[Ev(Empty)]] & = & [[unit]] \\
    [[Ev(Q1 * Q2)]] & = & [[Ev(Q1) * Ev(Q2)]]
  \end{array}
\right.
$$

It ought to be noted that $[[Ev(Q)]]$ is not technically well
defined. Indeed Section~\ref{sec:constraint-domain} defines the syntax
as being quotiented by associativity and commutativity of the tensor
product, and idempotence of unrestricted constraints. But core
language data types (or Haskell's for that matter) are not so
quotiented. So for the sake of defining $[[Ev(Q)]]$, we have to assume
that a particular representative of the equivalence classes has been
fixed.

This is a bit imprecise. It's not actually hard to fix the
imprecision: give a name to each atomic constraint, when tensoring two
simple constraints together merge constraints with the same name. Much
like we do for type context. This is actually essentially how
\textsc{gch} deals with constraints today. It is also the mechanism
that our prototype implementation (see
Section~\ref{sec:implementation}) uses. However, we have preferred
keeping this section a little imprecise, in order to save the rest of
the article from the non-trivial extra tedium that the more precise
presentation entails.

Furthermore we shall require that for every $[[Q1]]$ and $[[Q2]]$
such that $[[Q1 ||- Q2]]$, there is a (linear) function
$[[Ev(Q1 ||- Q2) : Ev(Q1) ->_1 Ev(Q2)]]$.

We will need one more device. Namely, we'll need a way to turn every
$[[Ev(omega.Q)]]$ into an $[[Ur(Ev(Q))]]$. For any
$[[e : Ev(omega.Q)]]$, we shall write $[[urify(Q;e) :
Ur(Ev(omega.Q))]]$. As a shorthand, particularly useful in nested
patterns, we will write $[[case e of {urified(Q;x) -> e'}]]$ for
$[[case urify(Q;e) of {Ur x -> e'}]]$.
Let's define $[[e : Ev(omega.Q)]]$:

$$
\left\{
  \begin{array}{lcl}
    [[urify(Empty;e)]]& = & [[case e of {() -> Ur ()}]] \\
    [[urify(1.q;e)]] & = & [[e]] \\
    [[urify(omega.q;e)]] & = & [[case e of {Ur x -> Ur (Ur x)}]] \\
    [[urify(Q1*Q2;e)]] & = & [[case e of {(urified(Q1;x), urified(Q2;y)) -> Ur (x,y)}]]
  \end{array}
\right.
$$

We will often omit the $[[Q]]$ in $[[urify(Q;e)]]$, and write
$[[urify(e)]]$ when it can be easily inferred from the context.

With this we can desugar a type $[[t]]$ of the qualified system into
a type $[[Ds(t)]]$ of the core calculus.\unsure{confusion type vs type
  scheme aka polytype. Probably not a problem, but it should be
  explained somewhere.}

$$
\left\{
  \begin{array}{lcl}
    [[Ds(forall as. Q =o t)]] & = & [[forall as. Ev(Q) ->_1 Ds(t)]] \\
    [[Ds(t1 ->_pi t2)]] & = & [[Ds(t1) ->_pi Ds(t2)]] \\
    [[Ds(exists as. t o= Q)]] & = & [[exists as. Ds(t) o- Ev(Q)]]
  \end{array}
\right.
$$

Let us finally build, given a derivation $[[Q;G |- e : t]]$, an
expression $[[Ds(z;Q;G |- e : t)]]$, such that
$[[G, z:_1 Ev(Q) |- Ds(z;Q;G |- e : t) : Ds(t)]]$ (for a distinguished
variable $[[z]]$).

\unsure{Explain how to read the recursive definition, because it's not
  really obvious}
$$
\left\{
  \begin{array}{lcl}
    [[ Ds(z;Q;G |- x : u[ts/as]) ]] & = & [[ x (Ev(Q ||- Q1[ts/as]) z) ]] \\
    [[ Ds(z;Q;G |- \x.e : t1 ->_pi t2) ]] & = & [[ \x. Ds(z;Q;G,x:_pi t1
                                              |- e : t2) ]] \\
    [[ Ds(z;Q1*Q2; G1+G2 |- e1 e2 : t) ]]
        & = & [[ case z of { (z1, z2) -> Ds(z1;Q1;G1 |- e1 : t1 ->_1 t)
              Ds(z2;Q2;G2 |- e2 : t1) } ]] \\
    [[ Ds(z;Q1*omega.Q2; G1+omega.G2 |- e1 e2 : t) ]]
        & = & [[ case z of { (z1, urified(z2))
              -> Ds(z1;Q1;G1 |- e1 : t1 ->_omega t)
              Ds(z2;Q2;G2 |- e2 : t1) } ]] \\
    [[ Ds(z;omega.Q * Q1[us/as];omega.G |- pack e : exists as. t o=
    Q1)]]
        & = & [[ case z of { (urified(z'), z'')
              -> pack (z'', Ds(z'; Q ; G |- e : t[us/as]))} ]] \\
    [[ Ds(z;Q1 * Q2;G1 + G2 |- unpack x = e1 in e2 : t) ]]
        & = & [[ case z of { (z1, z2) -> unpack (z',x) =
              Ds(z';Q1;G1 |- e1 : exists as. t1 o= Q) in let z2' =
              (z2,z') in Ds(z2';Q2 * Q;G2,x:_omega t1 |- e2 : t)
              } ]] \\
    [[ Ds(z;Q1 * Q2 ;G1+G2 |- let x = e1 in e2 : t) ]]
        & = & [[ case z of { (z1, z2) -> let x = Ds(z1;Q1;G1 |- e1 :
              t1) in Ds(z2;Q2;G2,x:_1 t1 |- e2 : t)} ]] \\
    [[ Ds(z;omega.Q1 * Q2 ;omega.G1+G2 |- let x = e1 in e2 : t) ]]
        & = & [[ case z of { (urified(z1), z2) -> let x = Ds(z1;Q1;G1 |- e1 :
              t1) in Ds(z2;Q2;G2,x:_omega t1 |- e2 : t)} ]] \\
    [[ Ds(z;omega.Q1*Q2;omega.G1+G2 |- case e of { alts } : t) ]]
        & = & [[ case z of { (urified(z1), z2) -> case Ds(z1;Q1;G1 |-
              e : T ts) of { < K xsi -> Ds(z2; Q2; G2, < xi :_(pi.pii)
              ui[ts/as] > |- ei : t)>}} ]] \\
    [[ Ds(z;Q1*Q2;G1+G2 |- case e of { alts } : t) ]]
        & = & [[ case z of { (z1, z2) -> case Ds(z1;Q1;G1 |-
              e : T ts) of { < K xsi -> Ds(z2; Q2; G2, < xi :_(pi.pii)
              ui[ts/as] > |- ei : t)>}} ]] \\
    [[ Ds(z;Q;G |- e : t) ]] & = & [[ let z' = Ev(Q1 ||- Q) z in
                                   Ds(z';Q1;G |- e : t) ]]
  \end{array}
\right.
$$

It is straightforward by induction, to verify that, indeed,
$[[G, z:_1 Ev(Q) |- Ds(z;Q;G |- e : t) : Ds(t)]]$ as
announced.\unsure{a few more closing words would be welcome.}

\newpage

\section{Implementation}
\label{sec:implementation}

We have implemented linear constraints on top of GHC 9.1, a version that already
ships with the LinearTypes extension. Function arrows (|->|) and context arrows
(|=>|) share the same internal representation in the typechecker, differentiated
only by a boolean flag. Thus, the LinearTypes implementation effort has already
laid down the bureaucratic ground work of annotating these arrows with
multiplicity information.

The key changes affect constraint generation and constraint solving. Constraints
are now annotated with a multiplicity, scaled according to the usage environment
from which they arise. With LinearTypes, GHC already does scaling for the usage
of term variables, we simply needed to modify the scaling funcion to capture all
the generated constraints and re-emit a scaled version of them -- a fairly local
change.

Nesting of constraints in GHC is done via implication constraints, which hold a
set of \emph{given} constraints and a set of \emph{wanted} constraints. The
givens can (and for linear constraints, must) be used to solve the wanteds. We
modified implication constraints to hold a set of sets of wanteds, to represent
multiplicative conjuctions ($[[*]]$) and additive conjuctions ($[[&]]$).

When solving $[[C_1 * C_2]]$ (such as for two arguments of a function), the
constraint solver first solves $[[C_1]]$ using all of the givens, and records
the ones that have been used and the ones that haven't. Then the residual givens
are fed into the solution of $[[C_2]]$.  GHC stores the given constraints in a
set (called the \emph{inert} set), which we modified to store a set of lists
instead: for each constraint $[[C]]$ we have a list of givens, in the order they
were bound (which can happen by opening several |Pack| constructors in nested
scopes for example), and the solver uses the most
recent one first.

When solving $[[C_1 & C_2]]$ (such as the two branches of an if expression),
we feed the same givens to both $[[C_1]]$ and $[[C_2]]$, and at the end
check that the residuals agree.

When a given constraint from the inert set is used to solve a particular wanted,
the given is removed from the inerts. In addition, unlike regular constraints,
linear constraints are never solved from top-level givens (like type class
instance declarations).

Finally, we check that each top-level implication constraint can be solved by
consuming all of the linear givens. If any residuals remain, an error is
generated.

This strategy is different from how GHC handles linear values. There, the
compiler first computes the usage count for a particular variable, then decides
to accept or reject if this matches the declaration. Recall the program
from~\ref{sec:examples}:

\begin{code}
overusing' :: Int ->. (Int, Int)
overusing' x = (x, x)
\end{code}

In this case, the usage of |x| is counted to be $[[omega]]$ and the program is
rejected. Linear constraints are not counted in the same way, instead, they are
expended from a set of givens during constraint solving as explained above. The
rationale is that we can accept the following program:

\begin{code}
two :: (C, C) =>. (Int, Int)
two = (useC, useC)
\end{code}

Which has no term-level analogue, since it is not possible to call two variables
the same name and thus have two copies of, say, a variable |x|.

\newpage

\section{Extensions}
\begin{itemize}
\item Like there are implicational and universally-quantified
  constraints in the left-hand side of fat arrows, we may want to have
  $\aand$ constraints on the left hand side of (linear) fat
  arrows. This falls in the Linear Hereditary Harrop fragment
  described, for instance, in~\cite{hh-ll}
  and~\cite{resource-management-for-ll-proof-search}. Hereditary
  Harrop is a natural extension of Horn clauses in proof search
  algorithms.
\end{itemize}

\appendix

\section{Preamble from Csongor}

\begin{spec}
data a .<= c where
  Pack :: c =>. a -> a .<= c
data IOL c a = IOL {runIOL :: RealWorld -> (RealWorld, a .<= c)}
\end{spec}

If we bake the constraint into |IOL|, then we need to change \emph{both} |c| and |a|:
\begin{spec}
(>>=) :: IOL c a -> (c =>. a -> IOL d b) -> IOL d b
io_a >>= f = IOL $ \rw -> case runIOL io_a rw of
                            (rw', Pack a) -> runIOL (f a) rw'
\end{spec}

% $ emacs

\section{Arnaud's motivating examples}

\subsection{Quantum IO Monad}

To showcase another area where deploying linear constraints seems promising, let
us review the quantum computational model. At the fundamental level, the
evolution of a quantum state is \emph{unitary}, which, in essence, means that
information cannot be lost at any point in a quantum circuit. Quantum circuit
gates can thus only express \emph{reversible} operations, and algorithms
operating on quantum machines therefore need to be carefully constructed to only
use reversible operations.

This criterion also poses a challenge to language designers who wish to create
high-level abstractions that can be compiled down to a realisable quantum
circuit, as many common operators, such as the logical OR, are not expressible
in a quantum machine due to their loss of information.

In \cite{altenkirch2010quantum} the authors describe an encoding of quantum
computation in the Quantum IO (QIO) monad, which can effectively simulate
probabilistic quantum operations by sampling a probability distribution. The
framework supplies a DSL, |U|, for reversible computations. This DSL includes,
for example |unot :: Qbit -> U|, which reverses negates a quantum bit (qbit), and |ifQ
:: Qbit -> U -> U| which runs a reversible computation when the supplied quantum
bit is in the true state. Qbits can be initialised using the |mkQbit ::
Bool -> QIO Qbit| operation, and reversible computations can be executed on the
state of the machine using |applyU :: U -> QIO ()|.

These seemingly simple combinators already expose a shortcoming of the API: it
is possible to express irreversible computations: given some |q :: Qbit|, |ifQ q
(unot q)| sets |q|'s value to false. Indeed, the QIO monad enforces a semantic
side condition that the conditional variable must not be modified in the body.
This condition is enforced by the simulator by throwing a runtime error when
such updates are attempted.

A better solution would be to catch the error before even attempting to execute
the program! Using linear constraints, we can provide a safe API for expressing
reversible computations.

The strategy is to modify the QIO API to keep track of having write access to a
qbit. Initialising a qbit provides write access to the qbit.

\begin{code}
mkQbit :: Bool -> exists u. QIO (Qbit q) .<= Write q
\end{code}

Then, we modify |unot| to require write access to the qbit.

\begin{code}
unot :: Write q =>. Qbit q -> U .<= Write q
\end{code}

Finally, |ifQ| consumes write access.

\begin{code}
ifQ :: Write q =>. Qbit q -> U -> U .<= Write q
\end{code}

This way, writing |ifQ q (unot q)| will no longer typecheck, as the call to
|ifQ| has consumed the write access to |q|, thus the body will not be able to
modify it. Of course, it is still possible to write any \emph{other} qbit |r| in the
body, creating an \emph{entagled} pair of qbits: |ifQ q (unot r)|.

\section{Application: memory ownership}

In Haskell, memory deallocation is normally the responsibility of a
garbage collector. However, garbage collection comes with runtime
costs which not all applications can afford: one must then resort to
explict memory allocation and deallocation. However this task is error
prone: one can easily forget a deallocation (causing a memory leak) or
deallocate several times (corrupting data).

With linear constraints, it is possible to use the type system to
enforce correct deallocation of memory.  The approach is to use a
linear constraint to represent \emph{ownership} of a memory location,
i.e. the responsibility to deallocate it. We use a linear constraint
|(Own n)|, such that a program which has an |Own n| contstraint in
context is responsible to deallocate the memory area(s) associated
with a memory locations |n|.  Because of linearity, this constraint
must be discharged exactly once, so it is guaranteed that the memory
is deallocated correctly.

In the above |n| is a type variable (of a special kind |Location|)
which represent a memory location or a set thereof. Locations mediate
the relationship between references and ownership constraints.

In fact, we will be using three linear constraints, one for ownership,
one for reading and one for writing:


> class Read (n :: Location)    -- read capability
> class Write (n :: Location)   -- write capability
> class Own (n :: Location)


Thanks to this extended set of constraints, programs are able to read
or write to a memory reference without necessarily owning it. However,
one cannot be writing unless we also have read access, so that a
reader does not experience changes to a location while it is
reading. This way we can additionally enforce consistency per memory
location. Therefore we will systematically use the |RW| set of
constraints, defined below, instead of |Read|.

> type RW n = (Read n, Write n)

Likewise, one cannot deallocate a location if any part of the program
is keeping a read or write reference to it, so all 3 capabilities are
needed for true ownership. Thus We never use |Own| alone, but |O|,
defined thus:

> type O n = (Read n, Write n, Own n)

With these components in place, we can provide an API for ownable
references.

> data AtomRef (a :: Type) (n :: Location)

The type |AtomRef| is a type of references to a pure type |a| with
location |n|. Allocation of a reference can be done using the
following function.

> newRef :: (forall n. O n =>. AtomRef a n -> Ur b) ⊸ Ur b

The reference available in a continuation, which returns an
unrestricted value.  Indeed, if we would allow returning any type |b|
then the |O n| constraint could be embedded in |b|, and therefore
escape the scope of the continuation. This would become a problematic
because newRef can be used in an unrestricted context, and thus
|newRef| could not be implemented by allocating an explicitly-managed
reference. In contrast with our API no linear constraint can escape
from the scope of the continuation, whose execution is forced at the
point where case analysis of the returned |Ur b| value is done.

To read a reference, a simple |Read| constraint is demanded, and
immediately released. Writing is handled similarly.

> readRef :: (Read n) =>. AtomRef a n -> a .<= Read n
> writeRef :: (RW n) =>. AtomRef a n -> a -> () .<= RW n

Note that the above primitives do not need to explicitly declare
effects in terms of a monad or another higher-order effect-tracking
device: because the |RW n| constraint is linear, passing it suffices
to ensure proper sequencing of effects concerning location |n|.
Deallocation consumes all linear constraints associated with |O n|.

> freeRef :: O n =>. AtomRef a n -> ()

As an alternative to read followed by free, one could transfer control
of the memory location to the garbage collector. This operation is
sometimes called ``freezing'':

> freezeRef :: O n =>. AtomRef a n -> Ur a


Another aspect of our system is that ownership can be relinquished, by
writing a reference in a datastructure owned by some other part of the
program. To illustrate this aspect, we can use arrays of references:
if one puts a reference in an array, the owner of the array becomes
responsible to deallocate this reference together with the array.


> data PArray (a :: Location -> Type) (n :: Location)

We make our the type |PArray a n| polymorphic in the reference type of
elements, |a|. A sublety is that the kind of |a| is |Location ->
Type|. This way we can easily enforce that every reference in the
array refer to the same location |n|. Both types |AtomRef a| and
|PArray a| inhabit this kind, and therefore one can allocate, and
manipulate arrays of arrays with this API.

Allocation of |PArrays| proceeds from the same logic as
that of simple references:

> newPArray    :: (forall n. O n =>. PArray a n -> Ur b) ⊸ Ur b

%% Reading at a given index returns a \emph{reference} to the element in question:

%% > readPArray   :: Read n =>. PArray a n -> Int -> a n .<= Read n

%% It can be noted that the returned reference remains in the same
%% location as the array, |readPArray| needs not be implemented by copy.

As advertised, writing a reference in an array gives up ownership.

> writePArray  :: (RW n, O p) =>. PArray a n -> Int -> a p -> (() .<= RW n)

More precisely, the ownership of the location |p| is absorbed in that
of |n|. Therefore, the associated operational semantics is to move the
reference inside the array (and potentially deallocate the memory
previously pointed to by the old reference at that index.)

Accessing elements of the arrays can be done using the following function):

> lendPArrayElement  :: RW n =>. Parray a n -> Int -> (forall p. RW p =>. a p ⊸ (k .<= RW p)) ⊸ (k .<= RW n)

|lendPArrayElement a i k| Lends read-write access to an element i of
a, to a continuation k. (In Rust terminology, the continuation
``borrows'' an element of the array.). Note that, with this API, |RW
n| and |RW p| are never simultaneously available. This is very
important; indeed the following function, extracting a reference,
could not be implemented soundly:

> extractElementWrong  :: RW n =>. Parray a n -> Int -> (a p .<= (RW n, RW p))

Indeed, when called from a context where the program owns the
allocated array, it can immediately deallocate it, even though the (RW
p) access to the element remains available. For the same reason,
gaining read access to an element needs to be done using a
continuation API as well:

> lendPArrayElementRead  :: Read n =>. Parray a n -> Int -> (forall p. Read p =>. a p ⊸ (k .<= Read p)) ⊸ (k .<= Read n)

For ownership, it is however possible to use a direct API:

> extractElementWrong  :: O n =>. Parray a n -> Int -> (a p .<= (O n, O p))

Here, operationally the element can be overwritten with ``null'', and
so the owner of the array is no longer owning it.


\section{$\klet$ should be generalised}

\unsure{In the current version of the system $\klet$ doesn't
  generalise. We may want to repurpose this argumentation as a
  discussion on possible refinement of the type system for
  convenience.}

The let rule infers a qualified type for the bound variable, by generalising
over all the linear constraints appearing in the bound expression. This is in
stark contrast with OutsideIn's strategy of inferring fully monomorphic types
for let expressions. So why not follow the established tradition and also infer
monomorphic types when linear constraints are involved? Since the let binder is
unrestricted, the variable $x$ may be used multiple times (or none at all). This
means that the let \emph{must not consume any linear constraints}. \change{which
means that if we also add linear lets to the language, then those can consume
linear constraints. But I (Csongor) don't think linear lets will be necessary?}

To illustrate the practical necessity of the let generalisation strategy,
consider the following file handling API:

\begin{code}
newFile :: IO (exists h. Handle h .<= Open h)
writeFile :: Open h =>. File h -> String -> IO (() .<= Open h)
closeFile :: Open h =>. File h -> IO ()
\end{code}

The |newFile| function creates a file and returns a file handle |File f|,
together with a linear constraint witnessing that the file |f| is open (note
that |f| is existentially quantified). |writeFile| writes a string to an open
file and keeps it open. Finally, |closeFile| closes the file and consumes the
|Open f| constraint.

Now consider the following program:

\begin{code}
readBad :: IO ()
readBad = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  return ()
\end{code}

This program creates a new file, writes the string |"hello"| to it, then
returns. Even though the |closeFile file| action is assigned to a variable, the
action itself is never invoked, and the file remains open. The fixed version
follows:

\begin{code}
readGood :: IO ()
readGood = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  x
\end{code}

Here, |x| is actually executed, thus the file is closed before the function
returns. The type of |x| in both cases is |Open f0 =>. IO ()| (with |f0| the
existential variable created by |newFile|). Happily, |readBad| gets rejected
because the |Open f0| constraint doesn't get consumed before the function returns.

Unlike traditional let-generalisation, this behaviour can not be overridden with
a signature, so writing |x :: IO ()| is rejected. \change{We don't have a rule
for let with a signature yet, but it will have to be this way.}

\subsection{Comparison with OutsideIn}

So far we have argued that linear constraints should be quantified over in let
bindings. But how does this fit into the OutsideIn constraint solver, the type
inference framework employed by GHC?  In~\cite{OutsideIn}, the authors carefully
consider various different generalisation strategies, each with different
tradeoffs, before reaching the conclusion that no generalisation is the most
ergonomic option.

Here is a summary of the different criteria:

\begin{description}
  \item[Equalities]
        OutsideIn never generalises over equality constraints. Doing
        so would result in very large constraints, resulting in ergonomic and
        performance penalties. In our system, equality constraints are always
        unrestricted, so the issues around consumption explained above do not
        apply to them. Thus, there is no need to generalise over equality
        constraints in our system.
  \item[Class constraints]
        OutsideIn never generalises over class constraints. A downside of
        generalising is that type errors are delayed to call sites when a
        constraint can not be solved. In the case of linear constraints, this is
        the desired behaviour, since whether the constraint can be solved depends
        on whether it is available at the call site, which might differ from
        whether it is available at the definition site.
  \item[Type variables]
        OutsideIn makes the observation that if a type variable is generalised,
        then so must be all the constraints that mention that variable (otherwise
        principal types are lost). Because constraints are not generalised, the
        algorithm opts to also not generalise type variables. A possibility not
        considered in~\cite{OutsideIn} is generalising only the constraint, but
        not the type variables mentioned in it. This is the path we take: type
        variables are not quantified over, but (linear) constraints are. This is
        a sensible option in our setting because it still allows deferring
        constraint solving to use sites, without deviating too much from GHC's
        existing strategy.
\end{description}

To summarise, the generalisation strategy in let bindings is to always
generalise over linear constraints, but keep type variables monomorphic and never
quantify over nonlinear constraints (which includes all equality constraints).
This is a conservative extension of OutsideIn.

\subsection{Maybe we need to be more careful?}

As I (Csongor) wrote the above example, I realised that the example API might
not be sufficient. For example,

\begin{code}
readBad2 = do
  file <- newFile
  writeFile file "hello"
  const (return ()) (closeFile file)
\end{code}

here the file handle is not closed, but according to the App rule, the |Open f0|
constrant is consumed by the application to |const|. The issue here is that we
want to actually ensure that |closeFile| gets \emph{executed}, so maybe a better
interface would be

\begin{code}
newFile :: IO (exists h. Handle h .<= Open h)
writeFile :: Handle h -> String -> IO (Open h =>. () .<= Open h)
closeFile :: Handle h -> IO (Open h =>. ())
\end{code}

is there any other way to fix it? Maybe a linear constraint is only consumed in
an application to a linear function?\info{Arnaud: yes! consuming a
  linear constraints in a non-linear operation should be a type error,
  otherwise linear constraints would be unsound.}

\newpage


\printbibliography

\end{document}

% LocalWords:  sequent typechecker idempotence polymorphism desugar
% LocalWords:  desugaring ghc OutsideIn toplevel quotiented
