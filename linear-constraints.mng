% -*- latex -*-

%if style == newcode
module LinearConstraints where

\begin{code}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE ConstraintKinds #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeOperators #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE MultiParamTypeClasses #-}

import Data.Kind (Constraint)
--import GHC.IO.Unsafe
import GHC.Base
\end{code}
%endif

\documentclass[acmsmall,review,natbib=false]{acmart}

\usepackage[backend=biber,citestyle=authoryear,style=alphabetic]{biblatex}
\bibliography{bibliography}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
  }
\usepackage[plain]{fancyref}
\usepackage{mathpartir}
\usepackage{newunicodechar}
\input{newunicodedefs}

%%%%%%%%%%%%%%%%% ott %%%%%%%%%%%%%%%%%

\usepackage[supertabular,implicitLineBreakHack]{ottalt}
\inputott{ott.tex}

%%%%%%%%%%%%%%%%% /ott %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% Workaround %%%%%%%%%%%%%%%%%

% This should be handled by the acmclass article, there are a couple
% of issues about
% this. https://github.com/borisveytsman/acmart/issues/271,
% https://github.com/borisveytsman/acmart/issues/327 . Both have been
% merged long ago, and the version of acmart in the shell.nix is from
% 2020.

%% \usepackage{fontspec}
%% \setmainfont{Linux Libertine O}
%% \setsansfont{Linux Biolinum O}
%% \setmonofont{inconsolata}

%%%%%%%%%%%%%%%%% /Workaround %%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%% lhs2tex %%%%%%%%%%%%%%%%%

\let\Bbbk\undefined    % see https://github.com/kosmikus/lhs2tex/issues/82
%include polycode.fmt
%if style == poly
%format ->. = "⊸"
%format =>. = "\Lolly"
%format .<= = "\RLolly"
%format IOL = "IO_L"
%format . = "."
%format exists = "\exists"
%format forall = "\forall"
%format pack = "\kpack"
%endif

%%%%%%%%%%%%%%%%% /lhs2tex %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      \setlength{\marginparwidth}{1.2cm} % A size that matches the new PACMPL format
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{{\color{blue}{#1}}}
      \newcommand{\note}[1]{{\color{blue}{\begin{itemize} \item {#1} \end{itemize}}}}
      \newenvironment{alt}{\color{red}}{}

      \newcommandx{\jp}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommandx{\csongor}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=purple,#1]{#2}}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
  \else
  %    \newcommand{\Red}[1]{#1}
      \newcommand{\Red}[1]{{\color{red}{#1}}}
      \newcommand{\newaudit}[1]{#1}
      \newcommand{\note}[1]{}
      \newenvironment{alt}{}{}
  %    \renewcommand\todo[2]{}
      \newcommand{\unsure}[2]{}
      \newcommand{\info}[2]{}
      \newcommand{\change}[2]{}
      \newcommand{\inconsistent}[2]{}
      \newcommand{\critical}[2]{}
      \newcommand{\improvement}[1]{}
      \newcommand{\resolved}[2]{}
  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% Domain-specific macros %%%%%%%%%%%%%%%%%

  \newcommand{\cscheme}[1]{\mathcal{#1}}
  \newcommand{\aand}{\mathop{\&}}
  \DeclareMathOperator*{\bigaand}{\vcenter{\hbox{\Large\&}}}
  \newcommand{\lollycirc}{\raisebox{-0.2ex}{\scalebox{1.4}{$\circ$}}}
  \newcommand{\Lolly}{\mathop{=\!\!\!{\lollycirc}}}
  \newcommand{\RLolly}{\mathop{\lollycirc\!\!\!=}}
  \newcommand{\subst}[2]{[#1]#2}
  \newcommand{\sby}[2]{#1 ↦ #2}
  \newcommand{\vdashi}{⊢_{\mathsf{i}}}
  \newcommand{\vdashs}{⊢_{\mathsf{s}}}

  % language keywords
  \newcommand{\keyword}[1]{\mathbf{#1}}
  \newcommand{\klet}{\keyword{let}}
  \newcommand{\kcase}{\keyword{case}}
  \newcommand{\kwith}{\keyword{with}}
  \newcommand{\kpack}{\keyword{pack}}
  \newcommand{\kunpack}{\keyword{unpack}}
  \newcommand{\kin}{\keyword{in}}
  \newcommand{\kof}{\keyword{of}}

%%%%%%%%%%%%%%%%% /Domain-specific macros %%%%%%%%%%%%%%%%%
\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  Paso, Texas USA} 
\acmYear{1997}
\copyrightyear{2016}

\acmPrice{15.00}

\begin{document}

\title{Linear Constraints}

\author{Jean-Philippe Bernardy}
\affiliation{
  \institution{University of Gothenburg}
  \city{Gothenburg}
  \country{Sweden}
}
\email{jean-philippe.bernardy@@gu.se}
\author{Richard Eisenberg}
\affiliation{
  \institution{Tweag}
  \city{Paris}
  \country{France}
}
\email{richard.eisenberg@@tweag.io}
\author{Csongor Kiss}
\affiliation{
  \institution{Imperial College London}
  \city{London}
  \country{United Kingdom}
}
\email{csongor.kiss14@@imperial.ac.uk}
\author{Arnaud Spiwack}
\affiliation{
  \institution{Tweag}
  \city{Paris}
  \country{France}
}
\email{arnaud.spiwack@@tweag.io}

\begin{abstract}
This paper presents \emph{linear constraints}, a language feature that improves
the ergonomics of using linear types by freeing programmers from having to
manually pass around linear resource tokens. The resulting code retains the
safety of the linear version while also keeping the simplicity of the
traditional version. We present a qualified type system with linear constraints,
and a typechecking algorithm. We prove the soundness of the algorithm with
respect to the type system, and show how our changes can be integrated into
|OutsideIn|, GHC's existing constraint solver algorithm.
\end{abstract}

\maketitle

\renewcommand{\shortauthors}{Bernardy, Eisenberg, Kiss, and Spiwack}

\section*{Introduction}
\info{There  is an Appendix section with unorganised thoughts and
  examples.}

Linear type systems have seen somewhat of a renessaince in recent years in
various mainstream programming communities. Rust's ownership system guarantees
memory safety for systems programmers, Haskell's linear types give functional
programmers safe APIs for low-level mutable data structures, and even
dependently typed programmers can now use linear types with Idris 2.

\csongor{Say something about ergonomics to set up the next part}

To get a sense of the power of linear types, consider the following example from
the Linear Haskell article~\cite{LinearHaskell}\footnote{|IOL| is the linear IO monad}:
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { f <- openFile fp
      ; (f, Ur bs) <- readLine f
      ; closeFile f
      ; return bs }
\end{code} This simple function opens a file, reads its first line, then closes
it. Linearity ensures that the file handle |f| is consumed at the end.
Forgetting to call |closeFile f| would result in a type error since |f| would
remain unused at the end of the function. Notice that `readLine` consumes the
file handle, and returns a fresh one, to be used in further interactions with
the file. The line's content is returned in an |Ur| wrapper (pronounced
``unrestricted'') to signify that it can be used arbitrary many times.

% We see that linear types introduce some noise on the |readLine| line:
% we need to destruct an extra pair, and an extra |Ur| (called
% |Unrestricted| in~\cite{LinearHaskell}), compared to the
% traditional (albeit less safe)\unsure{It only gets worse in larger
%   program. This makes the extra safety afforded by linear types too
%   rarely worth it.}

Compare this function with the traditional, non-linear version:
\begin{code}
firstLine :: FilePath -> IO Bytestring
firstLine fp =
  do  { f <- openFile fp
      ; bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

This version is less safe, because the type system does not keep track of the
file handle, so the programmer must. But it is also simpler: apparently, in the
linear version, we traded clarity for safety. Since the file handle is now an
expendable resource, the type system must know at all times where it is being
consumed, so the file handle must be passed around manually, culminating in
extra noise. Worse, the larger the program gets, the more additional bookkeeping
this requires.

But reading the non-linear version, it is perfectly clear where the
handle is used, and ultimately, consumed. Could the compiler not figure this out
without extra help?

In this paper, we answer this question affirmatively, and introduce \emph{linear
constraints}, an extension of Haskell's type class mechanism to be aware of
linearity. This way, resource consumption is tracked without explicitly having
to thread the tokens through the program. The final version of |firstLine| is thus:
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { f <- openFile fp
      ; bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

Note the only change from the unsafe version is that this version runs in the
linear IO monad.

\paragraph{Our contributions are as follows}

\begin{itemize}
\item A system of qualified types that allows a constraint assumption
  to be given a multiplicity. Linear assumptions are used precisely
  once in the body of a definition.
\item This system supports examples that have motivated the design of
  several resource-aware systems, such as ownership à la Rust, or
  capabilities in the style of Mezzo\unsure{citation needed} or \textsc{ats}~\cite{AtsLinearViews}; accordingly, our system
  may serve as a way to unify these lines of research.\unsure{Speak of
  the Pony language? On the one hand Pony is a pretty cool piece of
  tech, on the other hand, I don't know enough to say something
  smart about it.}\unsure{Should we speak of typestate here?}
\item A typechecking algorithm, based on a combination
  of~\cite{OutsideIn}
  and~\cite{resource-management-for-ll-proof-search}, that respects
  the multiplicity of assumptions. We prove that this algorithm is
  sound and complete with respect to our type system.\unsure{Can we
    have a concrete completeness result?}
\item Our algorithm additionally desugars expressions in our qualified
  type system into a core language (directly inspired
  by Linear Haskell~\cite{LinearHaskell}) that supports linear functions. We
  prove that the output of desugaring is well-typed in the core
  language.
\end{itemize}

\newpage

\section{Motivation}


\csongor{I moved the more detailed stuff from the introduction here for now. We
have more space here to elaborate the problem statement}
% This extra noise is the consequence of the fact that, as far as a
% linear type system is concerned, |f| is expended after |readLine
% f|. But, of course, we typically want to do more with a file that
% reading just one line of it, so the linear |readLine| is given the type.

\begin{code}
  readLine :: File ⊸ IOL (File, Unrestricted ByteString)
\end{code}
\unsure{Probably we want the entire \textsc{api} for this
  example. Also, we will probably start with the \textsc{api}, as part
  of the general linear types introduction only to
  demonstrate its limitation here.}

It appears to return a new file, but really, it returns a new name for
the same file. It really is these names which can only be used once,
the file handle itself continues to exist until |closeFile| is called.

This is a bit of a bother, though. Why do I have to manage a bunch of
names to help a compiler count? Surely this can be handled by the
typechecker automatically. And, indeed, compilers with \emph{ad hoc}
specialised logic let me write essentially the traditional program but
with the guarantee that if I forget to |closeFile|, I'll get a type
error. This is most notably the case of the
\textsc{ats}~\cite{AtsLinearViews}, and Mezzo
languages\unsure{Citation needed}.\unsure{Both \textsc{ats} and Mezzo
  are specialised in handling pointers-and-mutations, rather than
  file. So the sentence above is a little bit of a lie. Either
  rephrase to say that we can write programs of \emph{this type}, or
  use an array example instead of a file example. Though I think that
  the file example is a better introduction.}

\unsure{Maybe we want to hammer in the fact that, in Linear Haskell,
  there is no use case natively understood by the compiler. Every
  abstraction is built user-side. \textsc{Ats}'s views are closest to
  what we are doing, though seems to only be geared towards pointers.}
In this article we introduce a generic extension to Linear Haskell,
which lets the typechecker handle the counting. With this extension
|firstLine| would be written as:
\unsure{probably display |pack| in bold in Haskell code}
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { pack f <- openFile fp
      ; pack bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}

There is a bit of boilerplate left, but it doesn't involve managing
names to please the compiler. This considerably lowers the cost of
using a linear-type based abstraction.\unsure{I'm trying to get at the
  cost/benefit analysis thing and how it matters a lot, but I haven't
  found a convincing way to do so without ranting for a page or so,
  I'll get back to this when the rest of the paper is written and I
  revisit the introduction.}


\section{What it looks like}
\label{sec:what-it-looks-like}

Consider the Haskell function |show|

\begin{code}
show :: Show a => a -> String
\end{code}

In addition to the function arrow |->|, common to all functional
programming language, it features a fat arrow |=>|. Everything to the
left of a fat arrow is called a \emph{constraint}. Here |Show a| is a
type-class constraint, but there are other kinds of constraints such
as equality constraint or implicit parameter constraints.

What is crucial, for our purpose, is that constraints are handled
implicitly by the typechecker. That is, if we want to |show| an
integer, we'd write |show 42|, the typechecker would handle proving
that |Show Int| without intervention from the programmer.

In order to manage linearity implicitly, this article introduces a
linear fat arrow |=>.|, much like Linear Haskell introduced a linear
function arrow |->.|. We dub constraints to the left of a linear fat
arrow \emph{linear constraints}.  \unsure{I'm jumping to
  conclusions a little fast. I need to explain what it entails for a
  constraint to be linear. Then I need to re-read (and
  presumably re-write) the paragraphs below, they will probably flow a
  little bit better once the right principles are firmly established.}

In the introduction we wanted to use linearity to make sure that a
file was closed and not used after. That is, we need to track in types
whether the file open or not. We can use a linear constraint |Open f|
to represent that a file is, indeed, open. We can write the type of
|closeFile|:

\begin{code}
closeFile :: Open f =>. File f -> IOL ()
\end{code}

There are a few things to notice
\begin{itemize}
\item First, there is this type variable |f| which didn't exist in
  previous representation. In the representation of the Linear Haskell
  paper, for instance, |closeFile| had type |closeFile :: File ->. IOL
  ()|. This |f| is a type-level name for the file which we are
  closing.
  Giving a name to function argument is the bread and butter of more
  dependently typed languages such as \textsc{ats} or Liquid
  Haskell\unsure{citation needed}. But Haskell doesn't have such a
  naming mechanism built in, so we have to make argument names
  explicit in types.
\item Second, assuming that we have a single, linear, |Open f|
  available, then after |closeFile| there will not be any |Open f|
  left to use, therefore we won't be able to close the file
  twice. Which is precisely what we were trying to achieve.
\end{itemize}

This still leaves questions open: where does |f| come from? where does
|Open f| come from? what are the types of |openFile| and |readLine|?
The answers to these three question rely on the same device: we
introduce a type construction |exists a1 ... an. t .<= Q|\unsure{Todo:
  render the indices as actual indices}, where |Q| is some (linear)
constraint.

The fact that existential quantification generate new type-level names
is a folklore observation. It's used crucially in the interface of the
|ST| monad\unsure{citation needed} and of type-class
reflection\unsure{citation needed} (in both of these cases, existential
quantification is encoded as a rank-2 universal quantificaton). We
shall use it exactly this way: |openFile| uses an existential
quantifier to generate the type-level name of the file
handle. Existentially quantified types are paired with constraint |Q|
which we understand as being returned by functions. We will freely
omit the |exists a1 ... an.| or |.<= Q| parts when they are
empty. This lets us give the following \textsc{api} to files:

\begin{code}
openFile :: FilePath -> IOL (exists f. File f .<= Open f)
readLine :: Open f =>. File f -> IOL (() .<= Open f)
closeFile :: Open f =>. File f -> IOL ()
\end{code}

Haskell doesn't have such existential quantification, however each
instance of such existential quantification can be encoded as a
\textsc{gadt}. For instance |exists f. File f .<= Open f| can be
implemented as

\begin{code}
data NewFile where
  Pack :: Open f =>. File f -> NewFile
\end{code}

Therefore, the existential types of this article are really a
convenience for the sake of exposition\unsure{Though, see the
  existential type paper}. Correspondingly, existential types are
introduced by a data constructor, which we write |pack|.

When pattern-matching on a |pack| all the existentially quantified
names are introduced in scope and all the returned constraints are
made available. With all these ingredients, we can indeed write, as
promised in the introduction
\begin{code}
firstLine :: FilePath -> IOL Bytestring
firstLine fp =
  do  { pack f <- openFile fp
      ; pack bs <- readLine f
      ; closeFile f
      ; return bs }
\end{code}
\unsure{Deduplicate with the version in the introduction to avoid desync?}

\unsure {Explain that existentially quantified type always have an
  implicit unrestricted at their core.}

\unsure{Link to a typestate paper + mention how much closer this is
  to the idea of typestate than the pedestrian encoding in regular
  linear types.}

\newpage

\section{Examples}
\label{sec:examples}


\newpage

\section{A qualified type system}

\unsure{Some transition from example into the technique needed here.}

The description of the type system in this section, as well as the
type inference algorithm of Section~\ref{sec:type-inference}, are
strongly inspired by the presentation of
OutsideIn~\cite{OutsideIn}. OutsideIn is a foundation of the type
inference algorithm of \textsc{ghc}, the most popular Haskell
compiler, as such we decided to frame this presentation as an
extension of OutsideIn. We have chosen, for the sake of clarity of the
exposition, to omit details of OutsideIn which do not interact with
linear constraints. We shall point out such simplifications where they
arise.

\subsection{Multiplicities}
\label{sec:multiplicities}

\unsure{Multiplicities are $[[1]]$ or $[[omega]]$ (no
  variable). Multiplication table. Probably addition table.}

\subsection{Constraint entailment relation}
\label{sec:constraint-domain}

\info{See Fig 3, p14 of OutsideIn\cite{OutsideIn}.}

Like OutsideIn (see~\cite[Section 3.2, in particular Figure
3]{OutsideIn}), we parameterise the entire type system by a constraint
domain. This domain is characterised by an entailment relation
$[[Q1 ||- Q2]]$. The purpose of the constraint domain is to give a
syntax and semantics to constraints, both of which are abstract in the
type system. For instance, in \textsc{ghc}, the domain includes type
classes the entailment relation describes instance resolution.

For the sake of the examples of this article the domain need only be
the simplest possible domain. The domain serves to support the rest of
Haskell, or any future extension.

OutsideIn introduces, as part of the constraint domain, a generalised
kind of constraint $\mathcal{Q}$, which include toplevel axioms, such
as type-class instance declaration declarations. Such toplevel axioms
are never linear~--~just like toplevel definition are never linear in
Linear Haskell~\cite{LinearHaskell}~--~as such they don't have
interesting interaction with the rest of the system, and we choose to
omit them for simplicity.

Scaling is extended to all constraints:

$$
\left\{
  \begin{array}{lcl}
    [[pi.(Q1 * Q2)]] & = & [[pi.Q1 * pi.Q2]] \\
    [[pi.(rho. Q)]]  & = & [[(pi.rho) . Q]]
  \end{array}
\right.
$$
\unsure{Rendering}
\unsure{Explain that the commutation of scaling and tensor product is
  an exotic feature of Linear Haskell. It does simplify the
  presentation a bit here.}

Note that $[[1.Q]] = [[Q]]$.

The constraint entailment relation must satisfy the following
properties:

\unsure{I'm probably using associativity and commutativity of the
  tensor product under the hood. It should probably be assumed somehow.}
\unsure{Todo: we ignore scaling by $1$ most of the time.}
\unsure{Todo: scaled atomic constraints}
\begin{displaymath}
  \begin{array}{l}
    [[Q ||- Q]] \\
    [[Q1 ||- Q2]] \text{ and } [[Q * Q2 ||- Q3]] \text{ then } [[Q1 * Q ||- Q3]] \\
    [[Q ||- Q1 * Q2]] \text{ then there exists } [[Q']] \text{ and } [[Q'']]
    \text{ such that } [[Q' ||- Q1]] \text{ and } [[Q'' ||- Q2]] \\
    [[Q1 ||- Q1]] \text{ and } [[Q2 ||- Q2]] \text{ then } [[Q1 * Q2 ||- Q1 * Q2]] \\
    [[Q ||- rho. q]] \text{ then } [[pi . Q ||- (pi.rho). q]] \\
    [[Q ||- (pi.rho) . q]] \text{ then there exists } [[Q']] \text{ such
    that } [[Q]] = [[pi. Q']] \text{ and } [[Q' ||- rho . q]]
  \end{array}
\end{displaymath}
\unsure{Missing: $[[Q]]$ should be equal (up to reordering) to
  $[[Q' * Q'']]$ in the tensor splitting condition. Or, at least, some
  form of entailment relation. What precisely will be apparent in the
  proof of the inversion/uniformity lemma}

Another difference with OutsideIn is that we don't require the
presence of equality constraints. We come back to the motivation for
this simplification in Section~\ref{sec:constraint-generation}.

\begin{lemma}
  \label{lem:q:promotion}
  If $[[Q1 ||- Q2]]$, then $[[pi.Q1 ||- pi.Q2]]$.
\end{lemma}
\begin{proof}
  By induction on the syntax of $[[Q2]]$:
  \begin{itemize}
  \item If $[[Q2]] = [[rho.q]]$, then $[[pi.Q1 ||- (pi.rho).q]]$ holds by
    hypothesis.
  \item If $[[Q2]] = [[Q2' * Q2'']]$, then, by hypothesis, we know that
    $[[Q1]] = [[Q1' * Q1'']]$ for some $[[Q1']]$ and $[[Q1'']]$, and
    that
    $[[Q1' ||- Q2']]$ and $[[Q1'' ||- Q2'']]$. By induction hypothesis,
    we have
    $[[pi.Q1' ||- pi.Q2']]$ and $[[pi.Q1'' ||- pi.Q2'']]$. From which it
    follows that
    $[[pi.Q1 ||- pi.Q2]]$.
  \end{itemize}
\end{proof}

\begin{lemma}
  \label{lem:q:scaling-inversion}
  If $[[Q1 ||- pi.Q2]]$, then there exists $[[Q1']]$ such that
  $[[Q1]]=[[pi.Q1']]$ and $[[Q1' ||- Q2]]$
\end{lemma}
\begin{proof}
  By induction on the syntax of $[[Q2]]$
  \begin{itemize}
  \item If $[[Q2]] = [[rho.q]]$, then, by hypothesis, there exists
    $[[Q1']]$ such that $[[Q1]]=[[pi.Q1']]$ and $[[Q1' ||- rho.q]]$.
  \item If $[[Q2]] = [[Q2' * Q2'']]$, then, by hypothesis, we know
    that
    $[[Q1]] = [[Q1' * Q1'']]$ for some $[[Q1']]$ and $[[Q1'']]$, and
    that
    $[[Q1' ||- pi.Q2']]$ and $[[Q1'' ||- pi.Q2'']]$ (remember that, by
    definition, $[[pi.Q2]] = [[pi.Q2' * pi.Q2'']]$). By induction hypothesis,
    we have
    constraints $[[Q']]$ and $[[Q'']]$, such that $[[Q1']] =
    [[pi.Q']]$ and $[[Q1'']] = [[pi.Q'']]$, and $[[Q' ||- Q2']]$ and
    $[[Q'' ||- Q2'']]$.
    It follows that $[[Q1]] = [[pi.(Q' * Q'')]]$ and
    $[[Q' * Q'' ||- Q2]]$.
  \end{itemize}
\end{proof}

\newpage

\subsection{Typing rules}
\label{sec:typing-rules}

Like in OutsideIn~\cite[Section 4]{OutsideIn}, the type system is
presented as a \emph{qualified type system} in the style first introduced
by~\cite{QualifiedTypes}. Such a qualified type system introduces a
judgement of the form $[[Q;G |- e : t]]$, where $[[G]]$ is a standard
type context, and $[[Q]]$ is a constraint from the domain of
Section~\ref{sec:constraint-domain}. For the most part $[[Q]]$ behaves
much like with $[[G]]$, which will be instrumental for
desugaring in Section~\ref{sec:desugaring}; the main difference is
that $[[G]]$ is referred to explicitly with variables, whereas $[[Q]]$
is used implicitly in \rref{E-Var}.

\unsure{We probably want the grammar somewhere}
%
\jp{It's very important to explain in detail that linear constraints
  (as linear values) can never escape to omega contexts.
}

%
\info{See Fig 10, p25 of OutsideIn\cite{OutsideIn}.}

See Figure~\ref{fig:typing-rules}.

Main differences:
\begin{itemize}
\item Linearity as in the Linear Haskell paper
\item $\kcase$ doesn't have \textsc{gadt}s
\item Existential packs are our only \textsc{gadt}. They have a single
  constructor, pattern-matched over by $\kunpack$.

  (Consequently, we encode linear constraints inside data types as
  existential pack type.)\unsure{We may need a comment on the fact
    that $\kunpack$ doesn't have a $\pi$ index. There would be nothing
    wrong with it, I imagine, it's just a little bit useless.}
\item Explicit subsumption rule \rref*{E-Sub}
\end{itemize}
\improvement{We also want let with a signature. For the sake of completeness}

\begin{figure}
  \centering
  \drules[E]{$[[Q;G |- e : t]]$}{Expression
    typing}{Var,Abs,App,Pack,Unpack,Let,Case,Sub}
  \caption{Qualified type system}
  \label{fig:typing-rules}
\end{figure}

\info{No substitution on $[[Q1]]$ in the $\kunpack$ rule, because there is
  only existential quantification.}


\newpage

\section{Type inference}
\label{sec:type-inference}

\unsure{Should we keep with the terminology type inference (here and
  everywhere throughout the paper) considering that we assume that
  types are inferred by someone else, but really just ``infer
  constraints'' in some sense.}

\unsure{Todo: transition}

\subsection{Generated constraints}
\label{sec:wanteds}

\unsure{I [Arnaud] am currently thinking that we want to make a
  relation like this which extends the entailment to C-constraints. It
  would abstract over the actual solver and clarify proofs.}
\drules[C]{$[[Q |- C]]$}
  {Generalised constraint entailment}
  {Dom,Tensor,With,Impl}
\info{[Arnaud]: It's really more of a side remark, but there seems
  to be a connection with focusing here: if a combinator is
  ``asynchronous'' then it need not appear in $[[Q]]$ constraints
  whereas if the combinator is ``synchronous'', then it does.}

Scaling is extended to all generated constraints:

$$
\left\{
  \begin{array}{lcl}
    [[pi.(C1 * C2)]] & = & [[pi.C1 * pi.C2]] \\
    [[pi.(C1 & C2)]] & = & [[pi.C1 * pi.C2]] \\
    [[pi.(rho.(Q => C))]] & = & [[(pi.rho).(Q => C)]]
  \end{array}
\right.
$$

Note that there is no ambiguity when writing $[[Q => C]]$ for
$[[1.(Q => C)]]$, since $[[pi.(1.(Q => C))]]$ is indeed equal to
$[[pi.(Q => C)]]$.

\begin{lemma}
  \label{lem:wanted:promote}
  If $[[Q |- C]]$, then $[[pi.Q |- pi.C]]$
\end{lemma}
\begin{proof}
  todo
\end{proof}

\begin{lemma}
  \label{lem:inversion}
  \begin{itemize}
  \item If $[[Q |- C1*C2]]$ then there exists $[[Q1]]$ and
    $[[Q2]]$ such that
    \begin{itemize}
    \item $[[Q1 |- C1]]$
    \item $[[Q2 |- C2]]$
    \item $[[Q]] = [[Q1 * Q2]]$\unsure{I'm not sure this last
        one is quite the correct criterion. In that we may want an
        equivalence rather than an equality.}
    \end{itemize}
  \item If $[[Q |- pi.(Q2 => C)]]$ then there exists $[[Q1]]$ such
    that
    \begin{itemize}
    \item $[[Q1 * Q2 |- C]]$
    \item $[[Q]] = [[pi.Q1]]$
    \end{itemize}
  \item If $[[Q |- pi.C]]$ then there exists $[[Q']]$ such that
    \begin{itemize}
    \item $[[Q' |- C]]$
    \item $[[Q]] = [[pi.Q']]$
    \end{itemize}
  \end{itemize}
\end{lemma}
\unsure{I think they correspond to the uniform proof
  story from~\cite{hh-ll}, namely, any provable sequent with a
  non-atomic right-hand side can be proved with a right introduction
  rule. There is a bit of complication here due to the domain-specific
  entailment but the decomposability requirement should give us the
  same result.}



\newpage


\subsection{Constraint generation}
\label{sec:constraint-generation}

See Fig.13, p39 of OutsideIn~\cite{OutsideIn} \unsure{Todo: syntax to
  select the $\pi$ in case, linear $\kunpack$ rule}

In a full blown Haskell with linear constraints, there wouldn't be
linear equality constraints.\jp{Seems to suggest that we have linear
  equality constraints here? [Arnaud]: my poor phrasing, I meant to
  imply that we didn't have any equality constraints at all.}
That is, $a \sim b$\unsure{this notation
  hasn't been introduced, so if it makes the cut explain where it
  comes from} wouldn't appear to the left of a linear fat arrow. It's
not that linear equalities don't make sense, see for
instance~\cite{shulman2018linear} for a system which takes linear
equality seriously. However, the usual unification algorithms are
unsound for linear equalities, because they will gladly use the same
equality many times (or none-at-all). Haskell could, by some arbitrary
mean, reject equality constraints to the left of a linear fat arrow,
or it could simply refuse to do any solving with such equalities.

While it is possible that a future version of Haskell includes linear
equality constraints, automatic resolution of linear equality
constraints is beyond the scope of this article. Nor is it needed,
or even useful, for our use cases.
%
Thus, in general, no linear constraint can be used in, or influence in
any way, the unification of type meta variables to types.  As a
consequence, linear
%
constraints are fully orthogonal to type inference. Therefore, the
syntax-directed constraint generation system presented in this section
can legitimately assume that type inference is solved elsewhere;
contrary to~\cite{OutsideIn}, where type inference is mixed with
constraint generation. This separation of concern simplifies the
presentation significantly.\unsure{This paragraph is more wordy than
  it is clear, so let's not take it as an actual proposal for the
  explanation, I [Arnaud] merely wanted to record my thoughts}

\unsure{Todo: the rule for a constraint-generalising signatureless
  let}
\improvement{We also want let with a signature. There are two rules in
  OutsideIn: when the signature is monomorphic, and when it's
  polymorphic. Maybe we don't care about this distinction all that
  much.}
\unsure{The case rule, for an empty case, implies the existence of the
  typically annoying $⊤$. We will have to confront this.}
\unsure{We probably want the freshness condition on the $\kunpack$
  rule, though these variables are universal variables, not
  existentials.}
\info{Not caring about inferences simplifies $\kpack$ quite a bit, we
  are using the pseudo-inferred type to generate constraint. In a real
  system, we would need $\kpack$ to know its type (\emph{e.g.} using
  bidirectional type checking).}
\unsure{The case rule should have constructors with fields with
  varying multiplicities}
\drules[G]{$[[G |-> e : t ~> C]]$}{Constraint generation}{Var, Abs,
  App, Case, Unpack, Pack}

\jp{In the case rule, the sum is a bit confusing. It may just work with
  linear haskell, but Morally it is a union (or with), perhaps this should be written so for symmetry with what happens with constraints?}
\jp{In the case rule, the letter e is used twice; this is confusing.}
\jp{In G-Unpack, the use of ⊃ is confusing (it's not a superset, but rather a linear implication?). }

\newpage

\subsubsection{Soundness of constraint generation}
\label{sec:constraint-generation-soundness}

If we can type a term and generate constraints ($[[G |-> e : t ~> C]]$), and
these constraints are solvable using $[[Q]]$ with no leftover,
($[[Q |-s C ~> 1;1]]$), then we can type it in the declarative system
($[[Q;G |- e : t]]$).\unsure{TODO: rewrite now that we don't talk
  about the solver here. In fact, do we have to bring the
  simplifier here? Can we instead use the constraint entailment
  relation and show separately that the simplifier is sound for
  constraint entailment? [arnaud]: entailment doesn't understand
  $[[C]]$ constraints. However, I agree with the sentiment, and I've
  been considering introducing an extended entailment for $[[C]]$
  constraints rather than deal with the more algorithmic system.}

\begin{lemma}
  For all $[[Q_g]]$ if
  \begin{itemize}
  \item $[[G |-> e : t ~> C]]$
  \item $[[Q_g |- C]]$
  \end{itemize}
  then
  $[[Q_g; G |- e : t]]$
\end{lemma}
\begin{proof}
  \unsure{The proof is a sketch}
  \unsure{The proof needs to be corrected for the fixed Lemma~\ref{lem:inversion}}
  By induction on $[[G |-> e : t ~> C]]$
  \begin{description}
  \item[App] \info{Most of the linearity problems are here}
    We have
    \begin{itemize}
    \item $[[G1+pi.G2 |-> e1 e2 : t ~> C1 * pi.C2]]$
    \item $[[Q_g |- C1 * pi.C2]]$
    \item $[[G1 |-> e1 : t2 ->_pi t ~> C1]]$
    \item $[[G2 |-> e2 : t2 ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q1]]$, $[[Q2]]$ such that
    \begin{itemize}
    \item $[[Q1 |- C1]]$
    \item $[[Q2 |- C2]]$
    \item $[[Q_g]] = [[Q1 * pi.Q2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q1; G1 |- e1 : t2 ->_pi t]]$
    \item $[[Q2; G2 |- e2 : t2]]$
    \end{itemize}
    Hence $[[Q_g; G1+pi.G2 |- e1 e2 : t]]$.
  \item[Unpack] We have
    \begin{itemize}
    \item $[[pi.G1+G2 |-> unpack x = e1 in e2 : t ~> pi.C1 * Q' => C2]]$
    \item $[[Q_g |- omega.C1 * Q' => C2]]$
    \item $[[G1 |-> e1 : exists as. t1 o= Q' ~> C1]]$
    \item $[[G2, x:_pi t1 |-> e2 : t ~> C2]]$
    \end{itemize}
    By Lemma~\ref{lem:inversion}, there exist $[[Q_1]]$, $[[Q_2]]$
    such that
    \begin{itemize}
    \item $[[Q_1 |- C1]]$
    \item $[[Q_2 * Q' |- C2]]$
    \item $[[Q_g]] = [[omega.Q1 * Q2]]$
    \end{itemize}
    By induction hypothesis
    \begin{itemize}
    \item $[[Q_1; G1 |- e1 : exists as. t1 o= Q']]$
    \item $[[Q_2*Q ; G2 |- e2 : t]]$
    \end{itemize}
    Therefore $[[Q_g ; pi.G1 + G2 |- unpack x = e1 in e2 : t]]$
  \item[Case] \unsure{Arnaud: will I be able to avoid a $\aand$ constraint
     or not? I'm guessing not.}
  \end{description}
\end{proof}

\newpage

\subsection{Constraint solver}
\label{sec:constraint-solver}
$[[Q_g |-s C ~> Q_o;Q_r]]$

Correctness property: $[[Q_g * Q_r |- C * Q_o]]$.\unsure{We would
  typically have $[[Q_o]]⊆[[Q_g]]$, but does it matter? Actually, I'm
  [Arnaud] tempted to posit that this wouldn't always hold for
  GHC. Indeed, GHC rewrites givens, therefore, $[[Q_o]]$ may have
  extra formula or rewritten formulas which are not actually in
  $[[Q_g]]$.}

Various recipes are given
by~\textcite{resource-management-for-ll-proof-search}.
\info{The first presentation of returning output context that I could
  find is~\cite{hh-ll}, but I
  find~\cite{resource-management-for-ll-proof-search} more
  informative.}
These recipes are phrased in a way which implies goal oriented
proof search, but they can be adapted \emph{mutatis mutandis} to GHC's
backtrackingless rewrite-based search.

The key points are
\begin{itemize}
\item Each rule return the remaining, unused (linear) hypotheses: the
  \emph{leftovers}.
\item To deal with $⊤$, remember that you've encountered a $⊤$ in a
  different branch. And let you spend any leftover back into a
  previous $⊤$
\item In~\cite{resource-management-for-ll-proof-search}, there is a
  third input context ($Ξ$), which represents a context which need to
  be used, and cannot be returned as leftovers. However, this is used
  to fail earlier in backtracking branches which are doomed to
  fail. It doesn't apply to our backtrackingless
  setting\unsure{[Arnaud]: I think.}
\end{itemize}

We can do pretty much like in OutsideIn: split the constraint between
flat constraints and non-flat constraints if we wish (but, this time,
non-flat constraint include $\aand$! so there will be significantly
more of them). Apply synchronous rules on non-flat constraint to retrieve flat
constraint, call the simplifier on them.

To be honest, we can even do one atomic constraint at a time, given
that we have no equality, hence our wanted can't interact (I [Arnaud]
think) but the details don't matter terribly.

\newpage

\section{Desugaring}
\label{sec:desugaring}

\info{The plan is to give the operational semantics in the form
  of a desugaring to the core calculus of the Linear Haskell paper.}


\info{
  On unicity of tokens:

  A constraint like ``Open'' (no argument), does not make much sense
  to use as a linear constraint. Because if we can make it once, then
  we can make it omega times, and it's useless (it's similar to linear
  constants in linear haskell. They were not supported.)

  So, we're using something like ``Open f'' instead. Together with a
  an existential variable f. Then the API can ensure that there is a
  single token for this constraint at any given point. The API can
  however create several copies --- but then it's up to the API to
  make sure that the order of picking the constraints is
  computationally irrelevant. (Label constraints as computationally
  relevant? Then GHC could issue errors if there is computational
  relevance and it ends up making a choice.)

  [arnaud] maybe reject all programs which force the constraint solver
  to make an ordering choice
  
  [jp] still worried about the order of treating arguments: if we have
  writeFile f x >> writeFile f y then the arguments of could be
  handled in any order (for constraints!), and it's a shame to reject
  this.

  [arnaud] I don't think so, because in this case, writeFile f y is
  forced to use the most nested evidence, which is that given by
  writeFile f x
  
}

Goal: describe transformations
\begin{enumerate}
\item Constraint generator + solver $\leadsto$ declarative
  system\unsure{My [Arnaud's] guess is that the main difficulty, here,
  will be to deal with $⊤$ and its effect at a distance}
\item declarative system $\leadsto$ $λ^q$\info{Really, this is just
    evidence passing style. If the declarative system is well written,
    it will be quite direct.}
\end{enumerate}

\newpage

\section{Implementation}
\label{sec:implementation}

\unsure{Todo: discussion on the prototype implementation}

\newpage

\section{Extensions}
\begin{itemize}
\item Like there are implicational and universally-quantified
  constraints in the left-hand side of fat arrows, we may want to have
  $\aand$ constraints on the left hand side of (linear) fat
  arrows. This falls in the Linear Hereditary Harrop fragment
  described, for instance, in~\cite{hh-ll}
  and~\cite{resource-management-for-ll-proof-search}. Hereditary
  Harrop is a natural extension of Horn clauses in proof search
  algorithms.
\end{itemize}

\appendix

\section{Preamble from Csongor}

\begin{spec}
data a .<= c where
  Pack :: c =>. a -> a .<= c
data IOL c a = IOL {runIOL :: RealWorld -> (RealWorld, a .<= c)}
\end{spec}

If we bake the constraint into |IOL|, then we need to change \emph{both} |c| and |a|:
\begin{spec}
(>>=) :: IOL c a -> (c =>. a -> IOL d b) -> IOL d b
io_a >>= f = IOL $ \rw -> case runIOL io_a rw of
                            (rw', Pack a) -> runIOL (f a) rw'
\end{spec}

% $ emacs

\section{Arnaud's motivating examples}

\subsection{Linear IO without the hassle (file handles)}

In Linear Haskell~\cite{LinearHaskell}

\begin{spec}
readTwoLines path = do
  h0 <- openFile path
  (h1, line1) <- readLine h0
  (h2, line2) <- readLine h1
  close h2
\end{spec}
API:
\begin{spec}
openFile  :: FilePath -> IOL Handle
close     :: Handle ⊸ IOL ()
readLine  :: Handle ⊸ IOL (Handle, String)
\end{spec}
With linear constraints, API:
\begin{spec}
openFile  :: FilePath -> IOL (Handle h .<= Open h)
close     :: Open h =>. Handle h -> IOL ()
readLine  :: Open h =>. Handle h -> IOL (String .<= Open h)
\end{spec}
The example become (remark: not the do-notation for the |IO| monad):
\begin{spec}
readTwoLines path = do
  h <- openFile path
  line1 <- readLine h
  line2 <- readLine h
  close h
\end{spec}

It looks exactly the same as without linear types. But you still get
an error for double-free and use-after-free usages.

\subsection{Quantum IO Monad}

To showcase another area where deploying linear constraints seems promising, let
us review the quantum computational model. At the fundamental level, the
evolution of a quantum state is \emph{unitary}, which, in essence, means that
information cannot be lost at any point in a quantum circuit. Quantum circuit
gates can thus only express \emph{reversible} operations, and algorithms
operating on quantum machines therefore need to be carefully constructed to only
use reversible operations.

This criterion also poses a challenge to language designers who wish to create
high-level abstractions that can be compiled down to a realisable quantum
circuit, as many common operators, such as the logical OR, are not expressible
in a quantum machine due to their loss of information.

In \cite{altenkirch2010quantum} the authors describe an encoding of quantum
computation in the Quantum IO (QIO) monad, which can effectively simulate
probabilistic quantum operations by sampling a probability distribution. The
framework supplies a DSL, |U|, for reversible computations. This DSL includes,
for example |unot :: Qbit -> U|, which reverses negates a quantum bit (qbit), and |ifQ
:: Qbit -> U -> U| which runs a reversible computation when the supplied quantum
bit is in the true state. Qbits can be initialised using the |mkQbit ::
Bool -> QIO Qbit| operation, and reversible computations can be executed on the
state of the machine using |applyU :: U -> QIO ()|.

These seemingly simple combinators already expose a shortcoming of the API: it
is possible to express irreversible computations: given some |q :: Qbit|, |ifQ q
(unot q)| sets |q|'s value to false. Indeed, the QIO monad enforces a semantic
side condition that the conditional variable must not be modified in the body.
This condition is enforced by the simulator by throwing a runtime error when
such updates are attempted.

A better solution would be to catch the error before even attempting to execute
the program! Using linear constraints, we can provide a safe API for expressing
reversible computations.

The strategy is to modify the QIO API to keep track of having write access to a
qbit. Initialising a qbit provides write access to the qbit.

\begin{code}
mkQbit :: Bool -> exists u. QIO (Qbit q) .<= Write q
\end{code}

Then, we modify |unot| to require write access to the qbit.

\begin{code}
unot :: Write q =>. Qbit q -> U .<= Write q
\end{code}

Finally, |ifQ| consumes write access.

\begin{code}
ifQ :: Write q =>. Qbit q -> U -> U .<= Write q
\end{code}

This way, writing |ifQ q (unot q)| will no longer typecheck, as the call to
|ifQ| has consumed the write access to |q|, thus the body will not be able to
modify it. Of course, it is still possible to write any \emph{other} qbit |r| in the
body, creating an \emph{entagled} pair of qbits: |ifQ q (unot r)|.

\subsection{Ownership and so on…}

From the linear types paper:

\begin{spec}
  newMArray    :: (MArray a ⊸ Unrestricted b) ⊸ Unrestricted b
  writeMArray  :: MArray a ⊸ Int -> a -> MArray a
  freeze       :: MArray a ⊸ Unrestricted (Array a)
  readArray    :: Array a -> Int -> a
\end{spec}

In |writeArray|: we insert an unrestricted element |a ->|. Otherwise
we could do a linear type taboo:

\begin{spec}
unrestrict :: a ⊸ Unrestricted a
unrestrict x = case unrestrictArray x of
  Unrestricted arr -> readArray 0

unrestrictArray :: a ⊸ Unrestricted (Array a)
unrestrictArray x = newArray $ \marr ->
  freeze $
  writeMArray 0 x marr
\end{spec} % emacs <- syntax highlighting bug

This is not ok if I want to make a multidimensional array (say an
|MArray (MArray a)|), which I would later freeze.

How could freeze look like for that use-case?

Something like

\begin{spec}
  freeze :: MArray a ⊸ (a ⊸ Unrestricted b) -> Unrestricted (Array b)
\end{spec}

But this is no longer $O(1)$ unless the compiler has special support
(like |Coercible|~\cite{citation_needed}).

The crux of the issue is that mutable arrays and immutable arrays have
distinct types, which me must convert.

Contrast with Rust, where there is a single type \verb+Vector+, and
freezing is simply
\verb+fn (vect : Vector<a>) : Rc<Vector<a>> -> { Rc<vect> }+ (check
syntax).

With linear constraints:

\begin{spec}
-- Each reference has 3 linear capabilities associated with it. References can be freely copied, but the capabilities are controlled linearly.

-- The relation between references and capabilities is mediated with an existential type variable (of kind Token for legibility here, but we can let Token = Type with no loss of expressivity.)

kind Token
class Read (n :: Token)    -- read capability
class Write (n :: Token)   -- write capability
class Own (n :: Token)     -- move, free,

type O n = (Read n, Write n, Own n) -- but we cannot move unless no one has kept a reference, so really all 3 capabilities are needed. We never use Own alone, always O.

type RW n = (Read n, Write n) -- likewise, one cannot be writing unless we also have read access (so that a reader does not see changes happening while it is reading)

type Reference = Token -> Type -- kind of types which are associated to capabilities via tokens (so ``references'')

AtomRef a :: Reference

data AtomRef (a :: Type) (n :: Token)

writeRef :: (RW n) =>. AtomRef a n -> a -> () .<= RW n
readRef :: (Read n) =>. AtomRef a n -> a .<= Read n
dealloc :: O n =>. AtomRef a n -> ()
newRef :: (forall n. O n =>. AtomRef a n -> Unrestricted b) ⊸ Unrestricted b
aliasRef :: forall n. (RW n, O p) =>. AtomRef a n -> AtomRef a p -> () .<= RW n

-- Polymorphic aliasing
aliasRef' :: forall n. (RW n, O p, KnownRef a) =>. a n -> a p -> () .<= RW n


data PArray (a :: Reference) (n :: Token)
  -- This an array of References: is an array of boxed stuff. Are all
  -- references inside it are associated with the same token.

PArray a :: Reference

-- type Array a = Frozen (PArray a)
-- data Frozen a where
--   Freezed :: Read n => a n -> Frozen a
-- data Reading a where
--   Read :: Read n =>. a n -> Reading a
-- data Borrowed a where
--   Borrow :: RW n =>. a n -> Borrowed a
-- data Owned (a :: * -> *) where
--   Move :: O n =>. a n -> Owned a

newPArray    :: (forall n. O n =>. PArray a n -> Unrestricted b) ⊸ Unrestricted b
-- Create a new array with the 3 capabilities available (|O n|).

-- Wrong:
-- writePArray  :: (RW n, O p) =>. PArray a n -> Int -> a p -> Owned a .<= RW n
  -- Relinquishes the ownership of the |a p| argument. Returns
  -- ownership of the old value.
  -- iiuc: The reference p is moved inside the array (if we'd make a copy we don't need the O p capability). So we make a new token for it (existentially quantified by Owned).
  -- ? With this interface it seems that the owner will be able to freeze the array, but the reference will survive. So it seems that there is a bug here.

writePArrayAlt  :: (RW n, O p) =>. PArray a n -> Int -> a p -> () .<= (RW n)
-- here the ownership of |a p| is absorbed by n.
-- Operational semantics: move the p *reference* inside n.

readPArray   :: Read n =>. PArray a n -> Int -> a n .<= Read n
-- OK

borrowPArrayElement     :: RW n =>. Parray a n -> Int -> (Borrowed a             ⊸ Unrestricted b         ) ⊸ Unrestricted b .<= RW n
borrowPArrayElementAlt  :: RW n =>. Parray a n -> Int -> (forall p. RW p =>. a p ⊸ Unrestricted b .<= RW p) ⊸ Unrestricted b .<= RW n
borrowPArrayElementAlt' :: RW n =>. Parray a n -> Int -> (forall p. RW p =>. a p ⊸ k              .<= RW p) ⊸              k .<= RW n -- continuation won't be called from an unrestricted context because the initial RW n constraint is unique and linear.

borrowPArrayElement is the only way to access an element in read-write

-- freeze       :: O n =>. PArray a n -> Array a
freeze       :: O n =>. PArray a n -> Array a
-- OK


readArray :: Array a -> Int -> Frozen a
readArray (Freezed arr) i = Freezed (readPArray arr i)
\end{spec}

\section{$\klet$ should be generalised}

\unsure{In the current version of the system $\klet$ doesn't
  generalise. We may want to repurpose this argumentation as a
  discussion on possible refinement of the type system for
  convenience.}

The let rule infers a qualified type for the bound variable, by generalising
over all the linear constraints appearing in the bound expression. This is in
stark contrast with OutsideIn's strategy of inferring fully monomorphic types
for let expressions. So why not follow the established tradition and also infer
monomorphic types when linear constraints are involved? Since the let binder is
unrestricted, the variable $x$ may be used multiple times (or none at all). This
means that the let \emph{must not consume any linear constraints}. \change{which
means that if we also add linear lets to the language, then those can consume
linear constraints. But I (Csongor) don't think linear lets will be necessary?}

To illustrate the practical necessity of the let generalisation strategy,
consider the following file handling API:

\begin{code}
newFile :: IO (exists f. File f .<= Open f)
writeFile :: Open f =>. File f -> String -> IO (() .<= Open f)
closeFile :: Open f =>. File f -> IO ()
\end{code}

The |newFile| function creates a file and returns a file handle |File f|,
together with a linear constraint witnessing that the file |f| is open (note
that |f| is existentially quantified). |writeFile| writes a string to an open
file and keeps it open. Finally, |closeFile| closes the file and consumes the
|Open f| constraint.

Now consider the following program:

\begin{code}
readBad :: IO ()
readBad = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  return ()
\end{code}

This program creates a new file, writes the string |"hello"| to it, then
returns. Even though the |closeFile file| action is assigned to a variable, the
action itself is never invoked, and the file remains open. The fixed version
follows:

\begin{code}
readGood :: IO ()
readGood = do
  file <- newFile
  writeFile file "hello"
  let x = closeFile file
  x
\end{code}

Here, |x| is actually executed, thus the file is closed before the function
returns. The type of |x| in both cases is |Open f0 =>. IO ()| (with |f0| the
existential variable created by |newFile|). Happily, |readBad| gets rejected
because the |Open f0| constraint doesn't get consumed before the function returns.

Unlike traditional let-generalisation, this behaviour can not be overridden with
a signature, so writing |x :: IO ()| is rejected. \change{We don't have a rule
for let with a signature yet, but it will have to be this way.}

\subsection{Comparison with OutsideIn}

So far we have argued that linear constraints should be quantified over in let
bindings. But how does this fit into the OutsideIn constraint solver, the type
inference framework employed by GHC?  In~\cite{OutsideIn}, the authors carefully
consider various different generalisation strategies, each with different
tradeoffs, before reaching the conclusion that no generalisation is the most
ergonomic option.

Here is a summary of the different criteria:

\begin{description}
  \item[Equalities]
        OutsideIn never generalises over equality constraints. Doing
        so would result in very large constraints, resulting in ergonomic and
        performance penalties. In our system, equality constraints are always
        unrestricted, so the issues around consumption explained above do not
        apply to them. Thus, there is no need to generalise over equality
        constraints in our system.
  \item[Class constraints]
        OutsideIn never generalises over class constraints. A downside of
        generalising is that type errors are delayed to call sites when a
        constraint can not be solved. In the case of linear constraints, this is
        the desired behaviour, since whether the constraint can be solved depends
        on whether it is available at the call site, which might differ from
        whether it is available at the definition site.
  \item[Type variables]
        OutsideIn makes the observation that if a type variable is generalised,
        then so must be all the constraints that mention that variable (otherwise
        principal types are lost). Because constraints are not generalised, the
        algorithm opts to also not generalise type variables. A possibility not
        considered in~\cite{OutsideIn} is generalising only the constraint, but
        not the type variables mentioned in it. This is the path we take: type
        variables are not quantified over, but (linear) constraints are. This is
        a sensible option in our setting because it still allows deferring
        constraint solving to use sites, without deviating too much from GHC's
        existing strategy.
\end{description}

To summarise, the generalisation strategy in let bindings is to always
generalise over linear constraints, but keep type variables monomorphic and never
quantify over nonlinear constraints (which includes all equality constraints).
This is a conservative extension of OutsideIn.

\subsection{Maybe we need to be more careful?}

As I (Csongor) wrote the above example, I realised that the example API might
not be sufficient. For example,

\begin{code}
readBad2 = do
  file <- newFile
  writeFile file "hello"
  const (return ()) (closeFile file)
\end{code}

here the file handle is not closed, but according to the App rule, the |Open f0|
constrant is consumed by the application to |const|. The issue here is that we
want to actually ensure that |closeFile| gets \emph{executed}, so maybe a better
interface would be

\begin{code}
newFile :: IO (exists f. File f .<= Open f)
writeFile :: File f -> String -> IO (Open f =>. () .<= Open f)
closeFile :: File f -> IO (Open f =>. ())
\end{code}

is there any other way to fix it? Maybe a linear constraint is only consumed in
an application to a linear function?\info{Arnaud: yes! consuming a
  linear constraints in a non-linear operation should be a type error,
  otherwise linear constraints would be unsound.}

\newpage


\printbibliography

\end{document}

% LocalWords:  sequent typechecker
